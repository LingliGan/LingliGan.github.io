<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Levin-lee</title>
  
  <subtitle>Levin-lee的个人博客</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://levin-lee.github.io/"/>
  <updated>2021-12-04T09:45:14.604Z</updated>
  <id>http://levin-lee.github.io/</id>
  
  <author>
    <name>Levin lee</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>人生困惑-11月份小记</title>
    <link href="http://levin-lee.github.io/2021/12/03/%E4%BA%BA%E7%94%9F%E5%9B%B0%E6%83%91-11%E6%9C%88%E4%BB%BD%E5%B0%8F%E8%AE%B0/"/>
    <id>http://levin-lee.github.io/2021/12/03/%E4%BA%BA%E7%94%9F%E5%9B%B0%E6%83%91-11%E6%9C%88%E4%BB%BD%E5%B0%8F%E8%AE%B0/</id>
    <published>2021-12-02T16:59:25.000Z</published>
    <updated>2021-12-04T09:45:14.604Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>最近异常焦虑，导致我近段时间有点萎靡不振，但是到晚上睡觉时，却翻来覆去，怎么也睡不着。</p><p>事情的起因是因为喜欢上了一个女生，她叫张静，我在公司 bbs浏览帖子的时候，发现了她的交友贴，当时看t她照片的时候，并没有觉得她很好看，但是还蛮有个性，觉得可以认识一下，于是我<br>是加了她微信好友。刚开始的时候，聊的特别开心，仿佛有说不完的话，我早上会想跟她聊，晚上下班也跟她聊，越聊越投机（事后证明可能只有我是这样），了解了她的很多往事。就这样，我们一起相互交流、相互了解、相互认识，我对她的好感越来越深。终于，在一个周六的时候，我把她约出来，当时吃的泰国菜。不得不承认，当面看她还是比较可爱，通过面对面的交流，我感觉更加喜欢她了。往后的一周，我约了她一起爬山，爬山的过程也很愉快，她应该是很少爬山，有点体力不支，我们成功下山，去了海上世界去吃了饭，她也恢复了过来，我们聊到了9点半，各自回家。我很喜欢她<br>但是自从爬完山后，渐渐地我发现，她开始变得有些冷漠，从聊天过程，可以明显可以感觉她的语气变得生冷。早上发的一句话，直到晚上才回复。我很难受，我一直以为是自己的问题，不够关心、不够呵护她，但是经过被冷淡处理几次之后，终于我选择问她，她的回答也是那么俗套，“你很好，但是我们习俗和习惯不一样，从以后的发展来看不适合在一起，不用花时间浪费在她身上”。那一瞬间，心如死灰，我想是时候结束这么难受的感觉了。我们的习俗不一样，是早就存在的事情，我也多次跟确认，得到的回复都说大家都在深圳，是没关系的。而且她多次跟我表示，深圳房价很贵，两个人可以携手，就会简单一些。算了，一起都过去了，只是会想起来，依旧觉得伤感，我这么喜欢她。</p><p>三生三大悲剧，怨憎会，爱别离，求不得。</p><p><img src= "/img/loading.gif" data-lazy-src="/img/zhangjing.jpg" alt=""></p><p>附上她的交友信息</p><blockquote><p>关于自己：<br>94年，来自湖北荆州，硕士研究生，在深圳从事金融行业，比较独立但也需要一个值得依赖的人，比较感性，对事物有自己的见解～<br>期待的他：90年-94年，170+，本科及以上～未来能在深圳定居并且愿意一起共同努力为之奋斗！希望对方拥有的特质：有责任心，爱沟通，愿意分担家务，有换位思考的能力，不情绪化<br>微信号: XXXXXX</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot; cla
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="http://levin-lee.github.io/2021/11/27/hello-world/"/>
    <id>http://levin-lee.github.io/2021/11/27/hello-world/</id>
    <published>2021-11-27T07:16:59.307Z</published>
    <updated>2021-11-27T07:16:59.307Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot; cla
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>RDD函数大全</title>
    <link href="http://levin-lee.github.io/2021/11/27/RDD%E5%87%BD%E6%95%B0%E5%A4%A7%E5%85%A8/"/>
    <id>http://levin-lee.github.io/2021/11/27/RDD%E5%87%BD%E6%95%B0%E5%A4%A7%E5%85%A8/</id>
    <published>2021-11-27T06:20:45.000Z</published>
    <updated>2021-11-27T07:08:16.435Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2 id="map"><a href="#map" class="headerlink" title="map"></a>map</h2><blockquote><p>是对 RDD 中的每个元素都执行一个指定的函数来产生一个新的 RDD。 任何 原 RDD 中的元素在新 RDD 中都有且只有一个元素与之对应。 举例： </p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">scala&gt;val a&#x3D;sc.parallelize(1to9,3) </span><br><span class="line">scala&gt;val b&#x3D;a.map(x&#x3D;&gt;x*2) </span><br><span class="line">scala&gt;a.collect res10:Array[Int]&#x3D;Array(1,2,3,4,5,6,7,8,9) </span><br><span class="line">scala&gt;b.collect res11:Array[Int]&#x3D;Array(2,4,6,8,10,12,14,16,18) </span><br><span class="line">&#x2F;&#x2F;上述例子中把原 RDD 中每个元素都乘以 2 来产生一个新的 RDD。</span><br></pre></td></tr></table></figure><h2 id="filter"><a href="#filter" class="headerlink" title="filter"></a>filter</h2><blockquote><p>filter 是对 RDD 中的每个元素都执行一个指定的函数来过滤产生一个新的 RDD。 任何原 RDD 中的元素在新 RDD 中都有且只有一个元素与之对应。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">val rdd&#x3D;sc.parallelize(List(1,2,3,4,5,6)) </span><br><span class="line">val filterRdd&#x3D;rdd.filter(_&gt;5) </span><br><span class="line">filterRdd.collect()&#x2F;&#x2F;返回所有大于 5 的数据的一个 Array， Array(6,8,10,12)</span><br></pre></td></tr></table></figure><h2 id="flatMap"><a href="#flatMap" class="headerlink" title="flatMap"></a>flatMap</h2><blockquote><p>与 map 类似，区别是原 RDD 中的元素经 map 处理后只能生成一个元素，而原 RDD 中的元素经 flatmap 处理后可生成多个元素来构建新 RDD。举例：对原 RDD 中的每个元素 x 产生 y 个元素（从 1 到 y，y 为元素 x 的值） </p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scala&gt;vala&#x3D;sc.parallelize(1to4,2) scala&gt;valb&#x3D;a.flatMap(x&#x3D;&gt;1tox)</span><br><span class="line">scala&gt;b.collect res12:Array[Int]&#x3D;Array(1,1,2,1,2,3,1,2,3,4)</span><br></pre></td></tr></table></figure><h2 id="mapPartitions"><a href="#mapPartitions" class="headerlink" title="mapPartitions"></a>mapPartitions</h2><blockquote><p>mapPartitions 是 map 的一个变种。map 的输入函数是应用于 RDD 中每个元素， 而 mapPartitions 的输入函数是应用于每个分区，也就是把每个分区中的内容作 为整体来处理的。 它的函数定义为： def mapPartitions<a href="f: Iterator[T] =&gt; Iterator[U], preservesPartitioning: Boolean=false">U: ClassTag</a>:RDD[U] f 即为输入函数，它处理每个分区里面的内容。每个分区中的内容将以 Iterator[T] 传递给输入函数 f， f 的输出结果是 Iterator[U]。最终的 RDD 由所有分区经过输入 函数处理后的结果合并起来的。 举例：</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">scala&gt;val a&#x3D;sc.parallelize(1to9,3) </span><br><span class="line">scala&gt;def myfuncT:Iterator[(T,T)]&#x3D;&#123; </span><br><span class="line">var res&#x3D;List(T,T) </span><br><span class="line">var pre&#x3D;iter.next </span><br><span class="line">while(iter.hasNext)&#123; </span><br><span class="line">valcur&#x3D;iter.next </span><br><span class="line">res.::&#x3D;(pre,cur) </span><br><span class="line">pre&#x3D;cur &#125; res.iterator &#125; </span><br><span class="line">scala&gt;a.mapPartitions(myfunc).collect </span><br><span class="line">res0:Array[(Int,Int)]&#x3D;Array((2,3),(1,2),(5,6),(4,5),(8,9),(7,8))</span><br></pre></td></tr></table></figure><p> 上述例子中的函数myfunc是把分区中一个元素和它的下一个元素组成一个Tuple。 因为分区中最后一个元素没有下一个元素了，所以(3,4)和(6,7)不在结果中。 mapPartitions 还有些变种，比如 mapPartitionsWithContext，它能把处理过程中的 一些状态信息传递给用户指定的输入函数。还有 mapPartitionsWithIndex，它能 把分区的 index传递给用户指定的输入函数。</p><h2 id="mapPartitionsWithIndex"><a href="#mapPartitionsWithIndex" class="headerlink" title="mapPartitionsWithIndex"></a>mapPartitionsWithIndex</h2><p>def mapPartitionsWithIndex<a href="f: (Int, Iterator[T]">U</a> =&gt; Iterator[U], preservesPartitioning:Boolean=false)(implicitarg0:ClassTag[U]):RDD[U] 函数作用同 mapPartitions，不过提供了两个参数，第一个参数为分区的索引。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">var rdd1&#x3D;sc.makeRDD(1to5,2) &#x2F;&#x2F;rdd1 有两个分区 </span><br><span class="line">var rdd2&#x3D;rdd1.mapPartitionsWithIndex&#123; </span><br><span class="line">(x,iter)&#x3D;&gt;&#123; varresult&#x3D;ListString </span><br><span class="line">var i&#x3D;0 </span><br><span class="line">while(iter.hasNext)&#123; i+&#x3D;iter.next() &#125; result.::(x+&quot;|&quot;+i).iterator</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>//rdd2 将 rdd1 中每个分区的数字累加，并在每个分区的累加结果前面加了分区 索引 scala&gt;rdd2.collect res13:Array[String]=Array(0|3,1|12)</p><h2 id="mapWith"><a href="#mapWith" class="headerlink" title="mapWith"></a>mapWith</h2><blockquote><p>mapWith 是 map 的另外一个变种，map 只需要一个输入函数，而 mapWith 有两 个输入函数。它的定义如下： def mapWith<a href="constructA: Int =&gt; A, preservesPartitioning: Boolean = false">A: ClassTag, U: </a>(f:(T,A)=&gt;U):RDD[U] 第一个函数 constructA 是把 RDD 的 partitionindex（index 从 0 开始）作为输入， 输出为新类型 A； 第二个函数 f 是把二元组(T,A)作为输入（其中 T 为原 RDD 中的元素，A 为第一个 函数的输出），输出类型为 U。 举例：把 partitionindex 乘以 10 加 2,作为新的 RDD 的元素。 </p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">val x&#x3D;sc.parallelize(List(1,2,3,4,5,6,7,8,9,10),3) </span><br><span class="line">x.mapWith(a&#x3D;&gt;a*10)((b,a)&#x3D;&gt;(b,a+2)).collect </span><br><span class="line">&#x2F;&#x2F; 结果： </span><br><span class="line">(1,2) (2,2) (3,2) (4,12)</span><br><span class="line">(5,12) (6,12) (7,22) (8,22) (9,22) (10,22)</span><br></pre></td></tr></table></figure><h2 id="flatMapWith"><a href="#flatMapWith" class="headerlink" title="flatMapWith"></a>flatMapWith</h2><blockquote><p>flatMapWith 与 mapWith 很类似，都是接收两个函数，一个函数把 partitionIndex 作为输入，输出是一个新类型 A；另外一个函数是以二元组（T,A）作为输入，输 出为一个序列，这些序列里面的元素组成了新的 RDD。它的定义如下：<br>def flatMapWith<a href="constructA:Int =&gt;A, preservesPartitioning: Boolean=false">A:ClassTag, U: ClassTag</a>(f:(T,A)=&gt;Seq[U]):RDD[U] 举例： </p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scala&gt;vala&#x3D;sc.parallelize(List(1,2,3,4,5,6,7,8,9),3) </span><br><span class="line">scala&gt;a.flatMapWith(x&#x3D;&gt;x,true)((x,y)&#x3D;&gt;List(y,x)).collect </span><br><span class="line">res58:Array[Int]&#x3D;Array(0,1,0,2,0,3,1,4,1,5,1,6,2,7,2, 8,2,9)</span><br></pre></td></tr></table></figure><h2 id="coalesce"><a href="#coalesce" class="headerlink" title="coalesce"></a>coalesce</h2><blockquote><p>def coalesce(numPartitions: Int, shuffle: Boolean = false)(implicit ord: Ordering[T] = null):RDD[T] 该函数用于将 RDD 进行重分区，使用 HashPartitioner。 第一个参数为重分区的数目，第二个为是否进行 shuffle，默认为 false; 以下面的例子来看： </p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">scala&gt;var data&#x3D;sc.parallelize(1to12,3) </span><br><span class="line">scala&gt;data.collect </span><br><span class="line">scala&gt;data.partitions.size </span><br><span class="line">scala&gt;var rdd1&#x3D;data.coalesce(1) </span><br><span class="line">scala&gt;rdd1.partitions.size </span><br><span class="line">scala&gt;varrdd1&#x3D;data.coalesce(4) </span><br><span class="line">scala&gt;rdd1.partitions.size res2:Int&#x3D;1 </span><br><span class="line">&#x2F;&#x2F;如果重分区的数目大于原来的分区数，那么必须指定 shuffle 参 数为 true，&#x2F;&#x2F;否则，分区数不便 scala&gt;varrdd1&#x3D;data.coalesce(4,true) scala&gt;rdd1.partitions.size</span><br><span class="line">res3:Int&#x3D;4</span><br></pre></td></tr></table></figure><h2 id="repartition"><a href="#repartition" class="headerlink" title="repartition"></a>repartition</h2><blockquote><p>defrepartition(numPartitions:Int)(implicitord:Ordering[T]=null):RDD[T] 该函数其实就是 coalesce 函数第二个参数为 true 的实现<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">scala&gt;vardata&#x3D;sc.parallelize(1to12,3) </span><br><span class="line">scala&gt;data.collect scala&gt;data.partitions.size </span><br><span class="line">scala&gt;var rdd1&#x3D;data.repartition(1) </span><br><span class="line">scala&gt;rdd1.partitions.size </span><br><span class="line">scala&gt;varrdd1&#x3D;data.repartition(4) </span><br><span class="line">scala&gt;rdd1.partitions.size res3:Int&#x3D;4</span><br></pre></td></tr></table></figure></p></blockquote><h2 id="randomSplit"><a href="#randomSplit" class="headerlink" title="randomSplit"></a>randomSplit</h2><blockquote><p>def randomSplit(weights: Array[Double], seed: Long = Utils.random.nextLong): Array[RDD[T]] 该函数根据 weights 权重，将一个 RDD 切分成多个 RDD。 该权重参数为一个 Double 数组 第二个参数为 random 的种子，基本可忽略。 </p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">scala&gt;rdd.collect res6:Array[Int]&#x3D;Array(1,2,3,4,5,6,7,8,9,10)</span><br><span class="line">scala&gt;varsplitRDD&#x3D;rdd.randomSplit(Array(0.5,0.1,0.2,0.2)) splitRDD: Array[org.apache.spark.rdd.RDD[Int]] &#x3D; Array(MapPartitionsRDD[17] at randomSplitat:23, MapPartitionsRDD[18]atrandomSplitat:23, MapPartitionsRDD[19]atrandomSplitat:23, MapPartitionsRDD[20]atrandomSplitat:23)</span><br><span class="line">&#x2F;&#x2F;这里注意：randomSplit 的结果是一个 RDD 数组</span><br><span class="line">scala&gt;splitRDD.size res8:Int&#x3D;4 &#x2F;&#x2F;由于 randomSplit 的第一个参数 weights 中传入的值有 4 个，因此，就会切分成 4 个 RDD, &#x2F;&#x2F;把原来的 rdd 按照权重 0.5,0.1,0.2,0.2，随机划分到这 4 个 RDD 中，权重高的 RDD，划分到&#x2F;&#x2F;的几率就大一些。 &#x2F;&#x2F;注意，权重的总和加起来为 1，否则会不正常 scala&gt;splitRDD(0).collect res10:Array[Int]&#x3D;Array(1,4)</span><br><span class="line">scala&gt;splitRDD(1).collect res11:Array[Int]&#x3D;Array(3)</span><br><span class="line">scala&gt;splitRDD(2).collect res12:Array[Int]&#x3D;Array(5,9)</span><br><span class="line">scala&gt;splitRDD(3).collect res13:Array[Int]&#x3D;Array(2,6,7,8,10)</span><br></pre></td></tr></table></figure><h2 id="glom"><a href="#glom" class="headerlink" title="glom"></a>glom</h2><blockquote><p>defglom():RDD[Array[T]] 该函数是将 RDD 中每一个分区中类型为 T 的元素转换成 Array[T]，这样每一个分 区就只有一个数组元素。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">scala&gt;var rdd&#x3D;sc.makeRDD(1to10,3) </span><br><span class="line">rdd:org.apache.spark.rdd.RDD[Int]&#x3D;ParallelCollectionRDD[38]atmakeRDDat:21 </span><br><span class="line">scala&gt;rdd.partitions.size res33:Int&#x3D;3 </span><br><span class="line">&#x2F;&#x2F;该 RDD 有 3 个分区 </span><br><span class="line">scala&gt;rdd.glom().collect </span><br><span class="line">res35:Array[Array[Int]]&#x3D;Array(Array(1,2,3),Array(4,5,6),Array(7,8,9,10)) &#x2F;&#x2F;glom 将每个分区中的元素放到一个数组中，这样，结果就变成了 3 个数组</span><br></pre></td></tr></table></figure><h2 id="union-并集"><a href="#union-并集" class="headerlink" title="union 并集"></a>union 并集</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">val rdd1&#x3D;sc.parallelize(List(5,6,4,3)) </span><br><span class="line">val rdd2&#x3D;sc.parallelize(List(1,2,3,4)) &#x2F;&#x2F;求并集 </span><br><span class="line">val rdd3&#x3D;rdd1.union(rdd2) </span><br><span class="line">rdd3.collect</span><br></pre></td></tr></table></figure><h2 id="distinct"><a href="#distinct" class="headerlink" title="distinct"></a>distinct</h2><blockquote><p>去重 </p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">val rdd1&#x3D;sc.parallelize(List(5,6,4,3)) </span><br><span class="line">val rdd2&#x3D;sc.parallelize(List(1,2,3,4)) &#x2F;&#x2F;求并集 valrdd3&#x3D;rdd1.union(rdd2) &#x2F;&#x2F;去重输出 rdd3.distinct.collect</span><br></pre></td></tr></table></figure><h2 id="intersection-交集"><a href="#intersection-交集" class="headerlink" title="intersection 交集"></a>intersection 交集</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">val rdd1&#x3D;sc.parallelize(List(5,6,4,3)) </span><br><span class="line">valrdd2&#x3D;sc.parallelize(List(1,2,3,4)) &#x2F;&#x2F;求交集 valrdd4&#x3D;rdd1.intersection(rdd2) rdd4.collect</span><br></pre></td></tr></table></figure><h2 id="subtract"><a href="#subtract" class="headerlink" title="subtract"></a>subtract</h2><blockquote><p>def subtract(other:RDD[T]):RDD[T] defsubtract(other:RDD[T],numPartitions:Int):RDD[T] def subtract(other: RDD[T], partitioner: Partitioner)(implicit ord: Ordering[T] = null): RDD[T] 该函数返回在 RDD 中出现，并且不在 otherRDD 中出现的元素，不去重。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">val rdd1&#x3D;sc.parallelize(List(5,6,6,4,3)) </span><br><span class="line">val rdd2&#x3D;sc.parallelize(List(1,2,3,4)) &#x2F;&#x2F;求差集 valrdd4&#x3D;rdd1.subtract(rdd2) rdd4.collect</span><br></pre></td></tr></table></figure><h2 id="subtractByKey"><a href="#subtractByKey" class="headerlink" title="subtractByKey"></a>subtractByKey</h2><blockquote><p>defsubtractByKeyW(implicitarg0:ClassTag[W]):RDD[(K,V)] def subtractByKey<a href="other: RDD[(K, W">W</a>], numPartitions: Int)(implicit arg0: ClassTag[W]):RDD[(K,V)] def subtractByKey<a href="other: RDD[(K, W">W</a>], p: Partitioner)(implicit arg0: ClassTag[W]): RDD[(K,V)]<br>subtractByKey 和基本转换操作中的 subtract 类似，只不过这里是针对 K 的，返回 在主 RDD 中出现，并且不在 otherRDD 中出现的元素。 参数 numPartitions 用于指定结果的分区数 参数 partitioner 用于指定分区函数</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">var rdd1&#x3D;sc.makeRDD(Array((&quot;A&quot;,&quot;1&quot;),(&quot;B&quot;,&quot;2&quot;),(&quot;C&quot;,&quot;3&quot;)),2) </span><br><span class="line">var rdd2&#x3D;sc.makeRDD(Array((&quot;A&quot;,&quot;a&quot;),(&quot;C&quot;,&quot;c&quot;),(&quot;D&quot;,&quot;d&quot;)),2) </span><br><span class="line">scala&gt;rdd1.subtractByKey(rdd2).collect res13:Array[(String,String)]&#x3D;Array((B,2))</span><br></pre></td></tr></table></figure><h2 id="groupbyKey"><a href="#groupbyKey" class="headerlink" title="groupbyKey"></a>groupbyKey</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">val rdd1&#x3D;sc.parallelize(List((&quot;tom&quot;,1),(&quot;jerry&quot;,3),(&quot;kitty&quot;,2))) </span><br><span class="line">val rdd2&#x3D;sc.parallelize(List((&quot;jerry&quot;,2),(&quot;tom&quot;,1),(&quot;shuke&quot;,2))) &#x2F;&#x2F;求并集 </span><br><span class="line">val rdd4&#x3D;rdd1.union(rdd2) &#x2F;&#x2F;按 key 进行分组 </span><br><span class="line">val rdd5&#x3D;rdd4.groupByKey </span><br><span class="line">rdd5.collect</span><br></pre></td></tr></table></figure><h2 id="reduceByKey"><a href="#reduceByKey" class="headerlink" title="reduceByKey"></a>reduceByKey</h2><blockquote><p>顾名思义，reduceByKey 就是对元素为 KV 对的 RDD 中 Key 相同的元素的 Value 进行 reduce，因此，Key 相同的多个元素的值被 reduce 为一个值，然后与原 RDD 中的 Key 组成一个新的 KV 对。 举例: </p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">valrdd1&#x3D;sc.parallelize(List((&quot;tom&quot;,1),(&quot;jerry&quot;,3),(&quot;kitty&quot;,2))) </span><br><span class="line">valrdd2&#x3D;sc.parallelize(List((&quot;jerry&quot;,2),(&quot;tom&quot;,1),(&quot;shuke&quot;,2))) &#x2F;&#x2F;求并集 </span><br><span class="line">val rdd4&#x3D;rdd1unionrdd2 &#x2F;&#x2F;按 key 进行分组 </span><br><span class="line">val rdd6&#x3D;rdd4.reduceByKey(+) rdd6.collect()</span><br></pre></td></tr></table></figure><h2 id="sortByKey"><a href="#sortByKey" class="headerlink" title="sortByKey"></a>sortByKey</h2><blockquote><p>将 List((“tom”,1),(“jerry”,3),(“kitty”,2), (“shuke”,1))和 List((“jerry”,2),(“tom”,3), (“shuke”,2),(“kitty”,5))做 wordcount，并按名称排序<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">val rdd1&#x3D;sc.parallelize(List((&quot;tom&quot;,1),(&quot;jerry&quot;,3),(&quot;kitty&quot;,2),(&quot;shuke&quot;,1))) </span><br><span class="line">val rdd2&#x3D;sc.parallelize(List((&quot;jerry&quot;,2),(&quot;tom&quot;,3),(&quot;shuke&quot;,2),(&quot;kitty&quot;,5))) </span><br><span class="line">val rdd3&#x3D;rdd1.union(rdd2) &#x2F;&#x2F;按 key 进行聚合 </span><br><span class="line">val rdd4&#x3D;rdd3.reduceByKey(+) &#x2F;&#x2F;false 降序 </span><br><span class="line">val rdd5&#x3D;rdd4.sortByKey(false) </span><br><span class="line">rdd5.collect</span><br></pre></td></tr></table></figure></p></blockquote><h2 id="sortBy"><a href="#sortBy" class="headerlink" title="sortBy"></a>sortBy</h2><blockquote><p>将 List((“tom”,1),(“jerry”,3),(“kitty”,2), (“shuke”,1))和 List((“jerry”,2),(“tom”,3), (“shuke”,2),(“kitty”,5))做 wordcount，并按数值排序 </p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">val rdd1&#x3D;sc.parallelize(List((&quot;tom&quot;,1),(&quot;jerry&quot;,3),(&quot;kitty&quot;,2),(&quot;shuke&quot;,1))) </span><br><span class="line">valrdd2&#x3D;sc.parallelize(List((&quot;jerry&quot;,2),(&quot;tom&quot;,3),(&quot;shuke&quot;,2),(&quot;kitty&quot;,5))) </span><br><span class="line">val rdd3&#x3D;rdd1.union(rdd2) </span><br><span class="line">&#x2F;&#x2F;按 key 进行聚合 </span><br><span class="line">valrdd4&#x3D;rdd3.reduceByKey(+)</span><br><span class="line">&#x2F;&#x2F;false 降序 </span><br><span class="line">valrdd5&#x3D;rdd4.sortBy(_._2,false) rdd5.collect</span><br><span class="line"></span><br><span class="line">## zip</span><br><span class="line">&gt;def zipU(implicitarg0:ClassTag[U]):RDD[(T,U)]</span><br><span class="line">zip 函数用于将两个 RDD 组合成 Key&#x2F;Value 形式的 RDD,这里默认两个 RDD 的 partition 数量以及元素数量都相同，否则会抛出异常。</span><br></pre></td></tr></table></figure><p>scala&gt;varrdd1=sc.makeRDD(1to5,2) rdd1:org.apache.spark.rdd.RDD[Int]=ParallelCollectionRDD[1]atmakeRDDat:21<br>scala&gt;varrdd2=sc.makeRDD(Seq(“A”,”B”,”C”,”D”,”E”),2) rdd2: org.apache.spark.rdd.RDD[String] = ParallelCollectionRDD[2] at makeRDD at:21<br>scala&gt;rdd1.zip(rdd2).collect res0:Array[(Int,String)]=Array((1,A),(2,B),(3,C),(4,D),(5,E))<br>scala&gt;rdd2.zip(rdd1).collect res1:Array[(String,Int)]=Array((A,1),(B,2),(C,3),(D,4),(E,5))<br>scala&gt;varrdd3=sc.makeRDD(Seq(“A”,”B”,”C”,”D”,”E”),3) rdd3: org.apache.spark.rdd.RDD[String] = ParallelCollectionRDD[5] at makeRDD at:21 scala&gt;rdd1.zip(rdd3).collect java.lang.IllegalArgumentException: Can’t zip RDDs with unequal numbers of partitions //如果两个 RDD 分区数不同，则抛出异常<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">## zipPartitions</span><br><span class="line">&gt;zipPartitions 函数将多个 RDD 按照 partition 组合成为新的 RDD，该函数需要组合</span><br><span class="line">的 RDD 具有相同的分区数，但对于每个分区内的元素数量没有要求。 该函数有好几种实现，可分为三类：</span><br><span class="line">参数是一个 RDD</span><br></pre></td></tr></table></figure><br>def zipPartitions<a href="rdd2: RDD[B]">B, V</a>(f: (Iterator[T], Iterator[B]) =&gt; Iterator[V])(implicit arg0: ClassTag[B],arg1:ClassTag[V]):RDD[V]<br>def zipPartitions<a href="rdd2: RDD[B], preservesPartitioning: Boolean">B, V</a>(f: (Iterator[T], Iterator[B]) =&gt; Iterator[V])(implicitarg0:ClassTag[B],arg1:ClassTag[V]):RDD[V]<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">这两个区别就是参数 preservesPartitioning，是否保留父 RDD 的 partitioner 分区信息</span><br><span class="line">映射方法 f 参数为两个 RDD 的迭代器。</span><br></pre></td></tr></table></figure><br>scala&gt;varrdd1=sc.makeRDD(1to5,2) rdd1:org.apache.spark.rdd.RDD[Int]=ParallelCollectionRDD[22]atmakeRDDat:21<br>scala&gt;varrdd2=sc.makeRDD(Seq(“A”,”B”,”C”,”D”,”E”),2) rdd2:org.apache.spark.rdd.RDD[String]=ParallelCollectionRDD[23]atmakeRDDat:21<br>//rdd1 两个分区中元素分布： scala&gt;rdd1.mapPartitionsWithIndex{ | (x,iter)=&gt;{ | varresult=ListString | while(iter.hasNext){ | result::=(“part<em>“+x+”|”+iter.next()) | } | result.iterator | | } | }.collect res17:Array[String]=Array(part_0|2,part_0|1,part_1|5,part_1|4,part_1|3)<br>//rdd2 两个分区中元素分布 scala&gt;rdd2.mapPartitionsWithIndex{ | (x,iter)=&gt;{<br>| varresult=ListString | while(iter.hasNext){ | result::=(“part</em>“+x+”|”+iter.next()) | } | result.iterator | | } | }.collect res18:Array[String]=Array(part<em>0|B,part_0|A,part_1|E,part_1|D,part_1|C)<br>//rdd1 和 rdd2 做 zipPartition scala&gt;rdd1.zipPartitions(rdd2){ | (rdd1Iter,rdd2Iter)=&gt;{ | varresult=ListString | while(rdd1Iter.hasNext&amp;&amp;rdd2Iter.hasNext){ | result::=(rdd1Iter.next()+””+rdd2Iter.next()) | } | result.iterator | } | }.collect res19:Array[String]=Array(2_B,1_A,5_E,4_D,3_C)<br>参数是两个 RDD<br>def zipPartitions<a href="rdd2: RDD[B], rdd3: RDD[C]">B, C, V</a>(f: (Iterator[T], Iterator[B], Iterator[C]) =&gt; Iterator[V])(implicitarg0:ClassTag[B],arg1:ClassTag[C],arg2:ClassTag[V]):RDD[V]<br>def zipPartitions<a href="rdd2: RDD[B], rdd3: RDD[C], preservesPartitioning: Boolean">B, C, V</a>(f: (Iterator[T], Iterator[B], Iterator[C]) =&gt; Iterator[V])(implicit arg0: ClassTag[B], arg1: ClassTag[C], arg2:ClassTag[V]):RDD[V]<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">用法同上面，只不过该函数参数为两个 RDD，映射方法 f 输入参数为两个 RDD 的迭代器。</span><br></pre></td></tr></table></figure><br>scala&gt;varrdd1=sc.makeRDD(1to5,2) rdd1:org.apache.spark.rdd.RDD[Int]=ParallelCollectionRDD[27]atmakeRDDat:21<br>scala&gt;varrdd2=sc.makeRDD(Seq(“A”,”B”,”C”,”D”,”E”),2) rdd2:org.apache.spark.rdd.RDD[String]=ParallelCollectionRDD[28]atmakeRDDat:21<br>scala&gt;varrdd3=sc.makeRDD(Seq(“a”,”b”,”c”,”d”,”e”),2) rdd3:org.apache.spark.rdd.RDD[String]=ParallelCollectionRDD[29]atmakeRDDat:21<br>//rdd3 中个分区元素分布 scala&gt;rdd3.mapPartitionsWithIndex{ | (x,iter)=&gt;{ | varresult=ListString | while(iter.hasNext){ | result::=(“part”+x+”|”+iter.next()) | } | result.iterator | | } | }.collect res21:Array[String]=Array(part_0|b,part_0|a,part_1|e,part_1|d,part_1|c)<br>//三个 RDD 做 zipPartitions scala&gt;varrdd4=rdd1.zipPartitions(rdd2,rdd3){ | (rdd1Iter,rdd2Iter,rdd3Iter)=&gt;{ | varresult=ListString | while(rdd1Iter.hasNext&amp;&amp;rdd2Iter.hasNext&amp;&amp;rdd3Iter.hasNext){ | result::=(rdd1Iter.next()+””+rdd2Iter.next()+””+rdd3Iter.next()) | } | result.iterator | } | } rdd4:org.apache.spark.rdd.RDD[String]=ZippedPartitionsRDD3[33]atzipPartitionsat:27<br>scala&gt;rdd4.collect res23:Array[String]=Array(2_B_b,1_A_a,5_E_e,4_D_d,3_C_c)<br>参数是三个 RDD<br>def zipPartitions<a href="rdd2: RDD[B], rdd3: RDD[C], rdd4: RDD[D]">B, C, D, V</a>(f: (Iterator[T], Iterator[B],<br>Iterator[C], Iterator[D]) =&gt; Iterator[V])(implicit arg0: ClassTag[B], arg1: ClassTag[C], arg2: ClassTag[D],arg3:ClassTag[V]):RDD[V]<br>def zipPartitions<a href="rdd2: RDD[B], rdd3: RDD[C], rdd4: RDD[D], preservesPartitioning: Boolean">B, C, D, V</a>(f: (Iterator[T], Iterator[B], Iterator[C], Iterator[D]) =&gt; Iterator[V])(implicit arg0: ClassTag[B],arg1:ClassTag[C],arg2:ClassTag[D],arg3:ClassTag[V]):RDD[V]<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">用法同上面，只不过这里又多了个一个 RDD 而已。</span><br><span class="line"></span><br><span class="line">## zipWithIndex</span><br><span class="line">&gt;defzipWithIndex():RDD[(T,Long)] 该函数将 RDD 中的元素和这个元素在 RDD 中的 ID（索引号）组合成键&#x2F;值对。</span><br></pre></td></tr></table></figure><br>scala&gt;var rdd2=sc.makeRDD(Seq(“A”,”B”,”R”,”D”,”F”),2)<br>rdd2: org.apache.spark.rdd.RDD[String] = ParallelCollectionRDD[34] at makeRDD at:21<br>scala&gt;rdd2.zipWithIndex().collect res27:Array[(String,Long)]=Array((A,0),(B,1),(R,2),(D,3),(F,4))<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">##  zipWithUniqueId</span><br><span class="line">&gt;def zipWithUniqueId():RDD[(T,Long)] 该函数将 RDD 中元素和一个唯一 ID 组合成键&#x2F;值对，该唯一 ID 生成算法如下： 每个分区中第一个元素的唯一 ID 值为：该分区索引号， 每个分区中第 N 个元素的唯一 ID 值为： (前一个元素的唯一 ID 值)+(该 RDD 总的 分区数) 看下面的例子： scala&gt;varrdd1&#x3D;sc.makeRDD(Seq(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;,&quot;D&quot;,&quot;E&quot;,&quot;F&quot;),2) rdd1: org.apache.spark.rdd.RDD[String] &#x3D; ParallelCollectionRDD[44] at makeRDD at:21 &#x2F;&#x2F;rdd1 有两个分区， scala&gt;rdd1.zipWithUniqueId().collect res32:Array[(String,Long)]&#x3D;Array((A,0),(B,2),(C,4),(D,1),(E,3),(F,5))</span><br><span class="line">&#x2F;&#x2F;总分区数为 2 &#x2F;&#x2F;第一个分区第一个元素 ID 为 0，第二个分区第一个元素 ID 为 1 &#x2F;&#x2F;第一个分区第二个元素 ID 为 0+2&#x3D;2，第一个分区第三个元素 ID 为 2+2&#x3D;4 &#x2F;&#x2F;第二个分区第二个元素 ID 为 1+2&#x3D;3，第二个分区第三个元素 ID 为 3+2&#x3D;5</span><br><span class="line">键值转换</span><br><span class="line"></span><br><span class="line">## partitionBy</span><br><span class="line">&gt;def partitionBy(partitioner:Partitioner):RDD[(K,V)] 该函数根据 partitioner 函数生成新的 ShuffleRDD，将原 RDD 重新分区。 scala&gt;varrdd1&#x3D;sc.makeRDD(Array((1,&quot;A&quot;),(2,&quot;B&quot;),(3,&quot;C&quot;),(4,&quot;D&quot;)),2) rdd1:org.apache.spark.rdd.RDD[(Int,String)]&#x3D;ParallelCollectionRDD[23]atmakeRDDat:21 scala&gt;rdd1.partitions.size res20:Int&#x3D;2</span><br></pre></td></tr></table></figure><br>//查看 rdd1 中每个分区的元素<br>scala&gt;rdd1.mapPartitionsWithIndex{ | (partIdx,iter)=&gt;{ | varpart_map=scala.collection.mutable.MapString,List[(Int,String)] | while(iter.hasNext){ | varpart_name=”part</em>“+partIdx; | varelem=iter.next() | if(part<em>map.contains(part_name)){ | varelems=part_map(part_name) | elems::=elem | part_map(part_name)=elems | }else{ | part_map(part_name)=List[(Int,String)]{elem} | } | } | part_map.iterator | | } | }.collect res22:Array[(String,List[(Int,String)])]=Array((part_0,List((2,B),(1,A))),(part_1,List((4,D),(3,C))))<br>//(2,B),(1,A)在 part_0 中，(4,D),(3,C)在 part_1 中<br>//使用 partitionBy 重分区<br>scala&gt;varrdd2=rdd1.partitionBy(neworg.apache.spark.HashPartitioner(2)) rdd2:org.apache.spark.rdd.RDD[(Int,String)]=ShuffledRDD[25]atpartitionByat:23<br>scala&gt;rdd2.partitions.size res23:Int=2<br>//查看 rdd2 中每个分区的元素<br>scala&gt;rdd2.mapPartitionsWithIndex{ | (partIdx,iter)=&gt;{ | varpart_map=scala.collection.mutable.MapString,List[(Int,String)] | while(iter.hasNext){ | varpart_name=”part</em>“+partIdx; | varelem=iter.next() | if(part<em>map.contains(part_name)){ | varelems=part_map(part_name) | elems::=elem | part_map(part_name)=elems | }else{ | part_map(part_name)=List[(Int,String)]{elem} | } | } | part_map.iterator | } | }.collect res24:Array[(String,List[(Int,String)])]=Array((part_0,List((4,D),(2,B))),(part_1,List((3,C),(1,A)))) //(4,D),(2,B)在 part_0 中，(3,C),(1,A)在 part_1 中<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">##  mapValues</span><br><span class="line">&gt;mapValues 顾名思义就是输入函数应用于 RDD 中 Kev-Value 的 Value，原 RDD 中的 Key 保持 不变，与新的 Value 一起组成新的 RDD 中的元素。因此，该函数只适用于元素为 KV 对的 RDD。 举例：</span><br></pre></td></tr></table></figure><br>scala&gt;vala=sc.parallelize(List(“dog”,”tiger”,”lion”,”cat”,”panther”,”eagle”),2)<br>scala&gt;valb=a.map(x=&gt;(x.length,x))<br>scala&gt;b.mapValues(“x”+</em>+”x”).collect<br>res5: Array[(Int, String)] = Array((3,xdogx), (5,xtigerx), (4,xlionx),(3,xcatx), (7,xpantherx), (5,xeaglex))<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">##  flatMapValues</span><br><span class="line">&gt;flatMapValues 类似于 mapValues，不同的在于 flatMapValues 应用于元素为 KV 对的 RDD 中 Value。每个一元素的 Value 被输入函数映射为一系列的值，然后这些值再与原 RDD 中的 Key 组成一系列新的 KV 对。 举例 vala&#x3D;sc.parallelize(List((1,2),(3,4),(5,6))) valb&#x3D;a.flatMapValues(x&#x3D;&gt;1.to(x)) b.collect.foreach(println)</span><br><span class="line"></span><br><span class="line">## combineByKey</span><br><span class="line">&gt;def combineByKey[C](createCombiner: (V) &#x3D;&gt; C, mergeValue: (C, V) &#x3D;&gt; C, mergeCombiners: (C, C) &#x3D;&gt;C):RDD[(K,C)] def combineByKey[C](createCombiner: (V) &#x3D;&gt; C, mergeValue: (C, V) &#x3D;&gt; C, mergeCombiners: (C, C) &#x3D;&gt;C,numPartitions:Int):RDD[(K,C)] def combineByKey[C](createCombiner: (V) &#x3D;&gt; C, mergeValue: (C, V) &#x3D;&gt; C, mergeCombiners: (C, C) &#x3D;&gt; C, partitioner: Partitioner, mapSideCombine: Boolean &#x3D; true, serializer: Serializer &#x3D; null): RDD[(K,C)] 该函数用于将 RDD[K,V]转换成 RDD[K,C],这里的 V 类型和 C 类型可以相同也可以不同。 其中的参数： createCombiner：组合器函数，用于将 V 类型转换成 C 类型，输入参数为 RDD[K,V]中的 V,输 出为 C,分区内相同的 key 做一次 mergeValue：合并值函数，将一个C类型和一个V类型值合并成一个C类型， 输入参数为(C,V)， 输出为 C，分区内相同的 key 循环做 mergeCombiners：分区合并组合器函数，用于将两个 C 类型值合并成一个 C 类型，输入参数 为(C,C)，输出为 C，分区之间循环做 numPartitions：结果 RDD 分区数，默认保持原有的分区数 partitioner：分区函数,默认为 HashPartitioner mapSideCombine：是否需要在 Map 端进行 combine 操作，类似于 MapReduce 中的 combine， 默认为 true</span><br><span class="line">看下面例子：</span><br></pre></td></tr></table></figure><br>scala&gt;var rdd1=sc.makeRDD(Array((“A”,1),(“A”,2),(“B”,1),(“B”,2),(“C”,1)))<br>rdd1:org.apache.spark.rdd.RDD[(String,Int)]=ParallelCollectionRDD[64]atmakeRDDat:21<br>scala&gt;rdd1.combineByKey( | (v:Int)=&gt;v+””, | (c:String,v:Int)=&gt;c+”@”+v, | (c1:String,c2:String)=&gt;c1+”1),(B,1<em>” +c2//合并 C 类型和 C 类型，中间加$，返回 C(String) 其他参数为默认值。 最终，将 RDD[String,Int]转换为 RDD[String,String]。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">再看例子：</span><br></pre></td></tr></table></figure><br>rdd1.combineByKey( (v:Int)=&gt;List(v), (c:List[Int],v:Int)=&gt;v::c, (c1:List[Int],c2:List[Int])=&gt;c1:::c2 ).collect<br>res65:Array[(String,List[Int])]=Array((A,List(2,1)),(B,List(2,1)),(C,List(1))) 最终将 RDD[String,Int]转换为 RDD[String,List[Int]]。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">## foldByKey</span><br></pre></td></tr></table></figure><br>deffoldByKey(zeroValue:V)(func:(V,V)=&gt;V):RDD[(K,V)]<br>deffoldByKey(zeroValue:V,numPartitions:Int)(func:(V,V)=&gt;V):RDD[(K,V)]<br>deffoldByKey(zeroValue:V,partitioner:Partitioner)(func:(V,V)=&gt;V):RDD[(K,V)]<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">该函数用于 RDD[K,V]根据 K 将 V 做折叠、合并处理，其中的参数 zeroValue 表示先根据映射 函数将 zeroValue 应用于 V,进行初始化 V,再将映射函数应用于初始化后的 V.</span><br><span class="line">例子：</span><br></pre></td></tr></table></figure><br>scala&gt;varrdd1=sc.makeRDD(Array((“A”,0),(“A”,2),(“B”,1),(“B”,2),(“C”,1))) scala&gt;rdd1.foldByKey(0)(+).collect res75:Array[(String,Int)]=Array((A,2),(B,3),(C,1)) //将 rdd1 中每个 key 对应的 V 进行累加，注意 zeroValue=0,需要先初始化 V,映射函数为+操 //作，比如(“A”,0),(“A”,2)，先将 zeroValue 应用于每个 V,得到：(“A”,0+0),(“A”,2+0)，即： //(“A”,0),(“A”,2)，再将映射函数应用于初始化后的 V，最后得到(A,0+2),即(A,2)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">再看：</span><br></pre></td></tr></table></figure><br>scala&gt;rdd1.foldByKey(2)(+).collect res76:Array[(String,Int)]=Array((A,6),(B,7),(C,3)) //先将 zeroValue=2 应用于每个 V,得到：(“A”,0+2), (“A”,2+2)，即：(“A”,2), (“A”,4)，再将映射 函 //数应用于初始化后的 V，最后得到：(A,2+4)，即：(A,6)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">再看乘法操作：</span><br></pre></td></tr></table></figure><br>scala&gt;rdd1.foldByKey(0)(*).collect res77:Array[(String,Int)]=Array((A,0),(B,0),(C,0)) //先将 zeroValue=0 应用于每个 V,注意，这次映射函数为乘法，得到：(“A”,00),(“A”,20)， //即：(“A”,0),(“A”,0)，再将映射函//数应用于初始化后的 V，最后得到：(A,00)，即：(A,0) //其他 K 也一样，最终都得到了 V=0<br>scala&gt;rdd1.foldByKey(1)(_</em>).collect res78:Array[(String,Int)]=Array((A,0),(B,2),(C,1)) //映射函数为乘法时，需要将 zeroValue 设为 1，才能得到我们想要的结果。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">在使用 foldByKey 算子时候，要特别注意映射函数及 zeroValue 的取值。</span><br><span class="line"></span><br><span class="line">## reduceByKeyLocally</span><br><span class="line">&gt;defreduceByKeyLocally(func:(V,V)&#x3D;&gt;V):Map[K,V]</span><br><span class="line">该函数将 RDD[K,V]中每个 K 对应的 V 值根据映射函数来运算，运算结果映射到一个 Map[K,V] 中，而不是 RDD[K,V]。</span><br></pre></td></tr></table></figure><br>scala&gt;var rdd1=sc.makeRDD(Array((“A”,0),(“A”,2),(“B”,1),(“B”,2),(“C”,1)))<br>rdd1:org.apache.spark.rdd.RDD[(String,Int)]=ParallelCollectionRDD[91]atmakeRDDat:21<br>scala&gt;rdd1.reduceByKeyLocally((x,y)=&gt;x+y)<br>res90:scala.collection.Map[String,Int]=Map(B-&gt;3,A-&gt;2,C-&gt;1)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">## sample</span><br><span class="line">&gt;sample(withReplacement, fraction, seed):以指定的随机种子随机抽样出数量为fraction的数据，withReplacement表示是抽出的数据是否放回，true为有放回的抽样，false为无放回的抽样，seed用于指定随机数生成器种子。例子从RDD中随机且有放回的抽出50%的数据，随机种子值为3（即可能以1 2 3的其中一个起始值）</span><br></pre></td></tr></table></figure><br>Val red = sc.makeRDD(1 to 10)<br>Val sample = rdd.sample(true,0.4,.2)<br>``</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot; cla
      
    
    </summary>
    
    
    
      <category term="spark" scheme="http://levin-lee.github.io/tags/spark/"/>
    
  </entry>
  
  <entry>
    <title>spark-逻辑回归</title>
    <link href="http://levin-lee.github.io/2021/06/19/spark-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/"/>
    <id>http://levin-lee.github.io/2021/06/19/spark-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/</id>
    <published>2021-06-19T13:26:50.000Z</published>
    <updated>2021-12-02T17:10:57.120Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>代码实例<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line">import org.apache.log4j.&#123; Level, Logger &#125;</span><br><span class="line">import org.apache.spark.&#123; SparkConf, SparkContext &#125;</span><br><span class="line">import org.apache.spark.mllib.regression.LinearRegressionWithSGD</span><br><span class="line">import org.apache.spark.mllib.util.MLUtils</span><br><span class="line">import org.apache.spark.mllib.regression.LabeledPoint</span><br><span class="line">import org.apache.spark.mllib.linalg.Vectors</span><br><span class="line">import org.apache.spark.mllib.regression.LinearRegressionModel</span><br><span class="line"></span><br><span class="line">object LinearRegression &#123;</span><br><span class="line">  def main(args: Array[String]): Unit &#x3D; &#123;</span><br><span class="line">    &#x2F;&#x2F;  构建对象</span><br><span class="line">    val conf &#x3D; new SparkConf().setAppName(&quot;LinearRegressionWithSGD&quot;)</span><br><span class="line">    val sc &#x3D; new SparkContext(conf)</span><br><span class="line">    Logger.getRootLogger.setLevel(Level.WARN)</span><br><span class="line">    &#x2F;&#x2F; 读取样本数据（1）</span><br><span class="line">      val data_path1 &#x3D; &quot;&#x2F;Users&#x2F;lelingshan&#x2F;Downloads&#x2F;pandown&#x2F;MLlib机器学习&#x2F;数据&#x2F;lpsa.data&quot;</span><br><span class="line">      val data &#x3D; sc.textFile(data_path1)</span><br><span class="line">      val examples &#x3D; data.map&#123;line &#x3D;&gt;</span><br><span class="line">        val parts &#x3D; line.split(&#39;,&#39;)</span><br><span class="line">        LabeledPoint(parts(0).toDouble, Vectors.dense(parts(1).split(&#39; &#39;).map(_.toDouble)))</span><br><span class="line">      &#125;.cache()</span><br><span class="line">      val numExample &#x3D; examples.count()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 读取样本数据（1）</span><br><span class="line">&#x2F;&#x2F;    val data_path2 &#x3D; &quot;&#x2F;Users&#x2F;lelingshan&#x2F;Downloads&#x2F;pandown&#x2F;MLlib机器学习&#x2F;数据&#x2F;lpsa.data&quot;</span><br><span class="line">&#x2F;&#x2F;    val examples &#x3D; MLUtils.loadLibSVMFile(sc,data_path2).cache()</span><br><span class="line">&#x2F;&#x2F;    val numExample &#x3D; examples.count()</span><br><span class="line">    &#x2F;&#x2F; 新建线性回归模型，并设置参数</span><br><span class="line">    val numIterations &#x3D; 100</span><br><span class="line">    val stepSize &#x3D; 1</span><br><span class="line">    val miniBatchFraction &#x3D; 1.0</span><br><span class="line">    val model &#x3D; LinearRegressionWithSGD.train(examples,numIterations,stepSize,miniBatchFraction)</span><br><span class="line">    &#x2F;&#x2F; 对样本进行预测</span><br><span class="line">    val prediction &#x3D; model.predict(examples.map(_.features))</span><br><span class="line">    val predictionAndLabel &#x3D; prediction.zip(examples.map(_.label))</span><br><span class="line">    val print_predict &#x3D; predictionAndLabel.take(50)</span><br><span class="line">    println(&quot;prediction&quot;+&quot;\t&quot;+&quot;label&quot;)</span><br><span class="line">    for(i &lt;- 0 to print_predict.length-1)&#123;</span><br><span class="line">      println(print_predict(i)._1+&quot;\t&quot;+print_predict(i)._2)</span><br><span class="line">    &#125;</span><br><span class="line">    &#x2F;&#x2F; 进行测试误差</span><br><span class="line">    val loss &#x3D; predictionAndLabel.map&#123;</span><br><span class="line">        case(v,p) &#x3D;&gt; math.pow((v-p),2)&#125;.mean()</span><br><span class="line">    println(s&quot;Test RMSE &#x3D; $loss.&quot;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 模型保存</span><br><span class="line">&#x2F;&#x2F;    val ModelPath &#x3D; &quot;&#x2F;User&#x2F;Downloads&#x2F;pandown&#x2F;MLlib机器学习&#x2F;&quot;</span><br><span class="line">&#x2F;&#x2F;    model.save(sc,ModelPath)</span><br><span class="line">&#x2F;&#x2F;    val sameModel &#x3D; LinearRegressionModel.load(sc,ModelPath)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;-</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot; cla
      
    
    </summary>
    
    
    
      <category term="spark" scheme="http://levin-lee.github.io/tags/spark/"/>
    
      <category term="机器学习" scheme="http://levin-lee.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>spark-线性回归</title>
    <link href="http://levin-lee.github.io/2021/06/19/spark-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"/>
    <id>http://levin-lee.github.io/2021/06/19/spark-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/</id>
    <published>2021-06-19T13:24:24.000Z</published>
    <updated>2021-11-27T06:53:01.830Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>代码实例<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line">import org.apache.hadoop.util.XMLUtils</span><br><span class="line">import org.apache.log4j.&#123;Level, Logger&#125;</span><br><span class="line">import org.apache.spark.ml.classification.LogisticRegressionModel</span><br><span class="line">import org.apache.spark.mllib.classification.LogisticRegressionWithLBFGS</span><br><span class="line">import org.apache.spark.mllib.evaluation.MulticlassMetrics</span><br><span class="line">import org.apache.spark.mllib.util.MLUtils</span><br><span class="line">import org.apache.spark.&#123;SparkConf, SparkContext&#125;</span><br><span class="line">import org.apache.spark.mllib.regression.LabeledPoint</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">object LogisticRegression &#123;</span><br><span class="line">  def main(args: Array[String]): Unit &#x3D; &#123;</span><br><span class="line">    &#x2F;&#x2F;1 构建对象</span><br><span class="line">    val conf &#x3D; new SparkConf().setAppName(&quot;LogisticRegression&quot;)</span><br><span class="line">    val sc &#x3D; new SparkContext(conf)</span><br><span class="line">    Logger.getRootLogger.setLevel(Level.WARN)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F;2 读取样本数据，为libsvm格式</span><br><span class="line">    val  data &#x3D; MLUtils.loadLibSVMFile(sc,&quot;&#x2F;Users&#x2F;lelingshan&#x2F;Downloads&#x2F;pandown&#x2F;MLlib机器学习&#x2F;数据&#x2F;sample_libsvm_data.txt&quot;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F;3 处理样本数据</span><br><span class="line">    val splits &#x3D; data.randomSplit(Array(0.6,0.4),seed&#x3D;11L)</span><br><span class="line">    val training &#x3D; splits(0).cache()</span><br><span class="line">    val test &#x3D; splits(1)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 4 新建逻辑回归模型，并训练</span><br><span class="line">    val model &#x3D; new LogisticRegressionWithLBFGS().setNumClasses(10).run(training)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 5 对测试样本进行测试</span><br><span class="line">    val predictionAndLabels &#x3D; test.map&#123;</span><br><span class="line">      case LabeledPoint(label, features) &#x3D;&gt;</span><br><span class="line">        val prediction &#x3D; model.predict(features)</span><br><span class="line">        (prediction,label)</span><br><span class="line">    &#125;</span><br><span class="line">    val print_predict &#x3D; predictionAndLabels.take(20)</span><br><span class="line">    println(&quot;prediction&quot; + &quot;\t&quot; + &quot;label&quot;)</span><br><span class="line">    for (i &lt;- 0 to print_predict.length - 1)&#123;</span><br><span class="line">      println(print_predict(i)._1+&quot;\t&quot;+print_predict(i)._2)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 6 计算误差</span><br><span class="line">    val metrics &#x3D; new MulticlassMetrics(predictionAndLabels)</span><br><span class="line">    val precision &#x3D; metrics.precision</span><br><span class="line">    println(&quot;Precision &#x3D; &quot; + precision)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;    &#x2F;&#x2F; 7保存模型</span><br><span class="line">&#x2F;&#x2F;    val ModelPath &#x3D; &quot;&quot;</span><br><span class="line">&#x2F;&#x2F;    model.save(sc,ModelPath)</span><br><span class="line">&#x2F;&#x2F;    val sameModel &#x3D; LogisticRegressionModel.load(sc,ModelPath)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot; cla
      
    
    </summary>
    
    
    
      <category term="spark" scheme="http://levin-lee.github.io/tags/spark/"/>
    
      <category term="机器学习" scheme="http://levin-lee.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>模型评估</title>
    <link href="http://levin-lee.github.io/2021/05/29/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/"/>
    <id>http://levin-lee.github.io/2021/05/29/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/</id>
    <published>2021-05-29T03:56:18.000Z</published>
    <updated>2021-12-02T17:09:35.361Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>模型评估是验证模型准确率最重要的一步，常用的模型评估指标有AUC、ROC、精准率、召回率、KS、lift、模型稳定性PSI等。此外还可以利用F检验来验证模型是否显著的统计性假设检验。<br><strong> 1、ROC（接受者操作曲线）</strong><br><strong> 2、AUC </strong><br>AUC的物理意义伟ROC曲线下的面积，一般情况下AUC越大，表示的模型的效果越好。AUC主要由两部分所影响。</p><ul><li>精准率</li><li>召回率</li></ul><p><strong> 3、KS </strong><br>KS金融模型评估领域中运用十分广泛，尤其在信贷行业，它可以验证模型区分好人坏人的能力，KS<br>计算公式为：ks = max(Cum.Bi/Bad_total - Cum.Gi/Good_total)<br>计算KS的代码如下：<br>法一：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from scipy.stats import ks_2samp</span><br><span class="line"> </span><br><span class="line">get_ks &#x3D; lambda y_pred,y_true: ks_2samp(y_pred[y_true&#x3D;&#x3D;1], y_pred[y_true!&#x3D;1]).statistic</span><br><span class="line"> </span><br><span class="line">get_ks(x,y)</span><br></pre></td></tr></table></figure></p><p>法二：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">Import pandas as pd</span><br><span class="line">Import numpy as np</span><br><span class="line">From sklearn.metrics import roc_curve</span><br><span class="line">From spicy.stats import ks_2samp</span><br><span class="line"></span><br><span class="line">def ks_calc_cross(data,pred,y_label):</span><br><span class="line">    &#39;&#39;&#39;</span><br><span class="line">    功能: 计算KS值，输出对应分割点和累计分布函数曲线图</span><br><span class="line">    输入值:</span><br><span class="line">    data: 二维数组或dataframe，包括模型得分和真实的标签</span><br><span class="line">    pred: 一维数组或series，代表模型得分（一般为预测正类的概率）,已经分成10个区间分数</span><br><span class="line">    y_label: 一维数组或series，代表真实的标签（&#123;0,1&#125;或&#123;-1,1&#125;）</span><br><span class="line">    输出值:</span><br><span class="line">    &#39;ks&#39;: KS值，&#39;crossdens&#39;: 好坏客户累积概率分布以及其差值gap</span><br><span class="line">    &#39;&#39;&#39;</span><br><span class="line">    crossfreq &#x3D; pd.crosstab(data[pred[0]],data[y_label[0]])</span><br><span class="line">    crossdens &#x3D; crossfreq.cumsum(axis&#x3D;0) &#x2F; crossfreq.sum()</span><br><span class="line">    crossdens[&#39;gap&#39;] &#x3D; abs(crossdens[0] - crossdens[1])</span><br><span class="line">    ks &#x3D; crossdens[&#39;gap&#39;].max()</span><br><span class="line">    </span><br><span class="line">    return ks,crossdens</span><br></pre></td></tr></table></figure></p><p><strong> 4、模型稳定性PSI </strong><br>稳定性指标(populations stability index,PSI)可衡量测试样本及模型开发样本评分的分布差异。PSI表示按分数分档后，针对不同时间样本，population分布是否有变化，就是看各个分数区间内人数占总人数占比是否有显著变化。<br>计算公式为：PSI = sum[(Ac - Ex)*LN(Ac/Ex)]，其中Ac：表示分数区间实际的比例，Ex：表示分数区间预期的比例，也可以是之前模型分数区间的比例。<br>小于10%，无需更新模型；<br>10%-25%：检查一下其他度量方式<br>大于25%：需要更新模型</p><p><strong> 5、lift </strong><br>lift也是一种评估模型或者单个强变量是否区分好人坏人有效性的指标，与IV类似，做法是将模型分或者变量切割成几个区间，分别计算各个区间内的放款逾期率和金额逾期率，将各个区间的逾期率除于大盘的逾期率，就可以得到lift，我们俗称梯度。如果lift呈递增或者递减，我们就可以说模型是有效的，lift增长或者下降越快，则模型区分好人和坏人的效果越好。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot; cla
      
    
    </summary>
    
    
    
      <category term="模型" scheme="http://levin-lee.github.io/tags/%E6%A8%A1%E5%9E%8B/"/>
    
  </entry>
  
  <entry>
    <title>2020年终总结</title>
    <link href="http://levin-lee.github.io/2021/02/01/2020%E5%B9%B4%E7%BB%88%E6%80%BB%E7%BB%93/"/>
    <id>http://levin-lee.github.io/2021/02/01/2020%E5%B9%B4%E7%BB%88%E6%80%BB%E7%BB%93/</id>
    <published>2021-02-01T03:48:49.000Z</published>
    <updated>2021-11-07T14:47:21.807Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>2020年临近尾声，我也不能免俗，感觉是时候对自己这一年发个总结，不管是好是坏，也是我经历的人<br>生呀：<br>这一年发生了很多事情，现在想想都感觉很梦幻。</p><ul><li>1.家属患了淋巴瘤，目前还在化疗中;</li><li>2.从北漂转变为深漂，换了工作和地点，不变的是独孤的心;</li><li>3.交了女朋友，然后迅速就分了;</li><li>4.贯穿全年的新冠疫情;</li><li>5.股市</li></ul><p>当我知道听我爸说去医院看病的时候，起初我还不以为意，只道是平常的肿大，看看病吃吃药，修养几天就好，但万万没想到化验结果让我傻眼，竟然是淋巴瘤，顿时晴天霹雳，惆怅不已，根本没想到我爸还会得病，他身体那么好，怎么就突然得了淋巴瘤了呢。后来他自己透露，每天干活接触很多刺鼻性化学物质。我一直认为中国的农民是很傻的一群人，只知道拼命干最苦最累最脏的活赚钱，莫不知，当你身体被折磨到累倒后，你赚的钱远远无法满足治疗费用，这就是一笔不能做的买卖，但大多人永远也想不到这一点。化疗是个很痛苦的过程，全身插满管子，6次疗程，治疗费用高昂，而我却无能为力，治愈率也不清楚，还是自己太无能，什么忙也帮不上。</p><p>20年，我换了城市，换了工作。好像一起都往更好的方向发展，欣欣向荣。但只有自己知道，一切其实也没有改变，只是把身份从北漂改成了深漂，一样的漂泊居无定所，一样的孤独感。在大城市没有一套属于自己的房子，太辛苦了。</p><p>从北京到深圳，很大原因是因为前女友过来的，不过挺感谢她让我成长，让我学会如何很好地区恋爱，如何保持一个比较良好的沟通，给彼此独立的空间。</p><p>财富自由一直是我毕生所追求的目标，但是能让我财富自由的手段寥寥无几，投资可能是目前唯一能让我看清的方向，我希望通过投资来创造我的财富。股票又是投资中相对没有门槛的，每个人只要开户就可以直接参与。20年是个小爆发的牛市，完全没有被疫情所影响的现象。但是就是这样的牛市，却让我亏钱了，基金赚的都要比自己投资多的多，深刻地感觉自己的投资股票能力，亟待提高。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot; cla
      
    
    </summary>
    
    
    
      <category term="感悟" scheme="http://levin-lee.github.io/tags/%E6%84%9F%E6%82%9F/"/>
    
  </entry>
  
  <entry>
    <title>读平凡的世界有感</title>
    <link href="http://levin-lee.github.io/2020/10/18/%E8%AF%BB%E5%B9%B3%E5%87%A1%E7%9A%84%E4%B8%96%E7%95%8C%E6%9C%89%E6%84%9F/"/>
    <id>http://levin-lee.github.io/2020/10/18/%E8%AF%BB%E5%B9%B3%E5%87%A1%E7%9A%84%E4%B8%96%E7%95%8C%E6%9C%89%E6%84%9F/</id>
    <published>2020-10-18T11:11:31.000Z</published>
    <updated>2020-10-18T11:16:57.552Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>我真正的读书历程要从高中开始。很不幸，刚开始接触小说时，就接触了郭敬明和饶雪漫的一系列伤痛青春文学，代表作有《夏至未至》、《悲伤逆流成河》、《离歌》等，曾经一度对那浮藻堆砌的文字深深着迷，差点没把我的思想带偏。等到大学的时候，这个时候有比较明显的风格转变，从青春小说如《草样年华》、到修仙类如《诛仙》、再到金庸古龙的武侠小说，最后再到近现代现实主义文学《白鹿原》、《平凡的世界》等经典著作，感觉自己读书的层次有了明显的提升，更多地考虑是否能从一本书中汲取营养。</p><p>今天就来聊一聊《平凡的世界》，其实这本书在大学的时候就看过了，一直搁置到现在才写观后感也是因为借着这个博客写点东西。从我看到这本书开始，我几乎是一口气读完这本小说，真的是太精彩。这本书不仅能让你去了解那段尘封的历史，感受历史的厚重感，也能从书中角色中看到自己的影子。</p><p>我曾对她不知一次极力推荐这本书。我一直认为，她和田晓霞是高度匹配的一个人，她独立、坚强、热情似火、高雅而不高傲，具有女性一切的美好品质。当我深入读着这本书的时候，不知不觉，脑海中中田晓霞的形象和她渐渐重合，直至完全融合，眼前浮现着她的面容。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot; cla
      
    
    </summary>
    
    
    
      <category term="感悟" scheme="http://levin-lee.github.io/tags/%E6%84%9F%E6%82%9F/"/>
    
      <category term="读书" scheme="http://levin-lee.github.io/tags/%E8%AF%BB%E4%B9%A6/"/>
    
  </entry>
  
  <entry>
    <title>我的南漂</title>
    <link href="http://levin-lee.github.io/2020/10/18/%E6%88%91%E7%9A%84%E5%8D%97%E6%BC%82/"/>
    <id>http://levin-lee.github.io/2020/10/18/%E6%88%91%E7%9A%84%E5%8D%97%E6%BC%82/</id>
    <published>2020-10-18T11:05:58.000Z</published>
    <updated>2020-10-18T11:10:29.977Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>时间不甚让人唏嘘不已。时隔一年，在今年的6月份，我摆脱了北漂的身份，马上投入深圳的怀抱，变成了一名地道的南漂青年。或许，也已经不能叫青年，应该正式步入了中年。回首过去一年，我急于摆脱北京这座城市，没有沉下心来，领略它的美。每个周末，我待在自己的出租屋内，翻看着面试技巧，学习面试必备技能，沉浸在自己的世界中，从未主动去探索认识新的朋友，忽略了也很多。而在我已经拿到offer之后，我才认识了我的学姐，带我去社交，我很感激，但已经太迟了，我已经决定离开北京这座城市。短短一年，我在上家公司，丝毫没有积累、没有沉淀，在我带着一些概念性的东西离开时，我才痛心疾首地发现，我离真正掌握核心技术还差得很远。但也只能这样了。</p><p>现在的我进入了一家头部互联网公司，从事着和上家工作毫无关联的业务，每天矜矜业业，熟悉业务、熟悉同事、熟悉新公司的所有一切。每天忙碌着，身体却异常疲惫，不太明白每天忙忙碌碌的意义在哪里，还是在做着重复窃机械性的工作。好在渐渐适应了周遭的一切，慢慢开始改善。然而，还是在大城市中，还有漂泊感，可能是我之前把深圳想的太好了。</p><p>这段时间发生了太多的事情，我交了个女朋友，短短两个月之后我们分手了。她以一句性格不合为由，我接受了，互道了珍重。</p><p>我是个怀旧的人。当你沉浸其中某一事物时，可能你已习惯它的存在，不会太有过多的好感，领略不了对方的美。但当你在一个事物或者人身上倾注过时间和情感后，一旦发生脱离，发现其实是无法那么轻易割舍的，无论是城市也好，还是女朋友，都会有些许怀念。或许，也仅剩怀念而已。</p><p>生活还将继续，我需要好好思考，我想要什么、我想成为什么样的人，我是否会为了留在深圳而苦苦挣扎，亦或者回归厦门，开启另一段生活，现在的我还不得而已，恐怕只有时间会给我答案。</p>]]></content>
    
    <summary type="html">
    
      描写南漂的生活
    
    </summary>
    
    
    
      <category term="感悟" scheme="http://levin-lee.github.io/tags/%E6%84%9F%E6%82%9F/"/>
    
      <category term="南漂" scheme="http://levin-lee.github.io/tags/%E5%8D%97%E6%BC%82/"/>
    
  </entry>
  
  <entry>
    <title>hive操作</title>
    <link href="http://levin-lee.github.io/2020/10/11/hive%E6%93%8D%E4%BD%9C/"/>
    <id>http://levin-lee.github.io/2020/10/11/hive%E6%93%8D%E4%BD%9C/</id>
    <published>2020-10-11T13:02:40.000Z</published>
    <updated>2021-11-27T07:12:09.856Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p><strong>创建数据库例子</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; create database if not exists user_db;</span><br></pre></td></tr></table></figure></p><p><strong>查看数据库定义</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; describe database user_db;</span><br></pre></td></tr></table></figure></p><p><strong>查看数据库列表</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; show databases;</span><br></pre></td></tr></table></figure></p><p><strong>删除数据库</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; drop database if exists testdb cascade;</span><br></pre></td></tr></table></figure></p><p><strong>切换当前数据库</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; use user_db;</span><br></pre></td></tr></table></figure></p><p><strong>创建普通表</strong><br>1)第一种<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; create table if not exists userinfo  </span><br><span class="line">    (</span><br><span class="line">    userid int,</span><br><span class="line">    username string,</span><br><span class="line">    cityid int,</span><br><span class="line">    createtime date    </span><br><span class="line">    )</span><br><span class="line">    row format delimited fields terminated by &#39;\t&#39;</span><br><span class="line">    stored as textfile;</span><br></pre></td></tr></table></figure><br>row format delimited fields terminated by ‘\t’ 是指定列之间的分隔符；stored as textfile是指定文件存储格式为textfile。</p><p>2）第二种<br>create table as select 方式：根据查询的结果自动创建表，并将查询结果数据插入新建的表中。<br>3）第三种<br>create table like tablename1 方式：是克隆表，只复制tablename1表的结构。复制表和克隆表会在下面的Hive数据管理部分详细讲解。</p><p><strong>创建外部表</strong><br>外部表是没有被hive完全控制的表，当表删除后，数据不会被删除。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; create external table iislog_ext (</span><br><span class="line">    ip string,</span><br><span class="line">    logtime string    </span><br><span class="line">    );</span><br></pre></td></tr></table></figure></p><p><strong>创建分区表</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">create table user_action_log</span><br><span class="line">(</span><br><span class="line">companyId INT comment   &#39;公司ID&#39;,</span><br><span class="line">userid INT comment   &#39;销售ID&#39;,</span><br><span class="line">originalstring STRING comment   &#39;url&#39;, </span><br><span class="line">)</span><br><span class="line">partitioned by (dt string)</span><br><span class="line">row format delimited fields terminated by &#39;,&#39;</span><br><span class="line">stored as textfile;</span><br></pre></td></tr></table></figure></p><p><strong>创建桶表</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">create table user_leads</span><br><span class="line">(</span><br><span class="line">leads_id string,</span><br><span class="line">user_id string,</span><br><span class="line">user_id string,</span><br><span class="line">user_phone string,</span><br><span class="line">user_name string,</span><br><span class="line">create_time string</span><br><span class="line">)</span><br><span class="line">clustered by (user_id) sorted by(leads_id) into 10 buckets </span><br><span class="line">row format delimited fields terminated by &#39;\t&#39; </span><br><span class="line">stored as textfile;</span><br></pre></td></tr></table></figure></p><p><strong>查看简单定义</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">describe userinfo;</span><br></pre></td></tr></table></figure></p><p><strong>查看表详细信息</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">describe formatted userinfo;</span><br></pre></td></tr></table></figure></p><p><strong>修改表名</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alter table userinfo rename to user_info;</span><br></pre></td></tr></table></figure></p><p><strong>添加字段</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alter table user_info add columns (provinceid int );</span><br></pre></td></tr></table></figure></p><p><strong>修改字段</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alter table user_info replace columns (userid int,username string,cityid int,joindate date,provinceid int);</span><br></pre></td></tr></table></figure></p><p>将本地文本文件内容批量加载到Hive表中：<br>——要求文本文件中的格式和Hive表的定义一致<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">load data local inpath &#39;&#x2F;home&#x2F;hadoop&#x2F;userinfodata.txt&#39; overwrite into table user_info;</span><br></pre></td></tr></table></figure></p><p><strong>加载到分区表</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">load data local inpath &#39;&#x2F;home&#x2F;hadoop&#x2F;actionlog.txt&#39; overwrite into table user_action_log PARTITION (dt&#x3D;&#39;2017-05-26’);</span><br></pre></td></tr></table></figure></p><p><strong>导入分桶表</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">set hive.enforce.bucketing &#x3D; true;</span><br><span class="line">insert overwrite table user_leads select * from  user_leads_tmp;</span><br></pre></td></tr></table></figure></p><p><strong>导出数据</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">insert overwrite local directory &#39;&#x2F;home&#x2F;hadoop&#x2F;user_info.bak2016-08-22 &#39;</span><br><span class="line">select * from user_info;</span><br></pre></td></tr></table></figure></p><p><strong>插入数据的表是分区表</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">insert overwrite table user_leads PARTITION (dt&#x3D;&#39;2017-05-26&#39;) </span><br><span class="line">select * from  user_leads_tmp;</span><br></pre></td></tr></table></figure></p><p><strong>复制表</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">create table user_leads_bak</span><br><span class="line">row format delimited fields terminated by &#39;\t&#39;</span><br><span class="line">stored as textfile</span><br><span class="line">as</span><br><span class="line">select leads_id,user_id,&#39;2016-08-22&#39; as bakdate</span><br><span class="line">from user_leads</span><br><span class="line">where create_time&lt;&#39;2016-08-22’;</span><br></pre></td></tr></table></figure></p><p><strong>克隆表</strong><br>——克隆表时会克隆源表的所有元数据信息，但是不会复制源表的数据<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">create table user_leads_like like  user_leads;</span><br></pre></td></tr></table></figure></p><div class="table-container"><table><thead><tr><th style="text-align:left">操作符</th><th style="text-align:left">说明</th><th style="text-align:left">操作符</th><th style="text-align:left">说明</th></tr></thead><tbody><tr><td style="text-align:left">A=B</td><td style="text-align:left">A等于B就返回true，适用于各种基本类型</td><td style="text-align:left">A&lt;=&gt;B</td><td style="text-align:left">都为Null则返回True，其他和=一样</td></tr><tr><td style="text-align:left">A&lt;&gt;B</td><td style="text-align:left">不等于</td><td style="text-align:left">A!=B</td><td style="text-align:left">不等于</td></tr><tr><td style="text-align:left">A&lt;=B</td><td style="text-align:left">小于等于</td><td style="text-align:left">A&gt;B</td><td style="text-align:left">大于</td></tr><tr><td style="text-align:left">A&gt;=B</td><td style="text-align:left">大于等于</td><td style="text-align:left">A Between B And C</td><td style="text-align:left">筛选A的值处于B和C之间</td></tr><tr><td style="text-align:left">A Not Between B And C</td><td style="text-align:left">筛选A的值不处于B和C之间</td><td style="text-align:left">A Is NULL</td><td style="text-align:left">筛选A是NULL的</td></tr><tr><td style="text-align:left">A Is Not NULL</td><td style="text-align:left">筛选A值不是NULL的</td><td style="text-align:left">A Link B</td><td style="text-align:left">%一个或者多个字字符</td></tr><tr><td style="text-align:left">A Not Like B</td><td style="text-align:left">%一个或者多个字符_一个字符</td><td style="text-align:left">A RLike B</td><td style="text-align:left">正则匹配</td></tr></tbody></table></div><p><strong>排序</strong><br>Sort By——Hive中尽量不要用Order By，除非非常确定结果集很小<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from user_leads sort by user_id</span><br></pre></td></tr></table></figure></p><h2 id="日期函数"><a href="#日期函数" class="headerlink" title="日期函数"></a>日期函数</h2><p>1、UNIX时间戳转日期函数：from_unixtime<br>转化UNIX时间戳（从1970-01-01 00:00:00 UTC到指定时间的秒数）到当前时区的时间格式<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; select from_unixtime(1323308943,&#39;yyyyMMdd&#39;) fromlxw_dual;</span><br></pre></td></tr></table></figure></p><p>2、日期时间转日期函数：to_date<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; select to_date(&#39;2011-12-08 10:03:01&#39;) from lxw_dual;</span><br></pre></td></tr></table></figure></p><p>3、日期转年\月\日函数：year——month——day<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; select year(&#39;2011-12-08 10:03:01&#39;) from lxw_dual;</span><br></pre></td></tr></table></figure></p><p>4、日期比较函数：datediff<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; select datediff(&#39;2012-12-08&#39;,&#39;2012-05-09&#39;) from lxw_dual;</span><br></pre></td></tr></table></figure></p><p>5、日期增加、减少函数：date_add/date_sub<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; select date_add(&#39;2012-12-08&#39;,10) from lxw_dual;</span><br></pre></td></tr></table></figure></p><h2 id="字符串函数"><a href="#字符串函数" class="headerlink" title="字符串函数"></a>字符串函数</h2><p>1、字符串反转函数：reverse<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; select reverse(abcedfg’) from lxw_dual;</span><br></pre></td></tr></table></figure></p><p>2、字符串连接函数：concat<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; select concat(‘abc’,&#39;def’,&#39;gh’) from lxw_dual;</span><br></pre></td></tr></table></figure></p><p>3、带分隔符连接函数：concat_ws<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; select concat_ws(&#39;,&#39;,&#39;abc&#39;,&#39;def&#39;,&#39;gh&#39;) from lxw_dual;</span><br></pre></td></tr></table></figure></p><p>4、字符串截取函数：substr、substring<br>返回字符串A从start位置到结尾的字符串<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; select substr(&#39;abcde&#39;,3) from lxw_dual;</span><br></pre></td></tr></table></figure></p><p>5、字符串转大写和小写：upper、ucase / lower、lcase<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select lcase(&#39;abSEd&#39;) from lxw_dual;</span><br></pre></td></tr></table></figure></p><p>6、去空格函数<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; select trim(&#39; abc &#39;) from lxw_dual;</span><br></pre></td></tr></table></figure></p><p>7、正则表达式替代函数：regexp_replcae<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; select regexp_replace(&#39;foobar&#39;, &#39;oo|ar&#39;, &#39;&#39;) from lxw_dual;</span><br></pre></td></tr></table></figure></p><p>8、json解析函数：get_json_object<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">get_json_object(string json_string, string path)</span><br></pre></td></tr></table></figure><br>9、分隔字符串函数：split 返回数组<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; select split(&#39;abtcdtef&#39;,&#39;t&#39;) from lxw_dual;</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      Hive的基本用法
    
    </summary>
    
    
    
      <category term="hive" scheme="http://levin-lee.github.io/tags/hive/"/>
    
      <category term="编程" scheme="http://levin-lee.github.io/tags/%E7%BC%96%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>linux之shell</title>
    <link href="http://levin-lee.github.io/2020/08/25/linux%E4%B9%8Bshell/"/>
    <id>http://levin-lee.github.io/2020/08/25/linux%E4%B9%8Bshell/</id>
    <published>2020-08-25T12:08:03.000Z</published>
    <updated>2020-10-11T12:57:11.605Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><blockquote><p>$# 是传给脚本的参数个数<br>$0 是脚本本身的名字<br>$1 是传递给该shell脚本的第一个参数<br>$2 是传递给该shell脚本的第二个参数<br>$@ 是传给脚本的所有参数的列表<br>$* 是以一个单字符串显示所有向脚本传递的参数，与位置变量不同，参数可超过9个</p><p>$$ 是脚本运行的当前进程ID号<br>$? 是显示最后命令的退出状态，0表示没有错误，其他表示有错误</p></blockquote><h2 id="1-if-then语句"><a href="#1-if-then语句" class="headerlink" title="1. if-then语句"></a>1. if-then语句</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">if test command</span><br><span class="line">then commands</span><br><span class="line">else commands</span><br><span class="line">fi</span><br></pre></td></tr></table></figure><p>test检测：<br>数字<br>n1 -eq n2 检查n1是否与n2相等<br>n1 -ge n2 检查n1是否大于或等于n2<br>n1 -gt n2 检查n1是否大于n2<br>n1 -le n2 检查n1是否小于或等于n2<br>n1 -lt n2 检查n1是否小于n2<br>n1 -ne n2 检查n1是否不等于n2</p><p>字符串<br>-n str1 检查str1的长度是否非0<br>-z str1 检查str1的长度是否为0</p><h2 id="2-for循环"><a href="#2-for循环" class="headerlink" title="2. for循环"></a>2. for循环</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">for var in list do</span><br><span class="line">commands</span><br><span class="line">done</span><br></pre></td></tr></table></figure><p>例子：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">file&#x3D;“states”</span><br><span class="line">IFS&#x3D;$&#39;\n’   #能读空行的值</span><br><span class="line">for state in $(cat $file)</span><br><span class="line">do</span><br><span class="line">   echo &quot;Visit beautiful $state&quot;</span><br><span class="line">done</span><br></pre></td></tr></table></figure><br>跳出循环：break、continue</p><h2 id="3-创建函数"><a href="#3-创建函数" class="headerlink" title="3. 创建函数"></a>3. 创建函数</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">function name &#123; commands</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="高级函数"><a href="#高级函数" class="headerlink" title="高级函数"></a>高级函数</h1><h2 id="4-sed命令"><a href="#4-sed命令" class="headerlink" title="4. sed命令"></a>4. sed命令</h2><p>Sed编辑器被称为流编辑器，与普通的交互式文本编辑器想法。<br>1）在命令行定义编辑器<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ Echo “this is a test” | sed ’s&#x2F;test&#x2F;big test’</span><br></pre></td></tr></table></figure><br>This is a big test<br>或者<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Sed ’s&#x2F;dog&#x2F;cat&#x2F;‘ data.txt</span><br></pre></td></tr></table></figure><br>Sed编辑器并不会修改文本文件的数据<br>2）在命令行使用多个编辑器<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Sed -e ’s&#x2F;brown&#x2F;green&#x2F;; s&#x2F;dog&#x2F;cat’ data.txt</span><br></pre></td></tr></table></figure><br>必须要用；分割<br>3）从文件中读取编辑器命令<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Sed -f script1.sed datat.txt</span><br></pre></td></tr></table></figure><br>4）写入文件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Sed ‘1,2w test.txt’ datat.txt</span><br></pre></td></tr></table></figure><br>将test.txt文件的前两行打印到data.txt文件中</p><p>5、awk命令<br>1）格式化输出<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">awk &#39;&#123;printf &quot;%-8s %-10s\n&quot;,$1,$4&#125;&#39; log.txt</span><br><span class="line">&#96;&#96;</span><br><span class="line">2）使用，分割</span><br><span class="line">&#96;&#96;&#96;linux</span><br><span class="line">awk &#39;BEGIN&#123;FS&#x3D;&quot;,&quot;&#125; &#123;print $1,$2&#125;&#39;  log.txt</span><br></pre></td></tr></table></figure><br>3）条件语句<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">awk &#39;BEGIN &#123;</span><br><span class="line">    num &#x3D; 11; </span><br><span class="line">    if (num % 2 &#x3D;&#x3D; 0) printf &quot;%d 是偶数\n&quot;, num; </span><br><span class="line">    else printf &quot;%d 是奇数\n&quot;, num </span><br><span class="line">&#125;&#39;</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      学习shell的一些笔记
    
    </summary>
    
    
      <category term="shell" scheme="http://levin-lee.github.io/categories/shell/"/>
    
    
      <category term="编程" scheme="http://levin-lee.github.io/tags/%E7%BC%96%E7%A8%8B/"/>
    
      <category term="linux" scheme="http://levin-lee.github.io/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>投资观</title>
    <link href="http://levin-lee.github.io/2020/08/21/%E6%8A%95%E8%B5%84%E8%A7%82/"/>
    <id>http://levin-lee.github.io/2020/08/21/%E6%8A%95%E8%B5%84%E8%A7%82/</id>
    <published>2020-08-21T12:00:15.000Z</published>
    <updated>2021-12-02T17:12:21.354Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>人的一生都是不断投资自己的一个过程，投资是一辈子的事情，任何人都应该去学会投资。这里的投资并不是狭隘地指投资股票、债券等二级市场的行为，它也可以掌握理财或者更单纯地投资自己，花费时间看我一本书是投资、投入精力学习一项新技术也是投资。对于投资，我有几点想法，可以和大家一起交流。</p><h2 id="1、任何时候，投资的首要目标都是先投资自己"><a href="#1、任何时候，投资的首要目标都是先投资自己" class="headerlink" title="1、任何时候，投资的首要目标都是先投资自己"></a>1、任何时候，投资的首要目标都是先投资自己</h2><p>为什么投资的首要目标是投资自己？不要认为投资都是将钱投到金融市场中，投资自己比其他任何投资都更有意义。那么该如何正确投资自己，每天保持不断学习，付出时间和精力，每天坚持看几本书，培养自己的兴趣爱好，和喜欢的人交谈，花钱培养一项新技能，这些都是可以让你受益匪浅的投资，将会伴随你的一生。任何适合，投资自己永远是一项正确的决定。投资自己，永远不要怕多晚。</p><h2 id="2、不断学习、努力工作"><a href="#2、不断学习、努力工作" class="headerlink" title="2、不断学习、努力工作"></a>2、不断学习、努力工作</h2><p>学习是最有价值的一项投资，这是一条准则。古今中外，莫不如是。不会学习的人，只会固步自封，止步不前，只停留在同一层思想到老，是很可悲的一件事。学习不仅可以使我们获得前人宝贵的经验，也可以让我们规避他们所犯过的错误，所谓以史明鉴。</p><p>现在的我们工作是为了获取原始的积累，只有足够的原始积累，你才能有资本去做你想做的事情。现在你努力工作是为了更好的明天。别抱怨工作，学会去接受它、喜欢它，或许你也可以在工作上实现你人生的价值。</p><h2 id="3、构建适合自己的投资逻辑"><a href="#3、构建适合自己的投资逻辑" class="headerlink" title="3、构建适合自己的投资逻辑"></a>3、构建适合自己的投资逻辑</h2><p>投资的门派很多，根据金融市场不同可以分为一级市场的PE、VC，和二级市场流通市场；根据产品的不同可以分为债券、股票、汇率、期权、期货等派别；按照投资行为又分为投资者、投机者、套利者。在这纷扰繁杂的金融市场中，要构建属于自己的投资逻辑，形成自己的投资理念，否则随波逐流投机赚的钱，总又一天会以同样的形式流出。</p><h2 id="4、付诸实践，不断试错"><a href="#4、付诸实践，不断试错" class="headerlink" title="4、付诸实践，不断试错"></a>4、付诸实践，不断试错</h2><p>有人说，“年轻人要用于去尝试，不要害怕出错；到老了，犯错误的成本就会很高”。这句话是很有道理的，尤其是在投资界。年轻时，你的资本比较小，亏损了大不了，你还可以重新来过，你还年轻，还有大把的时间可以奋斗，但是当你老了，你已经没有能力或者精力去靠工作赚钱，这时候投资发生损失对于老年生活质量会大大打个折扣。所以，趁年轻，不断去试错，从失败中汲起教训，要么早点认清自己不适合投资，将时间放在更有价值、更合适的地方；要么坚持下去，不断修正自己的投资，完善投资框架，体验投资给你带来的财富增值。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot; cla
      
    
    </summary>
    
    
    
      <category term="感悟" scheme="http://levin-lee.github.io/tags/%E6%84%9F%E6%82%9F/"/>
    
      <category term="投资" scheme="http://levin-lee.github.io/tags/%E6%8A%95%E8%B5%84/"/>
    
  </entry>
  
  <entry>
    <title>我的北漂</title>
    <link href="http://levin-lee.github.io/2020/08/21/%E6%88%91%E7%9A%84%E5%8C%97%E6%BC%82/"/>
    <id>http://levin-lee.github.io/2020/08/21/%E6%88%91%E7%9A%84%E5%8C%97%E6%BC%82/</id>
    <published>2020-08-21T11:50:42.000Z</published>
    <updated>2020-10-18T11:09:55.760Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>最初开通github是打算写点技术文章，现在更像是我的记事本，时不时也需要记录下我对生活的感悟。<br>谈到北漂，以前一直以为与我无关，是很虚无飘渺的东西，因为我的目标城市是深圳或者上海。没想到阴差阳错最终来到北京。从去年19年的7月开始，我正式开启了我的北漂之旅，再过两个月就整整一年了。在这里我挥洒汗水，耗费青春的光阴而碌碌无为，忙忙碌碌且无成长，我常痛恨这样的自己。</p><h2 id="工作篇"><a href="#工作篇" class="headerlink" title="-工作篇-"></a>-工作篇-</h2><p>我工作的地方是被誉为中国互联网届的摇篮村，名叫后场村。我居住的地方也是人均程序员密度最高的西二旗。和我一起居住的还有我的两个研究生同学，和一个同事。另外还有一个是我校友的同事，一共五个人同租，后来成为我校友的女朋友，那是后话了。刚开始工作的三个月中，确实我成长最快的时候，这里要实名感谢@彩旭对我的帮助，我要是有计算机的问题基本都去找他，他也乐意帮忙，在他的帮助下，我才能快速上手linux，这个博客也是在他的影响下而开通的。而在业务层面，@子鹏对我的帮助较大。总之，前三个月是成长最快的时候，后续的工作其实都是在重复工作，没有自己的想法，只是一味地执行领导交代的任务。刚来这家公司最让我不习惯的是，内部没有很明确对校招生的培养机制，前辈写分享文档的也很少，所以需要自己一点点去琢磨，我想要是部门有完善的培养机制，应该能让我更快地上手吧。还有一个让我比较诡异的事情是。内部的分享沟通会很少，每个小组都在埋头干自己的工作，小组之间比较少交流，而且甚至部分小组藏着掖着，不想让其他组知道自己所做的事情，其他小组也无从介入，以保证自己的一个项目的绝对领导地位。<br>其他方面，由于部门是风控部门，是整个信贷产品的核心。所以，接触的面会广一些，会进行跨部门协同。这一块，需要不断地扯皮，才能推动业务进展，不过这一块，我想其他公司也该差不多吧。<br>公司的问题之下，也同时暴露了我的问题了，在工作中很粗心，经常计算出错，对待工作比较散漫，效率低下。这一块还是需要不断地磨合自己，历练自己。</p><h2 id="生活篇"><a href="#生活篇" class="headerlink" title="-生活篇-"></a>-生活篇-</h2><p>前面谈到我们是5个人同租房子。正所谓有人的地方就有江湖，从一开始的其乐融融，一片欢声笑语，到最后充满矛盾，相见无言，前后不超过2个月。这一切的导火索就是其中两人相恋了，矛盾不可避免地出现了。比如，本来约好5个人一起吃饭和游玩的计划。因为这对恋人私下约会而泡汤；又如，处于热恋期的两人常常在客厅聊至凌晨两三点，我们受其困扰，辗转难眠。从一开始的时候，搭伙煮饭，到最后分为三个团体，时间协调也是矛盾重重，所幸，我基本只点外卖。到最后，我悟出了一个道理，千万别和情侣一起合租。</p><p>十一将至，各种生活工作都开始稳定，就出现了一件大事，由于我们是5人合租，其中有两间是隔断房。而正值十一期间，北京严查隔断出租屋，导致大量中介的隔断房被拆除，我们门口就贴着一张隔断房拆除的通知。当时我们5人的关系还算不错，不像现在这样撕破脸都无所畏惧。我们惶恐不已，要是隔断房被拆除，无法再找个房子可以5个人合租在一起。为此我们不断地和房东沟通和交流，甚至做好了重新找房的准备。后来虽然证明这种担心是徒劳的，但我们还是费了不少心血在这上面。不过，我想我以后应该不会再租隔断房了。</p><h2 id="个人篇"><a href="#个人篇" class="headerlink" title="-个人篇-"></a>-个人篇-</h2><p>生活总是充满了各种感悟，北漂将近一年，已打算背起行囊，重新出发。<br><img src= "/img/loading.gif" data-lazy-src="/img/beauty.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      介绍我一年的北漂生活
    
    </summary>
    
    
    
      <category term="感悟" scheme="http://levin-lee.github.io/tags/%E6%84%9F%E6%82%9F/"/>
    
      <category term="北漂" scheme="http://levin-lee.github.io/tags/%E5%8C%97%E6%BC%82/"/>
    
  </entry>
  
  <entry>
    <title>python高级编程</title>
    <link href="http://levin-lee.github.io/2020/08/21/python%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B/"/>
    <id>http://levin-lee.github.io/2020/08/21/python%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B/</id>
    <published>2020-08-21T11:32:32.000Z</published>
    <updated>2020-08-21T11:36:15.750Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><h2 id="1、filter函数-过滤"><a href="#1、filter函数-过滤" class="headerlink" title="1、filter函数-过滤"></a>1、filter函数-过滤</h2><p>可以查看下面的例子<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">num = [<span class="number">1</span>,<span class="number">4</span>,<span class="number">-5</span>,<span class="number">3</span>,<span class="number">-7</span>,<span class="number">6</span>]</span><br><span class="line">after_filter = map(<span class="keyword">lambda</span> x:x**<span class="number">2</span>,filter(<span class="keyword">lambda</span> x:x&gt;<span class="number">0</span>,num))</span><br><span class="line">print(after_filter)</span><br></pre></td></tr></table></figure><br>当然，也可以用python自带的迭代器,可以达到一样的效果<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">after_filter = [x**<span class="number">2</span> <span class="keyword">for</span> x <span class="keyword">in</span> num <span class="keyword">if</span> x&gt;<span class="number">0</span>]</span><br></pre></td></tr></table></figure></p><p>此外，还可以使用生成器<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">squre_generator</span><span class="params">(parameter)</span>:</span></span><br><span class="line">    rerurn(x**<span class="number">2</span> <span class="keyword">for</span> x <span class="keyword">in</span> num <span class="keyword">if</span> x&gt;parameter)</span><br><span class="line">g = list(squre_generator(<span class="number">0</span>))</span><br></pre></td></tr></table></figure></p><h2 id="2、装饰器"><a href="#2、装饰器" class="headerlink" title="2、装饰器"></a>2、装饰器</h2><p>装饰器为我们提供了一个增加已有函数或类的功能。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> wraps</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">timethis</span><span class="params">(func)</span>:</span></span><br><span class="line"></span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">wrapper</span><span class="params">(*args,**kwargs)</span>:</span></span><br><span class="line">      start = time.time()</span><br><span class="line">      result = func(*args,**kwargs)</span><br><span class="line">      end = time.time()</span><br><span class="line">      print(func.__name__,end-start)</span><br><span class="line">      <span class="keyword">return</span> wrapper</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">countdown</span><span class="params">(n)</span>:</span></span><br><span class="line">    <span class="keyword">while</span> n&gt;<span class="number">0</span>:</span><br><span class="line">    n-=<span class="number">1</span></span><br><span class="line"></span><br><span class="line">countdown(<span class="number">10000</span>)</span><br></pre></td></tr></table></figure></p><h2 id="3、和和xx-的区别"><a href="#3、和和xx-的区别" class="headerlink" title="3、和和xx_的区别"></a>3、<em>和和xx_</em>的区别</h2><h3 id="1）“-”单下划线"><a href="#1）“-”单下划线" class="headerlink" title="1）“_”单下划线"></a>1）“_”单下划线</h3><p>可以在类的方法或属性前加一个“_”单下划线，意味着该方法或属性不应该去调用。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">A</span>:</span> </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_method</span><span class="params">(self)</span>:</span> </span><br><span class="line">        print(<span class="string">'约定为不在类的外面直接调用这个方法，但是也可以调用’) </span></span><br><span class="line"><span class="string">    def method(self): </span></span><br><span class="line"><span class="string">        return self._method() </span></span><br><span class="line"><span class="string">a = A()</span></span><br></pre></td></tr></table></figure><br>在类A中定义了一个_method方法，按照约定是不能在类外面直接调用它的，为了可以在外面使用_method方法，又定义了method方法，method方法调用_method方法。请看代码演示：<br>a._method() 不建议在类的外面直接调用这个方法，但是也可以调用。最好是a.method()</p><h3 id="2）双”-”下划线"><a href="#2）双”-”下划线" class="headerlink" title="2）双”__”下划线"></a>2）双”__”下划线</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">A</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__method</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">'This is a method from class A'</span>)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">method</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.__method()</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">B</span><span class="params">(A)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__method</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">'This is a method from calss B'</span>)</span><br></pre></td></tr></table></figure><p>在类A中，method方法其实由于name mangling技术的原因，变成了_Amethod，所以在A中method方法返回的是_Amethod，B作为A的子类，只重写了method方法，并没有重写method方法，所以调用B中的method方法时，调用的还是_Amethod方法：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">27</span>]: a = A()</span><br><span class="line">In [<span class="number">28</span>]: b = B()</span><br><span class="line">In [<span class="number">29</span>]: a.method()</span><br><span class="line">This <span class="keyword">is</span> a method <span class="keyword">from</span> <span class="class"><span class="keyword">class</span> <span class="title">A</span></span></span><br><span class="line"><span class="class"><span class="title">In</span> [30]:</span> b.method()</span><br><span class="line">This <span class="keyword">is</span> a method <span class="keyword">from</span> <span class="class"><span class="keyword">class</span> <span class="title">A</span></span></span><br></pre></td></tr></table></figure><br>在A中没有method方法，有的只是_A__method方法，也可以在外面直接调用，所以python中没有真正的私有化</p><h3 id="3）“xx”前后各双下划线"><a href="#3）“xx”前后各双下划线" class="headerlink" title="3）“xx”前后各双下划线"></a>3）“xx”前后各双下划线</h3><p>在特殊的情况下，它只是python调用的hook。例如，init()函数是当对象被创建初始化时调用的;new()是用来创建实例。<br>init #构造初始化函数,new之后运行<br>new #创建实例所需的属性<br>class #实例所在的类，实例.class<br>str #实例的字符串表示，可读性高<br>repr #实例的字符串表示，准确性高<br>del #删除实例引用<br>dict #实力自定义属性，vars(实例.dict)<br>doc #类文档，help(类或者实例)<br>bases #当前类的所有父类<br>getattribute #属性访问拦截器。</p><h2 id="4、map函数"><a href="#4、map函数" class="headerlink" title="4、map函数"></a>4、map函数</h2><p>map()函数接收两个参数，一个是函数，一个是序列，map将传入的函数依次作用到序列的每个元素，并把结果作为新的list返回。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f</span><span class="params">(x)</span>:</span></span><br><span class="line"><span class="keyword">return</span> x * x</span><br><span class="line">map(f, [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>])</span><br></pre></td></tr></table></figure></p><h2 id="5、reduce函数"><a href="#5、reduce函数" class="headerlink" title="5、reduce函数"></a>5、reduce函数</h2><p>reduce这个函数必须接收两个参数，reduce把结果继续和序列的下一个元素做累积计算，其效果就是：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fn</span><span class="params">(x, y)</span>:</span></span><br><span class="line"><span class="keyword">return</span> x * <span class="number">10</span> + y</span><br><span class="line">reduce(fn, [<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">9</span>])</span><br><span class="line"><span class="number">13579</span></span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot; cla
      
    
    </summary>
    
    
    
      <category term="编程" scheme="http://levin-lee.github.io/tags/%E7%BC%96%E7%A8%8B/"/>
    
      <category term="python" scheme="http://levin-lee.github.io/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>向前走，向后走</title>
    <link href="http://levin-lee.github.io/2020/08/21/%E5%90%91%E5%89%8D%E8%B5%B0%EF%BC%8C%E5%90%91%E5%90%8E%E8%B5%B0/"/>
    <id>http://levin-lee.github.io/2020/08/21/%E5%90%91%E5%89%8D%E8%B5%B0%EF%BC%8C%E5%90%91%E5%90%8E%E8%B5%B0/</id>
    <published>2020-08-21T11:06:56.000Z</published>
    <updated>2020-10-11T12:54:50.077Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>很喜欢台湾作家几米画的单行本漫画《向左走，向右走》，文字中处处透露着温暖，插画清新自然，很舒服。</p><p>书中描绘着，在一座陌生的城市中，寂寞孤独的一对男女因为偶然一次缘分在公园相遇，互诉衷肠，两个落寞的心彼此感受着对方的温暖。然而，天空开始下着暴雨，俩人不得不分开，在临别前女生给男生留下写着电话的字条，就各自匆忙回家。不幸的是，字条由于雨水打湿而模糊了字迹，辨认不出号码。女生就这么焦急地等待男生的电话，而男生由于打湿字条而懊悔，满怀希望去公园等待，每次只能失望而归。时间缓缓流逝，又回到当初孤生一人的状态，生活仿佛又恢复了平静，只有他们自己知道，他们的心结了厚厚一层霜。生活在同个城市，两人有很多次机会相遇，但一人习惯向左，一人习惯向右，总是插肩而过，仿佛命运给他们开了无情的玩笑，注定无法相遇。又过了一段时间，女生打算离开这个让她伤心的城市。女生早早起床，把行李收拾好，打算在日出来临之时逃离这座城市，恰好遇上同样外出的男生。这一次，命运开始重新眷顾他们，在最重要的时刻他们重新相遇，那一刻，初升的阳光温柔地打在他们身上，暖暖的，融化了心里的霜。<br><img src= "/img/loading.gif" data-lazy-src="/img/left.jpg" alt="向左走，向右走"><br>这本书其实带给我很深的感动。以前在学校，身边总是围绕着很多东西，心里不觉得孤单，但等我真正走出社会，我才发现，在这钢筋水泥包裹着的城市，心慢慢开始学会忍受孤独。慢慢地开始习惯一个人，习惯一个人吃饭、一个人逛街、一个人看电影，一个人学会忍受孤独，内心开始慢慢封闭，终于我们会发现原来一个人也会慢慢习惯。</p><p>本书带给我的另一个感受是，人的一生会错过许许多多的人，有的人你会跟他相识相知，然后一别再也不见；有的人仅仅是打一个照面，就再也没有出现在你的世界中。每一天我们都在上演这离别戏码，可能是你身边的爱人和家人，也有可能是司机、路人、乘客。每次离别时，我们总以为还有机会再见，下次会有勇气把“我喜欢你”说给心底的那人听，但往往离别之后，再也无法遇见，未说出口的表白成为永久的遗憾。</p><p>一别之后，两地相悬，怎知说那三四载，谁知是一生憾事。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot; cla
      
    
    </summary>
    
    
    
      <category term="感悟" scheme="http://levin-lee.github.io/tags/%E6%84%9F%E6%82%9F/"/>
    
      <category term="随笔" scheme="http://levin-lee.github.io/tags/%E9%9A%8F%E7%AC%94/"/>
    
  </entry>
  
  <entry>
    <title>评分卡</title>
    <link href="http://levin-lee.github.io/2020/08/21/%E8%AF%84%E5%88%86%E5%8D%A1/"/>
    <id>http://levin-lee.github.io/2020/08/21/%E8%AF%84%E5%88%86%E5%8D%A1/</id>
    <published>2020-08-21T11:01:02.000Z</published>
    <updated>2020-08-21T11:24:42.560Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><p>评分卡分为A卡、B卡、C卡，在金融领域，A卡是利用最多的模型，尤其是银行，经常运用到贷前准入环节。它具有可解释性，模型稳定等各种优势。</p><p>得到评分卡的步骤如下：</p><h2 id="一、认清目标"><a href="#一、认清目标" class="headerlink" title="一、认清目标"></a>一、认清目标</h2><p>我们的目标是预测用户为好人的概率，并将概率转换成打分形式。分数越高表示用户的资质越好。</p><h2 id="二、数据清洗和数据加工"><a href="#二、数据清洗和数据加工" class="headerlink" title="二、数据清洗和数据加工"></a>二、数据清洗和数据加工</h2><p>将我们的非结构数据转化成结构化数据，连续数据转离散数据，去除异常值，标准化处理（最大最小值；正态标准化等）；<br>分箱操作就是将连续数据转成离散数据的方法之一。分箱的优势为：1、排除异常值的影响，例如：年龄为200岁；2、可以防止模型过拟合；3、为模型引入非线性，提高表达能力<br>分箱方法：</p><p>监督方法：卡方分箱法、IV最大化分箱法<br>无监督方法：k-means聚类、等频、等宽</p><h2 id="三、特征工程"><a href="#三、特征工程" class="headerlink" title="三、特征工程"></a>三、特征工程</h2><p>得到相对多的特征变量，在得到IV值之前，需要进行WOE，即特征转换。<br>之后分别计算IV值（information value），计算IV值。<br>根据IV值大小排列，IV值越高代表单个变量的可解释性越高。<br>得到比较重要的特征，取前topN特征代入线性回归中。<br>IV&lt;=0.02，没有解释性<br>0.1&lt;=IV&lt;0.02，具有较弱的解释性<br>0.3&lt;=IV&lt;=0.1，具有较强的解释性<br>0.3&lt;=IV，具有极强的解释性<br>一般来说，IV大于0.1时候，特征就可以保留下来。</p><h2 id="四、LR线性回归"><a href="#四、LR线性回归" class="headerlink" title="四、LR线性回归"></a>四、LR线性回归</h2><p>普通线性回归为：y = \beta_1x_1+\beta_2x_2+…+\beta_nx_n，而logistic回归是将普通线性回归映射到 [0,1] 范围内。<br>Logistic 函数为：f(x) = \frac{1}{1+e^-x}<br>假定P是用户为坏人的概率，则1-P是用户为好人的概率，P∈[0,1]。<br>P(y=1|x) = \frac{e^wx}{1+e^wx} ….. (1)<br>P(y=0|x) = \frac{1}{1+e^wx} ……(2)<br>则 ods = \frac{p}{1-p}，是坏人与好人的几率。令p=P(y=1|x)，则好人的概率为1-p<br>将公式1除以公式2可得，ln\frac{p}{1-p} = wx，令y= ln\frac{p}{1-p}<br>故 lny = w_1x_1+w_2x_2+…+w_nx_n</p><p>目标函数（损失函数）：<br>这里我们利用极大似然估计来得到logistic回归的损失函数：<br>L = \prod{I=1}{N}p^y_i+(1-p)^(1-y_i) ，<br>则lnL<br>= \sum{I=1}{N}ylnp+(1-)yln(1-p)<br>= \sum{I=1}{N}yln\frac{p}{1-p}+ln(1-p)<br>= \sum{I=1}{N}ywx+ln(\frac{1}{1+e^wx})</p><p>如何使损失函数最小化，这个时候就需要利用坐标下降法，来得到各个特征系数的值。</p><h2 id="五、得到评分卡"><a href="#五、得到评分卡" class="headerlink" title="五、得到评分卡"></a>五、得到评分卡</h2><p>在第四步，我们得到坏人的概率之后，就需要将概率转换成我们所需要的分数。<br>在得到分数之前，我们需要定义三个参数：</p><p>基准odds好坏比，即\frac{p}{1-p}<br>基准分数<br>PDO(points to Double the odds)：当odds增加两倍时，所减少的信用分<br>可以列式子：<br>Base_score = A - Bln(odds)<br>Base_score - PDO = A - Bln(2odds)<br>可以得到：A = base_score + frac{PDO}{ln(2)}*ln(odds)，B = frac{PDO}{ln(2)}<br>当我们希望信用分为600分时，对应的ods为1:50。当ods扩大为2:50时，信用分降低20分至580分(PDO=20)，可以求出AB的取值。<br>A=487.122 ，B=28.854</p><h2 id="六、模型评估"><a href="#六、模型评估" class="headerlink" title="六、模型评估"></a>六、模型评估</h2><p>详见《模型与策略评估》专栏。</p><h2 id="参考目录："><a href="#参考目录：" class="headerlink" title="参考目录："></a>参考目录：</h2><p>【1】《统计学习方法》-李航<br>【2】《机器学习》-周志华</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;/assets/css/APlayer.min.css&quot;&gt;&lt;script src=&quot;/assets/js/APlayer.min.js&quot; cla
      
    
    </summary>
    
    
    
      <category term="评分卡" scheme="http://levin-lee.github.io/tags/%E8%AF%84%E5%88%86%E5%8D%A1/"/>
    
      <category term="风控模型" scheme="http://levin-lee.github.io/tags/%E9%A3%8E%E6%8E%A7%E6%A8%A1%E5%9E%8B/"/>
    
  </entry>
  
</feed>
