<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>RDD函数大全 | Levin-lee</title><meta name="description" content="map 是对 RDD 中的每个元素都执行一个指定的函数来产生一个新的 RDD。 任何 原 RDD 中的元素在新 RDD 中都有且只有一个元素与之对应。 举例：12345scala&gt;val a&#x3D;sc.parallelize(1to9,3) scala&gt;val b&#x3D;a.map(x&#x3D;&gt;x*2) scala&gt;a.collect res10:Array["><meta name="author" content="Levin lee"><meta name="copyright" content="Levin lee"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://levin-lee.github.io/2021/11/27/RDD%E5%87%BD%E6%95%B0%E5%A4%A7%E5%85%A8/"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//fonts.googleapis.com" crossorigin="crossorigin"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta property="og:type" content="article"><meta property="og:title" content="RDD函数大全"><meta property="og:url" content="http://levin-lee.github.io/2021/11/27/RDD%E5%87%BD%E6%95%B0%E5%A4%A7%E5%85%A8/"><meta property="og:site_name" content="Levin-lee"><meta property="og:description" content="map 是对 RDD 中的每个元素都执行一个指定的函数来产生一个新的 RDD。 任何 原 RDD 中的元素在新 RDD 中都有且只有一个元素与之对应。 举例：12345scala&gt;val a&#x3D;sc.parallelize(1to9,3) scala&gt;val b&#x3D;a.map(x&#x3D;&gt;x*2) scala&gt;a.collect res10:Array["><meta property="og:image" content="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg"><meta property="article:published_time" content="2021-11-27T06:20:45.000Z"><meta property="article:modified_time" content="2021-11-27T06:48:02.506Z"><meta name="twitter:card" content="summary"><script>var activateDarkMode = function () {
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null) {
    document.querySelector('meta[name="theme-color"]').setAttribute('content', '#000')
  }
}
var activateLightMode = function () {
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null) {
    document.querySelector('meta[name="theme-color"]').setAttribute('content', '#fff')
  }
}

var getCookies = function (name) {
  const value = `; ${document.cookie}`
  const parts = value.split(`; ${name}=`)
  if (parts.length === 2) return parts.pop().split(';').shift()
}

var autoChangeMode = 'false'
var t = getCookies('theme')
if (autoChangeMode === '1') {
  var isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
  var isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
  var isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
  var hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

  if (t === undefined) {
    if (isLightMode) activateLightMode()
    else if (isDarkMode) activateDarkMode()
    else if (isNotSpecified || hasNoSupport) {
      console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
      var now = new Date()
      var hour = now.getHours()
      var isNight = hour <= 6 || hour >= 18
      isNight ? activateDarkMode() : activateLightMode()
    }
    window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
      if (Cookies.get('theme') === undefined) {
        e.matches ? activateDarkMode() : activateLightMode()
      }
    })
  } else if (t === 'light') activateLightMode()
  else activateDarkMode()
} else if (autoChangeMode === '2') {
  now = new Date()
  hour = now.getHours()
  isNight = hour <= 6 || hour >= 18
  if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode()
} else {
  if (t === 'dark') activateDarkMode()
  else if (t === 'light') activateLightMode()
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web&amp;display=swap"><script>var GLOBAL_CONFIG = { 
  root: '/',
  hexoversion: '4.2.1',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  runtime: false,
  copyright: undefined,
  ClickShowText: undefined,
  medium_zoom: false,
  fancybox: true,
  Snackbar: undefined,
  justifiedGallery: {
    js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
    css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
  },
  baiduPush: false,
  highlightCopy: true,
  highlightLang: true,
  isPhotoFigcaption: false,
  islazyload: true,
  isanchor: false    
}</script><script id="config_change">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isSidebar: true,
  postUpdate: '2021-11-27 14:48:02'
}</script><noscript><style>
#nav {
  opacity: 1
}
.justified-gallery img {
  opacity: 1
}
</style></noscript><meta name="generator" content="Hexo 4.2.1"><link rel="alternate" href="/atom.xml" title="Levin-lee" type="application/atom+xml">
</head><body><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" data-lazy-src="/img/avatar.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">15</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">15</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">1</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 清单</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li><li><a class="site-page" href="/books/"><i class="fa-fw fas fa-book"></i><span> 书籍</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div id="body-wrap"><div id="web_bg" data-type="photo"></div><div id="sidebar"><i class="fas fa-arrow-right on" id="toggle-sidebar"></i><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#map"><span class="toc-number">1.</span> <span class="toc-text">map</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#filter"><span class="toc-number">2.</span> <span class="toc-text">filter</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#flatMap"><span class="toc-number">3.</span> <span class="toc-text">flatMap</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#mapPartitions"><span class="toc-number">4.</span> <span class="toc-text">mapPartitions</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#mapPartitionsWithIndex"><span class="toc-number">5.</span> <span class="toc-text">mapPartitionsWithIndex</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#mapWith"><span class="toc-number">6.</span> <span class="toc-text">mapWith</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#glom"><span class="toc-number">7.</span> <span class="toc-text">glom</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#union-并集"><span class="toc-number">8.</span> <span class="toc-text">union 并集</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#distinct"><span class="toc-number">9.</span> <span class="toc-text">distinct</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#intersection-交集"><span class="toc-number">10.</span> <span class="toc-text">intersection 交集</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#subtract"><span class="toc-number">11.</span> <span class="toc-text">subtract</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#subtractByKey"><span class="toc-number">12.</span> <span class="toc-text">subtractByKey</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#groupbyKey"><span class="toc-number">13.</span> <span class="toc-text">groupbyKey</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#reduceByKey"><span class="toc-number">14.</span> <span class="toc-text">reduceByKey</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#sortByKey"><span class="toc-number">15.</span> <span class="toc-text">sortByKey</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#sortBy"><span class="toc-number">16.</span> <span class="toc-text">sortBy</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#zip"><span class="toc-number">17.</span> <span class="toc-text">zip</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#zipPartitions"><span class="toc-number">18.</span> <span class="toc-text">zipPartitions</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#zipWithIndex"><span class="toc-number">19.</span> <span class="toc-text">zipWithIndex</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#zipWithUniqueId"><span class="toc-number">20.</span> <span class="toc-text">zipWithUniqueId</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#partitionBy"><span class="toc-number">21.</span> <span class="toc-text">partitionBy</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#mapValues"><span class="toc-number">22.</span> <span class="toc-text">mapValues</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#flatMapValues"><span class="toc-number">23.</span> <span class="toc-text">flatMapValues</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#combineByKey"><span class="toc-number">24.</span> <span class="toc-text">combineByKey</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#foldByKey"><span class="toc-number">25.</span> <span class="toc-text">foldByKey</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#reduceByKeyLocally"><span class="toc-number">26.</span> <span class="toc-text">reduceByKeyLocally</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#sample"><span class="toc-number">27.</span> <span class="toc-text">sample</span></a></li></ol></div></div></div><header class="post-bg" id="page-header" style="background-image: url(https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg)"><nav id="nav"><span class="pull-left" id="blog_name"><a class="blog_title" id="site-name" href="/">Levin-lee</a></span><span class="pull-right menus"><div id="search_button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 清单</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li><li><a class="site-page" href="/books/"><i class="fa-fw fas fa-book"></i><span> 书籍</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><span class="toggle-menu close"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></span></span></nav><div id="post-info"><div id="post-title"><div class="posttitle">RDD函数大全</div></div><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2021-11-27T06:20:45.000Z" title="发表于 2021-11-27 14:20:45">2021-11-27</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2021-11-27T06:48:02.506Z" title="更新于 2021-11-27 14:48:02">2021-11-27</time></span></div><div class="meta-secondline"> <span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout_post" id="content-inner"><article id="post"><div class="post-content" id="article-container"><h2 id="map"><a href="#map" class="headerlink" title="map"></a>map</h2><blockquote>
<p>是对 RDD 中的每个元素都执行一个指定的函数来产生一个新的 RDD。 任何 原 RDD 中的元素在新 RDD 中都有且只有一个元素与之对应。 举例：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">scala&gt;val a&#x3D;sc.parallelize(1to9,3) </span><br><span class="line">scala&gt;val b&#x3D;a.map(x&#x3D;&gt;x*2) </span><br><span class="line">scala&gt;a.collect res10:Array[Int]&#x3D;Array(1,2,3,4,5,6,7,8,9) </span><br><span class="line">scala&gt;b.collect res11:Array[Int]&#x3D;Array(2,4,6,8,10,12,14,16,18) </span><br><span class="line">&#x2F;&#x2F;上述例子中把原 RDD 中每个元素都乘以 2 来产生一个新的 RDD。</span><br></pre></td></tr></table></figure></p>
</blockquote>
<h2 id="filter"><a href="#filter" class="headerlink" title="filter"></a>filter</h2><blockquote>
<p>filter 是对 RDD 中的每个元素都执行一个指定的函数来过滤产生一个新的 RDD。 任何原 RDD 中的元素在新 RDD 中都有且只有一个元素与之对应。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">val rdd&#x3D;sc.parallelize(List(1,2,3,4,5,6)) </span><br><span class="line">val filterRdd&#x3D;rdd.filter(_&gt;5) </span><br><span class="line">filterRdd.collect()&#x2F;&#x2F;返回所有大于 5 的数据的一个 Array， Array(6,8,10,12)</span><br></pre></td></tr></table></figure></p>
</blockquote>
<h2 id="flatMap"><a href="#flatMap" class="headerlink" title="flatMap"></a>flatMap</h2><blockquote>
<p>与 map 类似，区别是原 RDD 中的元素经 map 处理后只能生成一个元素，而原 RDD 中的元素经 flatmap 处理后可生成多个元素来构建新 RDD。举例：对原 RDD 中的每个元素 x 产生 y 个元素（从 1 到 y，y 为元素 x 的值）<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scala&gt;vala&#x3D;sc.parallelize(1to4,2) scala&gt;valb&#x3D;a.flatMap(x&#x3D;&gt;1tox)</span><br><span class="line">scala&gt;b.collect res12:Array[Int]&#x3D;Array(1,1,2,1,2,3,1,2,3,4)</span><br></pre></td></tr></table></figure></p>
</blockquote>
<h2 id="mapPartitions"><a href="#mapPartitions" class="headerlink" title="mapPartitions"></a>mapPartitions</h2><blockquote>
<p>mapPartitions 是 map 的一个变种。map 的输入函数是应用于 RDD 中每个元素， 而 mapPartitions 的输入函数是应用于每个分区，也就是把每个分区中的内容作 为整体来处理的。 它的函数定义为： def mapPartitions<a href="f: Iterator[T] =&gt; Iterator[U], preservesPartitioning: Boolean=false">U: ClassTag</a>:RDD[U] f 即为输入函数，它处理每个分区里面的内容。每个分区中的内容将以 Iterator[T] 传递给输入函数 f， f 的输出结果是 Iterator[U]。最终的 RDD 由所有分区经过输入 函数处理后的结果合并起来的。 举例：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">scala&gt;val a&#x3D;sc.parallelize(1to9,3) </span><br><span class="line">scala&gt;def myfuncT:Iterator[(T,T)]&#x3D;&#123; </span><br><span class="line">var res&#x3D;List(T,T) </span><br><span class="line">var pre&#x3D;iter.next </span><br><span class="line">while(iter.hasNext)&#123; </span><br><span class="line">	valcur&#x3D;iter.next </span><br><span class="line">	res.::&#x3D;(pre,cur) </span><br><span class="line">	pre&#x3D;cur &#125; res.iterator &#125; </span><br><span class="line">scala&gt;a.mapPartitions(myfunc).collect </span><br><span class="line">res0:Array[(Int,Int)]&#x3D;Array((2,3),(1,2),(5,6),(4,5),(8,9),(7,8))</span><br></pre></td></tr></table></figure><br> 上述例子中的函数myfunc是把分区中一个元素和它的下一个元素组成一个Tuple。 因为分区中最后一个元素没有下一个元素了，所以(3,4)和(6,7)不在结果中。 mapPartitions 还有些变种，比如 mapPartitionsWithContext，它能把处理过程中的 一些状态信息传递给用户指定的输入函数。还有 mapPartitionsWithIndex，它能 把分区的 index传递给用户指定的输入函数。</p>
<h2 id="mapPartitionsWithIndex"><a href="#mapPartitionsWithIndex" class="headerlink" title="mapPartitionsWithIndex"></a>mapPartitionsWithIndex</h2><p>def mapPartitionsWithIndex<a href="f: (Int, Iterator[T]">U</a> =&gt; Iterator[U], preservesPartitioning:Boolean=false)(implicitarg0:ClassTag[U]):RDD[U] 函数作用同 mapPartitions，不过提供了两个参数，第一个参数为分区的索引。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">var rdd1&#x3D;sc.makeRDD(1to5,2) &#x2F;&#x2F;rdd1 有两个分区 </span><br><span class="line">var rdd2&#x3D;rdd1.mapPartitionsWithIndex&#123; </span><br><span class="line">(x,iter)&#x3D;&gt;&#123; varresult&#x3D;ListString </span><br><span class="line">var i&#x3D;0 </span><br><span class="line">while(iter.hasNext)&#123; i+&#x3D;iter.next() &#125; result.::(x+&quot;|&quot;+i).iterator</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>//rdd2 将 rdd1 中每个分区的数字累加，并在每个分区的累加结果前面加了分区 索引 scala&gt;rdd2.collect res13:Array[String]=Array(0|3,1|12)</p>
<h2 id="mapWith"><a href="#mapWith" class="headerlink" title="mapWith"></a>mapWith</h2><p>mapWith 是 map 的另外一个变种，map 只需要一个输入函数，而 mapWith 有两 个输入函数。它的定义如下： def mapWith<a href="constructA: Int =&gt; A, preservesPartitioning: Boolean = false">A: ClassTag, U: </a>(f:(T,A)=&gt;U):RDD[U] 第一个函数 constructA 是把 RDD 的 partitionindex（index 从 0 开始）作为输入， 输出为新类型 A； 第二个函数 f 是把二元组(T,A)作为输入（其中 T 为原 RDD 中的元素，A 为第一个 函数的输出），输出类型为 U。 举例：把 partitionindex 乘以 10 加 2,作为新的 RDD 的元素。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">val x&#x3D;sc.parallelize(List(1,2,3,4,5,6,7,8,9,10),3) </span><br><span class="line">x.mapWith(a&#x3D;&gt;a*10)((b,a)&#x3D;&gt;(b,a+2)).collect </span><br><span class="line">结果： </span><br><span class="line">(1,2) (2,2) (3,2) (4,12)</span><br><span class="line">(5,12) (6,12) (7,22) (8,22) (9,22) (10,22)</span><br><span class="line"></span><br><span class="line">## flatMapWith</span><br><span class="line">&gt;flatMapWith 与 mapWith 很类似，都是接收两个函数，一个函数把 partitionIndex 作为输入，输出是一个新类型 A；另外一个函数是以二元组（T,A）作为输入，输 出为一个序列，这些序列里面的元素组成了新的 RDD。它的定义如下： defflatMapWith[A:ClassTag, U: ClassTag](constructA:Int &#x3D;&gt;A, preservesPartitioning: Boolean&#x3D;false)(f:(T,A)&#x3D;&gt;Seq[U]):RDD[U] 举例： scala&gt;vala&#x3D;sc.parallelize(List(1,2,3,4,5,6,7,8,9),3) scala&gt;a.flatMapWith(x&#x3D;&gt;x,true)((x,y)&#x3D;&gt;List(y,x)).collect res58:Array[Int]&#x3D;Array(0,1,0,2,0,3,1,4,1,5,1,6,2,7,2, 8,2,9)</span><br><span class="line">## coalesce</span><br><span class="line">&gt;def coalesce(numPartitions: Int, shuffle: Boolean &#x3D; false)(implicit ord: Ordering[T] &#x3D; null):RDD[T] 该函数用于将 RDD 进行重分区，使用 HashPartitioner。 第一个参数为重分区的数目，第二个为是否进行 shuffle，默认为 false; 以下面的例子来看：</span><br></pre></td></tr></table></figure><br>scala&gt;var data=sc.parallelize(1to12,3)<br>scala&gt;data.collect<br>scala&gt;data.partitions.size<br>scala&gt;var rdd1=data.coalesce(1)<br>scala&gt;rdd1.partitions.size<br>scala&gt;varrdd1=data.coalesce(4)<br>scala&gt;rdd1.partitions.size res2:Int=1<br>//如果重分区的数目大于原来的分区数，那么必须指定 shuffle 参 数为 true，//否则，分区数不便 scala&gt;varrdd1=data.coalesce(4,true) scala&gt;rdd1.partitions.size<br>res3:Int=4<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">## repartition</span><br><span class="line">&gt;defrepartition(numPartitions:Int)(implicitord:Ordering[T]&#x3D;null):RDD[T] 该函数其实就是 coalesce 函数第二个参数为 true 的实现 scala&gt;vardata&#x3D;sc.parallelize(1to12,3) scala&gt;data.collect scala&gt;data.partitions.size scala&gt;varrdd1&#x3D;data.repartition(1) scala&gt;rdd1.partitions.size scala&gt;varrdd1&#x3D;data.repartition(4) scala&gt;rdd1.partitions.size res3:Int&#x3D;4</span><br><span class="line"></span><br><span class="line">## randomSplit</span><br><span class="line">&gt;def randomSplit(weights: Array[Double], seed: Long &#x3D; Utils.random.nextLong): Array[RDD[T]] 该函数根据 weights 权重，将一个 RDD 切分成多个 RDD。 该权重参数为一个 Double 数组 第二个参数为 random 的种子，基本可忽略。 </span><br><span class="line">&#96;&#96;&#96;scala&gt;varrdd&#x3D;sc.makeRDD(1to12,12) rdd:org.apache.spark.rdd.RDD[Int]&#x3D;ParallelCollectionRDD[16]atmakeRDDat:21</span><br><span class="line">scala&gt;rdd.collect res6:Array[Int]&#x3D;Array(1,2,3,4,5,6,7,8,9,10)</span><br><span class="line">scala&gt;varsplitRDD&#x3D;rdd.randomSplit(Array(0.5,0.1,0.2,0.2)) splitRDD: Array[org.apache.spark.rdd.RDD[Int]] &#x3D; Array(MapPartitionsRDD[17] at randomSplitat:23, MapPartitionsRDD[18]atrandomSplitat:23, MapPartitionsRDD[19]atrandomSplitat:23, MapPartitionsRDD[20]atrandomSplitat:23)</span><br><span class="line">&#x2F;&#x2F;这里注意：randomSplit 的结果是一个 RDD 数组</span><br><span class="line">scala&gt;splitRDD.size res8:Int&#x3D;4 &#x2F;&#x2F;由于 randomSplit 的第一个参数 weights 中传入的值有 4 个，因此，就会切分成 4 个 RDD, &#x2F;&#x2F;把原来的 rdd 按照权重 0.5,0.1,0.2,0.2，随机划分到这 4 个 RDD 中，权重高的 RDD，划分到&#x2F;&#x2F;的几率就大一些。 &#x2F;&#x2F;注意，权重的总和加起来为 1，否则会不正常 scala&gt;splitRDD(0).collect res10:Array[Int]&#x3D;Array(1,4)</span><br><span class="line">scala&gt;splitRDD(1).collect res11:Array[Int]&#x3D;Array(3)</span><br><span class="line">scala&gt;splitRDD(2).collect res12:Array[Int]&#x3D;Array(5,9)</span><br><span class="line">scala&gt;splitRDD(3).collect res13:Array[Int]&#x3D;Array(2,6,7,8,10)</span><br></pre></td></tr></table></figure></p>
</blockquote>
<h2 id="glom"><a href="#glom" class="headerlink" title="glom"></a>glom</h2><blockquote>
<p>defglom():RDD[Array[T]] 该函数是将 RDD 中每一个分区中类型为 T 的元素转换成 Array[T]，这样每一个分 区就只有一个数组元素。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">scala&gt;var rdd&#x3D;sc.makeRDD(1to10,3) </span><br><span class="line">rdd:org.apache.spark.rdd.RDD[Int]&#x3D;ParallelCollectionRDD[38]atmakeRDDat:21 </span><br><span class="line">scala&gt;rdd.partitions.size res33:Int&#x3D;3 </span><br><span class="line">&#x2F;&#x2F;该 RDD 有 3 个分区 </span><br><span class="line">scala&gt;rdd.glom().collect </span><br><span class="line">res35:Array[Array[Int]]&#x3D;Array(Array(1,2,3),Array(4,5,6),Array(7,8,9,10)) &#x2F;&#x2F;glom 将每个分区中的元素放到一个数组中，这样，结果就变成了 3 个数组</span><br></pre></td></tr></table></figure></p>
</blockquote>
<h2 id="union-并集"><a href="#union-并集" class="headerlink" title="union 并集"></a>union 并集</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">val rdd1&#x3D;sc.parallelize(List(5,6,4,3)) </span><br><span class="line">val rdd2&#x3D;sc.parallelize(List(1,2,3,4)) &#x2F;&#x2F;求并集 </span><br><span class="line">val rdd3&#x3D;rdd1.union(rdd2) </span><br><span class="line">rdd3.collect</span><br></pre></td></tr></table></figure>
<h2 id="distinct"><a href="#distinct" class="headerlink" title="distinct"></a>distinct</h2><blockquote>
<p>去重<br>val rdd1=sc.parallelize(List(5,6,4,3))<br>val rdd2=sc.parallelize(List(1,2,3,4)) //求并集 valrdd3=rdd1.union(rdd2) //去重输出 rdd3.distinct.collect</p>
</blockquote>
<h2 id="intersection-交集"><a href="#intersection-交集" class="headerlink" title="intersection 交集"></a>intersection 交集</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">val rdd1&#x3D;sc.parallelize(List(5,6,4,3)) </span><br><span class="line">valrdd2&#x3D;sc.parallelize(List(1,2,3,4)) &#x2F;&#x2F;求交集 valrdd4&#x3D;rdd1.intersection(rdd2) rdd4.collect</span><br></pre></td></tr></table></figure>
<h2 id="subtract"><a href="#subtract" class="headerlink" title="subtract"></a>subtract</h2><blockquote>
<p>def subtract(other:RDD[T]):RDD[T] defsubtract(other:RDD[T],numPartitions:Int):RDD[T] def subtract(other: RDD[T], partitioner: Partitioner)(implicit ord: Ordering[T] = null): RDD[T] 该函数返回在 RDD 中出现，并且不在 otherRDD 中出现的元素，不去重。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">val rdd1&#x3D;sc.parallelize(List(5,6,6,4,3)) </span><br><span class="line">val rdd2&#x3D;sc.parallelize(List(1,2,3,4)) &#x2F;&#x2F;求差集 valrdd4&#x3D;rdd1.subtract(rdd2) rdd4.collect</span><br></pre></td></tr></table></figure></p>
</blockquote>
<h2 id="subtractByKey"><a href="#subtractByKey" class="headerlink" title="subtractByKey"></a>subtractByKey</h2><blockquote>
<p>defsubtractByKeyW(implicitarg0:ClassTag[W]):RDD[(K,V)] def subtractByKey<a href="other: RDD[(K, W">W</a>], numPartitions: Int)(implicit arg0: ClassTag[W]):RDD[(K,V)] def subtractByKey<a href="other: RDD[(K, W">W</a>], p: Partitioner)(implicit arg0: ClassTag[W]): RDD[(K,V)]<br>subtractByKey 和基本转换操作中的 subtract 类似，只不过这里是针对 K 的，返回 在主 RDD 中出现，并且不在 otherRDD 中出现的元素。 参数 numPartitions 用于指定结果的分区数 参数 partitioner 用于指定分区函数<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">var rdd1&#x3D;sc.makeRDD(Array((&quot;A&quot;,&quot;1&quot;),(&quot;B&quot;,&quot;2&quot;),(&quot;C&quot;,&quot;3&quot;)),2) </span><br><span class="line">var rdd2&#x3D;sc.makeRDD(Array((&quot;A&quot;,&quot;a&quot;),(&quot;C&quot;,&quot;c&quot;),(&quot;D&quot;,&quot;d&quot;)),2) </span><br><span class="line">scala&gt;rdd1.subtractByKey(rdd2).collect res13:Array[(String,String)]&#x3D;Array((B,2))</span><br></pre></td></tr></table></figure></p>
</blockquote>
<h2 id="groupbyKey"><a href="#groupbyKey" class="headerlink" title="groupbyKey"></a>groupbyKey</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">val rdd1&#x3D;sc.parallelize(List((&quot;tom&quot;,1),(&quot;jerry&quot;,3),(&quot;kitty&quot;,2))) </span><br><span class="line">val rdd2&#x3D;sc.parallelize(List((&quot;jerry&quot;,2),(&quot;tom&quot;,1),(&quot;shuke&quot;,2))) &#x2F;&#x2F;求并集 </span><br><span class="line">val rdd4&#x3D;rdd1.union(rdd2) &#x2F;&#x2F;按 key 进行分组 </span><br><span class="line">val rdd5&#x3D;rdd4.groupByKey </span><br><span class="line">rdd5.collect</span><br></pre></td></tr></table></figure>
<h2 id="reduceByKey"><a href="#reduceByKey" class="headerlink" title="reduceByKey"></a>reduceByKey</h2><blockquote>
<p>顾名思义，reduceByKey 就是对元素为 KV 对的 RDD 中 Key 相同的元素的 Value 进行 reduce，因此，Key 相同的多个元素的值被 reduce 为一个值，然后与原 RDD 中的 Key 组成一个新的 KV 对。 举例: valrdd1=sc.parallelize(List((“tom”,1),(“jerry”,3),(“kitty”,2))) valrdd2=sc.parallelize(List((“jerry”,2),(“tom”,1),(“shuke”,2))) //求并集 valrdd4=rdd1unionrdd2 //按 key 进行分组 valrdd6=rdd4.reduceByKey(+) rdd6.collect()</p>
</blockquote>
<h2 id="sortByKey"><a href="#sortByKey" class="headerlink" title="sortByKey"></a>sortByKey</h2><p>将 List((“tom”,1),(“jerry”,3),(“kitty”,2), (“shuke”,1))和 List((“jerry”,2),(“tom”,3), (“shuke”,2),(“kitty”,5))做 wordcount，并按名称排序 valrdd1=sc.parallelize(List((“tom”,1),(“jerry”,3),(“kitty”,2),(“shuke”,1))) valrdd2=sc.parallelize(List((“jerry”,2),(“tom”,3),(“shuke”,2),(“kitty”,5))) valrdd3=rdd1.union(rdd2) //按 key 进行聚合 valrdd4=rdd3.reduceByKey(+) //false 降序 valrdd5=rdd4.sortByKey(false) rdd5.collect</p>
<h2 id="sortBy"><a href="#sortBy" class="headerlink" title="sortBy"></a>sortBy</h2><p>将 List((“tom”,1),(“jerry”,3),(“kitty”,2), (“shuke”,1))和 List((“jerry”,2),(“tom”,3), (“shuke”,2),(“kitty”,5))做 wordcount，并按数值排序 valrdd1=sc.parallelize(List((“tom”,1),(“jerry”,3),(“kitty”,2),(“shuke”,1))) valrdd2=sc.parallelize(List((“jerry”,2),(“tom”,3),(“shuke”,2),(“kitty”,5))) valrdd3=rdd1.union(rdd2) //按 key 进行聚合 valrdd4=rdd3.reduceByKey(+)<br>//false 降序 valrdd5=rdd4.sortBy(_._2,false) rdd5.collect</p>
<h2 id="zip"><a href="#zip" class="headerlink" title="zip"></a>zip</h2><p>defzipU(implicitarg0:ClassTag[U]):RDD[(T,U)]<br>zip 函数用于将两个 RDD 组合成 Key/Value 形式的 RDD,这里默认两个 RDD 的 partition 数量以及元素数量都相同，否则会抛出异常。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">scala&gt;varrdd1&#x3D;sc.makeRDD(1to5,2) rdd1:org.apache.spark.rdd.RDD[Int]&#x3D;ParallelCollectionRDD[1]atmakeRDDat:21</span><br><span class="line">scala&gt;varrdd2&#x3D;sc.makeRDD(Seq(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;,&quot;D&quot;,&quot;E&quot;),2) rdd2: org.apache.spark.rdd.RDD[String] &#x3D; ParallelCollectionRDD[2] at makeRDD at:21</span><br><span class="line">scala&gt;rdd1.zip(rdd2).collect res0:Array[(Int,String)]&#x3D;Array((1,A),(2,B),(3,C),(4,D),(5,E))</span><br><span class="line">scala&gt;rdd2.zip(rdd1).collect res1:Array[(String,Int)]&#x3D;Array((A,1),(B,2),(C,3),(D,4),(E,5))</span><br><span class="line">scala&gt;varrdd3&#x3D;sc.makeRDD(Seq(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;,&quot;D&quot;,&quot;E&quot;),3) rdd3: org.apache.spark.rdd.RDD[String] &#x3D; ParallelCollectionRDD[5] at makeRDD at:21 scala&gt;rdd1.zip(rdd3).collect java.lang.IllegalArgumentException: Can&#39;t zip RDDs with unequal numbers of partitions &#x2F;&#x2F;如果两个 RDD 分区数不同，则抛出异常</span><br></pre></td></tr></table></figure></p>
<h2 id="zipPartitions"><a href="#zipPartitions" class="headerlink" title="zipPartitions"></a>zipPartitions</h2><blockquote>
<p>zipPartitions 函数将多个 RDD 按照 partition 组合成为新的 RDD，该函数需要组合<br>的 RDD 具有相同的分区数，但对于每个分区内的元素数量没有要求。 该函数有好几种实现，可分为三类：<br>参数是一个 RDD<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">def zipPartitions[B, V](rdd2: RDD[B])(f: (Iterator[T], Iterator[B]) &#x3D;&gt; Iterator[V])(implicit arg0: ClassTag[B],arg1:ClassTag[V]):RDD[V]</span><br><span class="line">def zipPartitions[B, V](rdd2: RDD[B], preservesPartitioning: Boolean)(f: (Iterator[T], Iterator[B]) &#x3D;&gt; Iterator[V])(implicitarg0:ClassTag[B],arg1:ClassTag[V]):RDD[V]</span><br></pre></td></tr></table></figure><br>这两个区别就是参数 preservesPartitioning，是否保留父 RDD 的 partitioner 分区信息<br>映射方法 f 参数为两个 RDD 的迭代器。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">scala&gt;varrdd1&#x3D;sc.makeRDD(1to5,2) rdd1:org.apache.spark.rdd.RDD[Int]&#x3D;ParallelCollectionRDD[22]atmakeRDDat:21</span><br><span class="line">scala&gt;varrdd2&#x3D;sc.makeRDD(Seq(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;,&quot;D&quot;,&quot;E&quot;),2) rdd2:org.apache.spark.rdd.RDD[String]&#x3D;ParallelCollectionRDD[23]atmakeRDDat:21</span><br><span class="line">&#x2F;&#x2F;rdd1 两个分区中元素分布： scala&gt;rdd1.mapPartitionsWithIndex&#123; | (x,iter)&#x3D;&gt;&#123; | varresult&#x3D;ListString | while(iter.hasNext)&#123; | result::&#x3D;(&quot;part_&quot;+x+&quot;|&quot;+iter.next()) | &#125; | result.iterator | | &#125; | &#125;.collect res17:Array[String]&#x3D;Array(part_0|2,part_0|1,part_1|5,part_1|4,part_1|3)</span><br><span class="line">&#x2F;&#x2F;rdd2 两个分区中元素分布 scala&gt;rdd2.mapPartitionsWithIndex&#123; | (x,iter)&#x3D;&gt;&#123;</span><br><span class="line">| varresult&#x3D;ListString | while(iter.hasNext)&#123; | result::&#x3D;(&quot;part_&quot;+x+&quot;|&quot;+iter.next()) | &#125; | result.iterator | | &#125; | &#125;.collect res18:Array[String]&#x3D;Array(part_0|B,part_0|A,part_1|E,part_1|D,part_1|C)</span><br><span class="line">&#x2F;&#x2F;rdd1 和 rdd2 做 zipPartition scala&gt;rdd1.zipPartitions(rdd2)&#123; | (rdd1Iter,rdd2Iter)&#x3D;&gt;&#123; | varresult&#x3D;ListString | while(rdd1Iter.hasNext&amp;&amp;rdd2Iter.hasNext)&#123; | result::&#x3D;(rdd1Iter.next()+&quot;&quot;+rdd2Iter.next()) | &#125; | result.iterator | &#125; | &#125;.collect res19:Array[String]&#x3D;Array(2_B,1_A,5_E,4_D,3_C)</span><br><span class="line">参数是两个 RDD</span><br><span class="line">def zipPartitions[B, C, V](rdd2: RDD[B], rdd3: RDD[C])(f: (Iterator[T], Iterator[B], Iterator[C]) &#x3D;&gt; Iterator[V])(implicitarg0:ClassTag[B],arg1:ClassTag[C],arg2:ClassTag[V]):RDD[V]</span><br><span class="line">def zipPartitions[B, C, V](rdd2: RDD[B], rdd3: RDD[C], preservesPartitioning: Boolean)(f: (Iterator[T], Iterator[B], Iterator[C]) &#x3D;&gt; Iterator[V])(implicit arg0: ClassTag[B], arg1: ClassTag[C], arg2:ClassTag[V]):RDD[V]</span><br></pre></td></tr></table></figure><br>用法同上面，只不过该函数参数为两个 RDD，映射方法 f 输入参数为两个 RDD 的迭代器。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">scala&gt;varrdd1&#x3D;sc.makeRDD(1to5,2) rdd1:org.apache.spark.rdd.RDD[Int]&#x3D;ParallelCollectionRDD[27]atmakeRDDat:21</span><br><span class="line">scala&gt;varrdd2&#x3D;sc.makeRDD(Seq(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;,&quot;D&quot;,&quot;E&quot;),2) rdd2:org.apache.spark.rdd.RDD[String]&#x3D;ParallelCollectionRDD[28]atmakeRDDat:21</span><br><span class="line">scala&gt;varrdd3&#x3D;sc.makeRDD(Seq(&quot;a&quot;,&quot;b&quot;,&quot;c&quot;,&quot;d&quot;,&quot;e&quot;),2) rdd3:org.apache.spark.rdd.RDD[String]&#x3D;ParallelCollectionRDD[29]atmakeRDDat:21</span><br><span class="line">&#x2F;&#x2F;rdd3 中个分区元素分布 scala&gt;rdd3.mapPartitionsWithIndex&#123; | (x,iter)&#x3D;&gt;&#123; | varresult&#x3D;ListString | while(iter.hasNext)&#123; | result::&#x3D;(&quot;part&quot;+x+&quot;|&quot;+iter.next()) | &#125; | result.iterator | | &#125; | &#125;.collect res21:Array[String]&#x3D;Array(part_0|b,part_0|a,part_1|e,part_1|d,part_1|c)</span><br><span class="line">&#x2F;&#x2F;三个 RDD 做 zipPartitions scala&gt;varrdd4&#x3D;rdd1.zipPartitions(rdd2,rdd3)&#123; | (rdd1Iter,rdd2Iter,rdd3Iter)&#x3D;&gt;&#123; | varresult&#x3D;ListString | while(rdd1Iter.hasNext&amp;&amp;rdd2Iter.hasNext&amp;&amp;rdd3Iter.hasNext)&#123; | result::&#x3D;(rdd1Iter.next()+&quot;&quot;+rdd2Iter.next()+&quot;&quot;+rdd3Iter.next()) | &#125; | result.iterator | &#125; | &#125; rdd4:org.apache.spark.rdd.RDD[String]&#x3D;ZippedPartitionsRDD3[33]atzipPartitionsat:27</span><br><span class="line">scala&gt;rdd4.collect res23:Array[String]&#x3D;Array(2_B_b,1_A_a,5_E_e,4_D_d,3_C_c)</span><br><span class="line">参数是三个 RDD</span><br><span class="line">def zipPartitions[B, C, D, V](rdd2: RDD[B], rdd3: RDD[C], rdd4: RDD[D])(f: (Iterator[T], Iterator[B],</span><br><span class="line">Iterator[C], Iterator[D]) &#x3D;&gt; Iterator[V])(implicit arg0: ClassTag[B], arg1: ClassTag[C], arg2: ClassTag[D],arg3:ClassTag[V]):RDD[V]</span><br><span class="line">def zipPartitions[B, C, D, V](rdd2: RDD[B], rdd3: RDD[C], rdd4: RDD[D], preservesPartitioning: Boolean)(f: (Iterator[T], Iterator[B], Iterator[C], Iterator[D]) &#x3D;&gt; Iterator[V])(implicit arg0: ClassTag[B],arg1:ClassTag[C],arg2:ClassTag[D],arg3:ClassTag[V]):RDD[V]</span><br></pre></td></tr></table></figure><br>用法同上面，只不过这里又多了个一个 RDD 而已。</p>
</blockquote>
<h2 id="zipWithIndex"><a href="#zipWithIndex" class="headerlink" title="zipWithIndex"></a>zipWithIndex</h2><blockquote>
<p>defzipWithIndex():RDD[(T,Long)] 该函数将 RDD 中的元素和这个元素在 RDD 中的 ID（索引号）组合成键/值对。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scala&gt;var rdd2&#x3D;sc.makeRDD(Seq(&quot;A&quot;,&quot;B&quot;,&quot;R&quot;,&quot;D&quot;,&quot;F&quot;),2) </span><br><span class="line">rdd2: org.apache.spark.rdd.RDD[String] &#x3D; ParallelCollectionRDD[34] at makeRDD at:21 </span><br><span class="line">scala&gt;rdd2.zipWithIndex().collect res27:Array[(String,Long)]&#x3D;Array((A,0),(B,1),(R,2),(D,3),(F,4))</span><br></pre></td></tr></table></figure></p>
</blockquote>
<h2 id="zipWithUniqueId"><a href="#zipWithUniqueId" class="headerlink" title="zipWithUniqueId"></a>zipWithUniqueId</h2><p>defzipWithUniqueId():RDD[(T,Long)] 该函数将 RDD 中元素和一个唯一 ID 组合成键/值对，该唯一 ID 生成算法如下： 每个分区中第一个元素的唯一 ID 值为：该分区索引号， 每个分区中第 N 个元素的唯一 ID 值为： (前一个元素的唯一 ID 值)+(该 RDD 总的 分区数) 看下面的例子： scala&gt;varrdd1=sc.makeRDD(Seq(“A”,”B”,”C”,”D”,”E”,”F”),2) rdd1: org.apache.spark.rdd.RDD[String] = ParallelCollectionRDD[44] at makeRDD at:21 //rdd1 有两个分区， scala&gt;rdd1.zipWithUniqueId().collect res32:Array[(String,Long)]=Array((A,0),(B,2),(C,4),(D,1),(E,3),(F,5))<br>//总分区数为 2 //第一个分区第一个元素 ID 为 0，第二个分区第一个元素 ID 为 1 //第一个分区第二个元素 ID 为 0+2=2，第一个分区第三个元素 ID 为 2+2=4 //第二个分区第二个元素 ID 为 1+2=3，第二个分区第三个元素 ID 为 3+2=5<br>键值转换</p>
<h2 id="partitionBy"><a href="#partitionBy" class="headerlink" title="partitionBy"></a>partitionBy</h2><blockquote>
<p>def partitionBy(partitioner:Partitioner):RDD[(K,V)] 该函数根据 partitioner 函数生成新的 ShuffleRDD，将原 RDD 重新分区。 scala&gt;varrdd1=sc.makeRDD(Array((1,”A”),(2,”B”),(3,”C”),(4,”D”)),2) rdd1:org.apache.spark.rdd.RDD[(Int,String)]=ParallelCollectionRDD[23]atmakeRDDat:21 scala&gt;rdd1.partitions.size res20:Int=2<br>//查看 rdd1 中每个分区的元素 scala&gt;rdd1.mapPartitionsWithIndex{ | (partIdx,iter)=&gt;{ | varpart<em>map=scala.collection.mutable.MapString,List[(Int,String)] | while(iter.hasNext){ | varpart_name=”part</em>“+partIdx; | varelem=iter.next() | if(part<em>map.contains(part_name)){ | varelems=part_map(part_name) | elems::=elem | part_map(part_name)=elems | }else{ | part_map(part_name)=List[(Int,String)]{elem} | } | } | part_map.iterator | | } | }.collect res22:Array[(String,List[(Int,String)])]=Array((part_0,List((2,B),(1,A))),(part_1,List((4,D),(3,C))))<br>//(2,B),(1,A)在 part_0 中，(4,D),(3,C)在 part_1 中<br>//使用 partitionBy 重分区 scala&gt;varrdd2=rdd1.partitionBy(neworg.apache.spark.HashPartitioner(2)) rdd2:org.apache.spark.rdd.RDD[(Int,String)]=ShuffledRDD[25]atpartitionByat:23<br>scala&gt;rdd2.partitions.size res23:Int=2<br>//查看 rdd2 中每个分区的元素 scala&gt;rdd2.mapPartitionsWithIndex{ | (partIdx,iter)=&gt;{ | varpart_map=scala.collection.mutable.MapString,List[(Int,String)] | while(iter.hasNext){ | varpart_name=”part</em>“+partIdx; | varelem=iter.next() | if(part_map.contains(part_name)){ | varelems=part_map(part_name) | elems::=elem | part_map(part_name)=elems | }else{ | part_map(part_name)=List[(Int,String)]{elem} | } | } | part_map.iterator | } | }.collect res24:Array[(String,List[(Int,String)])]=Array((part_0,List((4,D),(2,B))),(part_1,List((3,C),(1,A)))) //(4,D),(2,B)在 part_0 中，(3,C),(1,A)在 part_1 中</p>
</blockquote>
<h2 id="mapValues"><a href="#mapValues" class="headerlink" title="mapValues"></a>mapValues</h2><blockquote>
<p>mapValues 顾名思义就是输入函数应用于 RDD 中 Kev-Value 的 Value，原 RDD 中的 Key 保持 不变，与新的 Value 一起组成新的 RDD 中的元素。因此，该函数只适用于元素为 KV 对的 RDD。 举例：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">scala&gt;vala&#x3D;sc.parallelize(List(&quot;dog&quot;,&quot;tiger&quot;,&quot;lion&quot;,&quot;cat&quot;,&quot;panther&quot;,&quot;eagle&quot;),2) </span><br><span class="line">scala&gt;valb&#x3D;a.map(x&#x3D;&gt;(x.length,x)) </span><br><span class="line">scala&gt;b.mapValues(&quot;x&quot;+_+&quot;x&quot;).collect</span><br><span class="line">res5: Array[(Int, String)] &#x3D; Array((3,xdogx), (5,xtigerx), (4,xlionx),(3,xcatx), (7,xpantherx), (5,xeaglex))</span><br></pre></td></tr></table></figure></p>
</blockquote>
<h2 id="flatMapValues"><a href="#flatMapValues" class="headerlink" title="flatMapValues"></a>flatMapValues</h2><blockquote>
<p>flatMapValues 类似于 mapValues，不同的在于 flatMapValues 应用于元素为 KV 对的 RDD 中 Value。每个一元素的 Value 被输入函数映射为一系列的值，然后这些值再与原 RDD 中的 Key 组成一系列新的 KV 对。 举例 vala=sc.parallelize(List((1,2),(3,4),(5,6))) valb=a.flatMapValues(x=&gt;1.to(x)) b.collect.foreach(println)</p>
</blockquote>
<h2 id="combineByKey"><a href="#combineByKey" class="headerlink" title="combineByKey"></a>combineByKey</h2><blockquote>
<p>def combineByKey<a href="createCombiner: (V">C</a> =&gt; C, mergeValue: (C, V) =&gt; C, mergeCombiners: (C, C) =&gt;C):RDD[(K,C)] def combineByKey<a href="createCombiner: (V">C</a> =&gt; C, mergeValue: (C, V) =&gt; C, mergeCombiners: (C, C) =&gt;C,numPartitions:Int):RDD[(K,C)] def combineByKey<a href="createCombiner: (V">C</a> =&gt; C, mergeValue: (C, V) =&gt; C, mergeCombiners: (C, C) =&gt; C, partitioner: Partitioner, mapSideCombine: Boolean = true, serializer: Serializer = null): RDD[(K,C)] 该函数用于将 RDD[K,V]转换成 RDD[K,C],这里的 V 类型和 C 类型可以相同也可以不同。 其中的参数： createCombiner：组合器函数，用于将 V 类型转换成 C 类型，输入参数为 RDD[K,V]中的 V,输 出为 C,分区内相同的 key 做一次 mergeValue：合并值函数，将一个C类型和一个V类型值合并成一个C类型， 输入参数为(C,V)， 输出为 C，分区内相同的 key 循环做 mergeCombiners：分区合并组合器函数，用于将两个 C 类型值合并成一个 C 类型，输入参数 为(C,C)，输出为 C，分区之间循环做 numPartitions：结果 RDD 分区数，默认保持原有的分区数 partitioner：分区函数,默认为 HashPartitioner mapSideCombine：是否需要在 Map 端进行 combine 操作，类似于 MapReduce 中的 combine， 默认为 true<br>看下面例子：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scala&gt;var rdd1&#x3D;sc.makeRDD(Array((&quot;A&quot;,1),(&quot;A&quot;,2),(&quot;B&quot;,1),(&quot;B&quot;,2),(&quot;C&quot;,1))) </span><br><span class="line">rdd1:org.apache.spark.rdd.RDD[(String,Int)]&#x3D;ParallelCollectionRDD[64]atmakeRDDat:21 </span><br><span class="line">scala&gt;rdd1.combineByKey( | (v:Int)&#x3D;&gt;v+&quot;&quot;, | (c:String,v:Int)&#x3D;&gt;c+&quot;@&quot;+v, | (c1:String,c2:String)&#x3D;&gt;c1+&quot;1),(B,1_” +c2&#x2F;&#x2F;合并 C 类型和 C 类型，中间加$，返回 C(String) 其他参数为默认值。 最终，将 RDD[String,Int]转换为 RDD[String,String]。</span><br></pre></td></tr></table></figure></p>
</blockquote>
<p>再看例子：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rdd1.combineByKey( (v:Int)&#x3D;&gt;List(v), (c:List[Int],v:Int)&#x3D;&gt;v::c, (c1:List[Int],c2:List[Int])&#x3D;&gt;c1:::c2 ).collect </span><br><span class="line">res65:Array[(String,List[Int])]&#x3D;Array((A,List(2,1)),(B,List(2,1)),(C,List(1))) 最终将 RDD[String,Int]转换为 RDD[String,List[Int]]。</span><br></pre></td></tr></table></figure></p>
<h2 id="foldByKey"><a href="#foldByKey" class="headerlink" title="foldByKey"></a>foldByKey</h2><p>deffoldByKey(zeroValue:V)(func:(V,V)=&gt;V):RDD[(K,V)]<br>deffoldByKey(zeroValue:V,numPartitions:Int)(func:(V,V)=&gt;V):RDD[(K,V)]<br>deffoldByKey(zeroValue:V,partitioner:Partitioner)(func:(V,V)=&gt;V):RDD[(K,V)]<br>该函数用于 RDD[K,V]根据 K 将 V 做折叠、合并处理，其中的参数 zeroValue 表示先根据映射 函数将 zeroValue 应用于 V,进行初始化 V,再将映射函数应用于初始化后的 V.<br>例子：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scala&gt;varrdd1&#x3D;sc.makeRDD(Array((&quot;A&quot;,0),(&quot;A&quot;,2),(&quot;B&quot;,1),(&quot;B&quot;,2),(&quot;C&quot;,1))) scala&gt;rdd1.foldByKey(0)(+).collect res75:Array[(String,Int)]&#x3D;Array((A,2),(B,3),(C,1)) &#x2F;&#x2F;将 rdd1 中每个 key 对应的 V 进行累加，注意 zeroValue&#x3D;0,需要先初始化 V,映射函数为+操 &#x2F;&#x2F;作，比如(&quot;A&quot;,0),(&quot;A&quot;,2)，先将 zeroValue 应用于每个 V,得到：(&quot;A&quot;,0+0),(&quot;A&quot;,2+0)，即： &#x2F;&#x2F;(&quot;A&quot;,0),(&quot;A&quot;,2)，再将映射函数应用于初始化后的 V，最后得到(A,0+2),即(A,2)</span><br></pre></td></tr></table></figure><br>再看：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scala&gt;rdd1.foldByKey(2)(+).collect res76:Array[(String,Int)]&#x3D;Array((A,6),(B,7),(C,3)) &#x2F;&#x2F;先将 zeroValue&#x3D;2 应用于每个 V,得到：(&quot;A&quot;,0+2), (&quot;A&quot;,2+2)，即：(&quot;A&quot;,2), (&quot;A&quot;,4)，再将映射 函 &#x2F;&#x2F;数应用于初始化后的 V，最后得到：(A,2+4)，即：(A,6)</span><br></pre></td></tr></table></figure><br>再看乘法操作：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scala&gt;rdd1.foldByKey(0)(*).collect res77:Array[(String,Int)]&#x3D;Array((A,0),(B,0),(C,0)) &#x2F;&#x2F;先将 zeroValue&#x3D;0 应用于每个 V,注意，这次映射函数为乘法，得到：(&quot;A&quot;,00),(&quot;A&quot;,20)， &#x2F;&#x2F;即：(&quot;A&quot;,0),(&quot;A&quot;,0)，再将映射函&#x2F;&#x2F;数应用于初始化后的 V，最后得到：(A,00)，即：(A,0) &#x2F;&#x2F;其他 K 也一样，最终都得到了 V&#x3D;0</span><br><span class="line">scala&gt;rdd1.foldByKey(1)(__).collect res78:Array[(String,Int)]&#x3D;Array((A,0),(B,2),(C,1)) &#x2F;&#x2F;映射函数为乘法时，需要将 zeroValue 设为 1，才能得到我们想要的结果。</span><br></pre></td></tr></table></figure><br>在使用 foldByKey 算子时候，要特别注意映射函数及 zeroValue 的取值。</p>
<h2 id="reduceByKeyLocally"><a href="#reduceByKeyLocally" class="headerlink" title="reduceByKeyLocally"></a>reduceByKeyLocally</h2><blockquote>
<p>defreduceByKeyLocally(func:(V,V)=&gt;V):Map[K,V]<br>该函数将 RDD[K,V]中每个 K 对应的 V 值根据映射函数来运算，运算结果映射到一个 Map[K,V] 中，而不是 RDD[K,V]。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">scala&gt;var rdd1&#x3D;sc.makeRDD(Array((&quot;A&quot;,0),(&quot;A&quot;,2),(&quot;B&quot;,1),(&quot;B&quot;,2),(&quot;C&quot;,1))) </span><br><span class="line">rdd1:org.apache.spark.rdd.RDD[(String,Int)]&#x3D;ParallelCollectionRDD[91]atmakeRDDat:21</span><br><span class="line">scala&gt;rdd1.reduceByKeyLocally((x,y)&#x3D;&gt;x+y) </span><br><span class="line">res90:scala.collection.Map[String,Int]&#x3D;Map(B-&gt;3,A-&gt;2,C-&gt;1)</span><br></pre></td></tr></table></figure></p>
</blockquote>
<h2 id="sample"><a href="#sample" class="headerlink" title="sample"></a>sample</h2><blockquote>
<p>sample(withReplacement, fraction, seed):以指定的随机种子随机抽样出数量为fraction的数据，withReplacement表示是抽出的数据是否放回，true为有放回的抽样，false为无放回的抽样，seed用于指定随机数生成器种子。例子从RDD中随机且有放回的抽出50%的数据，随机种子值为3（即可能以1 2 3的其中一个起始值）<br><code>`
Val red = sc.makeRDD(1 to 10)
Val sample = rdd.sample(true,0.4,.2)</code></p>
</blockquote>
</div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Levin lee</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://levin-lee.github.io/2021/11/27/RDD%E5%87%BD%E6%95%B0%E5%A4%A7%E5%85%A8/">http://levin-lee.github.io/2021/11/27/RDD%E5%87%BD%E6%95%B0%E5%A4%A7%E5%85%A8/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://levin-lee.github.io" target="_blank">Levin-lee</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i> 打赏<div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/img/wechat.jpg" target="_blank"><img class="post-qr-code-img" data-lazy-src="/img/wechat.jpg" alt="wechat"/></a><div class="post-qr-code-desc">wechat</div></li><li class="reward-item"><a href="/img/alipay.jpg" target="_blank"><img class="post-qr-code-img" data-lazy-src="/img/alipay.jpg" alt="alipay"/></a><div class="post-qr-code-desc">alipay</div></li></ul></div></div></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/2021/06/19/spark-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/"><img class="next-cover" data-lazy-src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">spark-逻辑回归</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div></article></main><footer id="footer" data-type="color"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2021 By Levin lee</div><div class="framework-info"><span>框架 </span><a href="https://hexo.io" target="_blank" rel="noopener">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener">Butterfly</a></div><div class="footer_custom_text">Hi, welcome to my blog!</div></div></footer></div><section id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font_plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font_minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></section><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>由</span> <a href="https://github.com/wzpan/hexo-generator-search" target="_blank" rel="noopener" style="color:#49B1F5;">hexo-generator-search</a>
 <span>提供支持</span></div></div></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div><div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module" defer></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js" async></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>function loadValine () {
  function initValine () {
    window.valine = new Valine({
      el: '#vcomment',
      appId: '',
      appKey: '',
      placeholder: 'Please leave your footprints',
      avatar: 'monsterid',
      meta: 'nick,mail,link'.split(','),
      pageSize: '10',
      lang: 'en',
      recordIP: false,
      serverURLs: '',
      emojiCDN: '',
      emojiMaps: "",
      enableQQ: false,
      path: window.location.pathname,
    });
    if ('nick,mail') { valine.config.requiredFields= 'nick,mail'.split(',') }
  }

  if (typeof Valine === 'function') initValine() 
  else $.getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js', initValine)
}

if ('Valine' === 'Valine' || !true) {
  if (true) loadComment(document.querySelector('#vcomment'),loadValine)
  else setTimeout(() => loadValine(), 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script src="https://cdn.jsdelivr.net/gh/lete114/CDN/Sum/sakura.js"></script>#樱花<canvas class="fireworks"></canvas><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="/js/third-party/fireworks.js"></script><script src="/js/third-party/activate-power-mode.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
document.body.addEventListener('input', POWERMODE);
</script></div></body></html>