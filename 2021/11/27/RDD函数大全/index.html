<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-CN">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="spark," />




  


  <link rel="alternate" href="/atom.xml" title="LingliGan" type="application/atom+xml" />






<meta name="description" content="map 是对 RDD 中的每个元素都执行一个指定的函数来产生一个新的 RDD。 任何 原 RDD 中的元素在新 RDD 中都有且只有一个元素与之对应。 举例：   12345scala&gt;val a&#x3D;sc.parallelize(1to9,3) scala&gt;val b&#x3D;a.map(x&#x3D;&gt;x*2) scala&gt;a.collect res10:Arr">
<meta property="og:type" content="article">
<meta property="og:title" content="RDD函数大全">
<meta property="og:url" content="http://lingligan.github.io/2021/11/27/RDD%E5%87%BD%E6%95%B0%E5%A4%A7%E5%85%A8/index.html">
<meta property="og:site_name" content="LingliGan">
<meta property="og:description" content="map 是对 RDD 中的每个元素都执行一个指定的函数来产生一个新的 RDD。 任何 原 RDD 中的元素在新 RDD 中都有且只有一个元素与之对应。 举例：   12345scala&gt;val a&#x3D;sc.parallelize(1to9,3) scala&gt;val b&#x3D;a.map(x&#x3D;&gt;x*2) scala&gt;a.collect res10:Arr">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2021-11-27T20:20:45.000Z">
<meta property="article:modified_time" content="2021-11-27T07:08:16.000Z">
<meta property="article:author" content="LingliGan">
<meta property="article:tag" content="spark">
<meta name="twitter:card" content="summary">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://LingliGan.github.io/2021/11/27/RDD函数大全/"/>





  <title>RDD函数大全 | LingliGan</title>
  








<meta name="generator" content="Hexo 4.2.1"></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">LingliGan</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-schedule">
          <a href="/schedule/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-calendar"></i> <br />
            
            Schedule
          </a>
        </li>
      
        
        <li class="menu-item menu-item-sitemap">
          <a href="/sitemap.xml" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-sitemap"></i> <br />
            
            Sitemap
          </a>
        </li>
      
        
        <li class="menu-item menu-item-commonweal">
          <a href="/404/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-heartbeat"></i> <br />
            
            Commonweal 404
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://LingliGan.github.io/2021/11/27/RDD%E5%87%BD%E6%95%B0%E5%A4%A7%E5%85%A8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="LingliGan">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LingliGan">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">RDD函数大全</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2021-11-27T14:20:45-06:00">
                2021-11-27
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="map"><a href="#map" class="headerlink" title="map"></a>map</h2><blockquote>
<p>是对 RDD 中的每个元素都执行一个指定的函数来产生一个新的 RDD。 任何 原 RDD 中的元素在新 RDD 中都有且只有一个元素与之对应。 举例： </p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">scala&gt;val a&#x3D;sc.parallelize(1to9,3) </span><br><span class="line">scala&gt;val b&#x3D;a.map(x&#x3D;&gt;x*2) </span><br><span class="line">scala&gt;a.collect res10:Array[Int]&#x3D;Array(1,2,3,4,5,6,7,8,9) </span><br><span class="line">scala&gt;b.collect res11:Array[Int]&#x3D;Array(2,4,6,8,10,12,14,16,18) </span><br><span class="line">&#x2F;&#x2F;上述例子中把原 RDD 中每个元素都乘以 2 来产生一个新的 RDD。</span><br></pre></td></tr></table></figure>
<h2 id="filter"><a href="#filter" class="headerlink" title="filter"></a>filter</h2><blockquote>
<p>filter 是对 RDD 中的每个元素都执行一个指定的函数来过滤产生一个新的 RDD。 任何原 RDD 中的元素在新 RDD 中都有且只有一个元素与之对应。</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">val rdd&#x3D;sc.parallelize(List(1,2,3,4,5,6)) </span><br><span class="line">val filterRdd&#x3D;rdd.filter(_&gt;5) </span><br><span class="line">filterRdd.collect()&#x2F;&#x2F;返回所有大于 5 的数据的一个 Array， Array(6,8,10,12)</span><br></pre></td></tr></table></figure>
<h2 id="flatMap"><a href="#flatMap" class="headerlink" title="flatMap"></a>flatMap</h2><blockquote>
<p>与 map 类似，区别是原 RDD 中的元素经 map 处理后只能生成一个元素，而原 RDD 中的元素经 flatmap 处理后可生成多个元素来构建新 RDD。举例：对原 RDD 中的每个元素 x 产生 y 个元素（从 1 到 y，y 为元素 x 的值） </p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scala&gt;vala&#x3D;sc.parallelize(1to4,2) scala&gt;valb&#x3D;a.flatMap(x&#x3D;&gt;1tox)</span><br><span class="line">scala&gt;b.collect res12:Array[Int]&#x3D;Array(1,1,2,1,2,3,1,2,3,4)</span><br></pre></td></tr></table></figure>
<h2 id="mapPartitions"><a href="#mapPartitions" class="headerlink" title="mapPartitions"></a>mapPartitions</h2><blockquote>
<p>mapPartitions 是 map 的一个变种。map 的输入函数是应用于 RDD 中每个元素， 而 mapPartitions 的输入函数是应用于每个分区，也就是把每个分区中的内容作 为整体来处理的。 它的函数定义为： def mapPartitions<a href="f: Iterator[T] =&gt; Iterator[U], preservesPartitioning: Boolean=false">U: ClassTag</a>:RDD[U] f 即为输入函数，它处理每个分区里面的内容。每个分区中的内容将以 Iterator[T] 传递给输入函数 f， f 的输出结果是 Iterator[U]。最终的 RDD 由所有分区经过输入 函数处理后的结果合并起来的。 举例：</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">scala&gt;val a&#x3D;sc.parallelize(1to9,3) </span><br><span class="line">scala&gt;def myfuncT:Iterator[(T,T)]&#x3D;&#123; </span><br><span class="line">var res&#x3D;List(T,T) </span><br><span class="line">var pre&#x3D;iter.next </span><br><span class="line">while(iter.hasNext)&#123; </span><br><span class="line">	valcur&#x3D;iter.next </span><br><span class="line">	res.::&#x3D;(pre,cur) </span><br><span class="line">	pre&#x3D;cur &#125; res.iterator &#125; </span><br><span class="line">scala&gt;a.mapPartitions(myfunc).collect </span><br><span class="line">res0:Array[(Int,Int)]&#x3D;Array((2,3),(1,2),(5,6),(4,5),(8,9),(7,8))</span><br></pre></td></tr></table></figure>
<p> 上述例子中的函数myfunc是把分区中一个元素和它的下一个元素组成一个Tuple。 因为分区中最后一个元素没有下一个元素了，所以(3,4)和(6,7)不在结果中。 mapPartitions 还有些变种，比如 mapPartitionsWithContext，它能把处理过程中的 一些状态信息传递给用户指定的输入函数。还有 mapPartitionsWithIndex，它能 把分区的 index传递给用户指定的输入函数。</p>
<h2 id="mapPartitionsWithIndex"><a href="#mapPartitionsWithIndex" class="headerlink" title="mapPartitionsWithIndex"></a>mapPartitionsWithIndex</h2><p>def mapPartitionsWithIndex<a href="f: (Int, Iterator[T]">U</a> =&gt; Iterator[U], preservesPartitioning:Boolean=false)(implicitarg0:ClassTag[U]):RDD[U] 函数作用同 mapPartitions，不过提供了两个参数，第一个参数为分区的索引。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">var rdd1&#x3D;sc.makeRDD(1to5,2) &#x2F;&#x2F;rdd1 有两个分区 </span><br><span class="line">var rdd2&#x3D;rdd1.mapPartitionsWithIndex&#123; </span><br><span class="line">(x,iter)&#x3D;&gt;&#123; varresult&#x3D;ListString </span><br><span class="line">var i&#x3D;0 </span><br><span class="line">while(iter.hasNext)&#123; i+&#x3D;iter.next() &#125; result.::(x+&quot;|&quot;+i).iterator</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>//rdd2 将 rdd1 中每个分区的数字累加，并在每个分区的累加结果前面加了分区 索引 scala&gt;rdd2.collect res13:Array[String]=Array(0|3,1|12)</p>
<h2 id="mapWith"><a href="#mapWith" class="headerlink" title="mapWith"></a>mapWith</h2><blockquote>
<p>mapWith 是 map 的另外一个变种，map 只需要一个输入函数，而 mapWith 有两 个输入函数。它的定义如下： def mapWith<a href="constructA: Int =&gt; A, preservesPartitioning: Boolean = false">A: ClassTag, U: </a>(f:(T,A)=&gt;U):RDD[U] 第一个函数 constructA 是把 RDD 的 partitionindex（index 从 0 开始）作为输入， 输出为新类型 A； 第二个函数 f 是把二元组(T,A)作为输入（其中 T 为原 RDD 中的元素，A 为第一个 函数的输出），输出类型为 U。 举例：把 partitionindex 乘以 10 加 2,作为新的 RDD 的元素。 </p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">val x&#x3D;sc.parallelize(List(1,2,3,4,5,6,7,8,9,10),3) </span><br><span class="line">x.mapWith(a&#x3D;&gt;a*10)((b,a)&#x3D;&gt;(b,a+2)).collect </span><br><span class="line">&#x2F;&#x2F; 结果： </span><br><span class="line">(1,2) (2,2) (3,2) (4,12)</span><br><span class="line">(5,12) (6,12) (7,22) (8,22) (9,22) (10,22)</span><br></pre></td></tr></table></figure>
<h2 id="flatMapWith"><a href="#flatMapWith" class="headerlink" title="flatMapWith"></a>flatMapWith</h2><blockquote>
<p>flatMapWith 与 mapWith 很类似，都是接收两个函数，一个函数把 partitionIndex 作为输入，输出是一个新类型 A；另外一个函数是以二元组（T,A）作为输入，输 出为一个序列，这些序列里面的元素组成了新的 RDD。它的定义如下：<br>def flatMapWith<a href="constructA:Int =&gt;A, preservesPartitioning: Boolean=false">A:ClassTag, U: ClassTag</a>(f:(T,A)=&gt;Seq[U]):RDD[U] 举例： </p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scala&gt;vala&#x3D;sc.parallelize(List(1,2,3,4,5,6,7,8,9),3) </span><br><span class="line">scala&gt;a.flatMapWith(x&#x3D;&gt;x,true)((x,y)&#x3D;&gt;List(y,x)).collect </span><br><span class="line">res58:Array[Int]&#x3D;Array(0,1,0,2,0,3,1,4,1,5,1,6,2,7,2, 8,2,9)</span><br></pre></td></tr></table></figure>
<h2 id="coalesce"><a href="#coalesce" class="headerlink" title="coalesce"></a>coalesce</h2><blockquote>
<p>def coalesce(numPartitions: Int, shuffle: Boolean = false)(implicit ord: Ordering[T] = null):RDD[T] 该函数用于将 RDD 进行重分区，使用 HashPartitioner。 第一个参数为重分区的数目，第二个为是否进行 shuffle，默认为 false; 以下面的例子来看： </p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">scala&gt;var data&#x3D;sc.parallelize(1to12,3) </span><br><span class="line">scala&gt;data.collect </span><br><span class="line">scala&gt;data.partitions.size </span><br><span class="line">scala&gt;var rdd1&#x3D;data.coalesce(1) </span><br><span class="line">scala&gt;rdd1.partitions.size </span><br><span class="line">scala&gt;varrdd1&#x3D;data.coalesce(4) </span><br><span class="line">scala&gt;rdd1.partitions.size res2:Int&#x3D;1 </span><br><span class="line">&#x2F;&#x2F;如果重分区的数目大于原来的分区数，那么必须指定 shuffle 参 数为 true，&#x2F;&#x2F;否则，分区数不便 scala&gt;varrdd1&#x3D;data.coalesce(4,true) scala&gt;rdd1.partitions.size</span><br><span class="line">res3:Int&#x3D;4</span><br></pre></td></tr></table></figure>
<h2 id="repartition"><a href="#repartition" class="headerlink" title="repartition"></a>repartition</h2><blockquote>
<p>defrepartition(numPartitions:Int)(implicitord:Ordering[T]=null):RDD[T] 该函数其实就是 coalesce 函数第二个参数为 true 的实现<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">scala&gt;vardata&#x3D;sc.parallelize(1to12,3) </span><br><span class="line">scala&gt;data.collect scala&gt;data.partitions.size </span><br><span class="line">scala&gt;var rdd1&#x3D;data.repartition(1) </span><br><span class="line">scala&gt;rdd1.partitions.size </span><br><span class="line">scala&gt;varrdd1&#x3D;data.repartition(4) </span><br><span class="line">scala&gt;rdd1.partitions.size res3:Int&#x3D;4</span><br></pre></td></tr></table></figure></p>
</blockquote>
<h2 id="randomSplit"><a href="#randomSplit" class="headerlink" title="randomSplit"></a>randomSplit</h2><blockquote>
<p>def randomSplit(weights: Array[Double], seed: Long = Utils.random.nextLong): Array[RDD[T]] 该函数根据 weights 权重，将一个 RDD 切分成多个 RDD。 该权重参数为一个 Double 数组 第二个参数为 random 的种子，基本可忽略。 </p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">scala&gt;rdd.collect res6:Array[Int]&#x3D;Array(1,2,3,4,5,6,7,8,9,10)</span><br><span class="line">scala&gt;varsplitRDD&#x3D;rdd.randomSplit(Array(0.5,0.1,0.2,0.2)) splitRDD: Array[org.apache.spark.rdd.RDD[Int]] &#x3D; Array(MapPartitionsRDD[17] at randomSplitat:23, MapPartitionsRDD[18]atrandomSplitat:23, MapPartitionsRDD[19]atrandomSplitat:23, MapPartitionsRDD[20]atrandomSplitat:23)</span><br><span class="line">&#x2F;&#x2F;这里注意：randomSplit 的结果是一个 RDD 数组</span><br><span class="line">scala&gt;splitRDD.size res8:Int&#x3D;4 &#x2F;&#x2F;由于 randomSplit 的第一个参数 weights 中传入的值有 4 个，因此，就会切分成 4 个 RDD, &#x2F;&#x2F;把原来的 rdd 按照权重 0.5,0.1,0.2,0.2，随机划分到这 4 个 RDD 中，权重高的 RDD，划分到&#x2F;&#x2F;的几率就大一些。 &#x2F;&#x2F;注意，权重的总和加起来为 1，否则会不正常 scala&gt;splitRDD(0).collect res10:Array[Int]&#x3D;Array(1,4)</span><br><span class="line">scala&gt;splitRDD(1).collect res11:Array[Int]&#x3D;Array(3)</span><br><span class="line">scala&gt;splitRDD(2).collect res12:Array[Int]&#x3D;Array(5,9)</span><br><span class="line">scala&gt;splitRDD(3).collect res13:Array[Int]&#x3D;Array(2,6,7,8,10)</span><br></pre></td></tr></table></figure>
<h2 id="glom"><a href="#glom" class="headerlink" title="glom"></a>glom</h2><blockquote>
<p>defglom():RDD[Array[T]] 该函数是将 RDD 中每一个分区中类型为 T 的元素转换成 Array[T]，这样每一个分 区就只有一个数组元素。</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">scala&gt;var rdd&#x3D;sc.makeRDD(1to10,3) </span><br><span class="line">rdd:org.apache.spark.rdd.RDD[Int]&#x3D;ParallelCollectionRDD[38]atmakeRDDat:21 </span><br><span class="line">scala&gt;rdd.partitions.size res33:Int&#x3D;3 </span><br><span class="line">&#x2F;&#x2F;该 RDD 有 3 个分区 </span><br><span class="line">scala&gt;rdd.glom().collect </span><br><span class="line">res35:Array[Array[Int]]&#x3D;Array(Array(1,2,3),Array(4,5,6),Array(7,8,9,10)) &#x2F;&#x2F;glom 将每个分区中的元素放到一个数组中，这样，结果就变成了 3 个数组</span><br></pre></td></tr></table></figure>
<h2 id="union-并集"><a href="#union-并集" class="headerlink" title="union 并集"></a>union 并集</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">val rdd1&#x3D;sc.parallelize(List(5,6,4,3)) </span><br><span class="line">val rdd2&#x3D;sc.parallelize(List(1,2,3,4)) &#x2F;&#x2F;求并集 </span><br><span class="line">val rdd3&#x3D;rdd1.union(rdd2) </span><br><span class="line">rdd3.collect</span><br></pre></td></tr></table></figure>
<h2 id="distinct"><a href="#distinct" class="headerlink" title="distinct"></a>distinct</h2><blockquote>
<p>去重 </p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">val rdd1&#x3D;sc.parallelize(List(5,6,4,3)) </span><br><span class="line">val rdd2&#x3D;sc.parallelize(List(1,2,3,4)) &#x2F;&#x2F;求并集 valrdd3&#x3D;rdd1.union(rdd2) &#x2F;&#x2F;去重输出 rdd3.distinct.collect</span><br></pre></td></tr></table></figure>
<h2 id="intersection-交集"><a href="#intersection-交集" class="headerlink" title="intersection 交集"></a>intersection 交集</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">val rdd1&#x3D;sc.parallelize(List(5,6,4,3)) </span><br><span class="line">valrdd2&#x3D;sc.parallelize(List(1,2,3,4)) &#x2F;&#x2F;求交集 valrdd4&#x3D;rdd1.intersection(rdd2) rdd4.collect</span><br></pre></td></tr></table></figure>
<h2 id="subtract"><a href="#subtract" class="headerlink" title="subtract"></a>subtract</h2><blockquote>
<p>def subtract(other:RDD[T]):RDD[T] defsubtract(other:RDD[T],numPartitions:Int):RDD[T] def subtract(other: RDD[T], partitioner: Partitioner)(implicit ord: Ordering[T] = null): RDD[T] 该函数返回在 RDD 中出现，并且不在 otherRDD 中出现的元素，不去重。</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">val rdd1&#x3D;sc.parallelize(List(5,6,6,4,3)) </span><br><span class="line">val rdd2&#x3D;sc.parallelize(List(1,2,3,4)) &#x2F;&#x2F;求差集 valrdd4&#x3D;rdd1.subtract(rdd2) rdd4.collect</span><br></pre></td></tr></table></figure>
<h2 id="subtractByKey"><a href="#subtractByKey" class="headerlink" title="subtractByKey"></a>subtractByKey</h2><blockquote>
<p>defsubtractByKeyW(implicitarg0:ClassTag[W]):RDD[(K,V)] def subtractByKey<a href="other: RDD[(K, W">W</a>], numPartitions: Int)(implicit arg0: ClassTag[W]):RDD[(K,V)] def subtractByKey<a href="other: RDD[(K, W">W</a>], p: Partitioner)(implicit arg0: ClassTag[W]): RDD[(K,V)]<br>subtractByKey 和基本转换操作中的 subtract 类似，只不过这里是针对 K 的，返回 在主 RDD 中出现，并且不在 otherRDD 中出现的元素。 参数 numPartitions 用于指定结果的分区数 参数 partitioner 用于指定分区函数</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">var rdd1&#x3D;sc.makeRDD(Array((&quot;A&quot;,&quot;1&quot;),(&quot;B&quot;,&quot;2&quot;),(&quot;C&quot;,&quot;3&quot;)),2) </span><br><span class="line">var rdd2&#x3D;sc.makeRDD(Array((&quot;A&quot;,&quot;a&quot;),(&quot;C&quot;,&quot;c&quot;),(&quot;D&quot;,&quot;d&quot;)),2) </span><br><span class="line">scala&gt;rdd1.subtractByKey(rdd2).collect res13:Array[(String,String)]&#x3D;Array((B,2))</span><br></pre></td></tr></table></figure>
<h2 id="groupbyKey"><a href="#groupbyKey" class="headerlink" title="groupbyKey"></a>groupbyKey</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">val rdd1&#x3D;sc.parallelize(List((&quot;tom&quot;,1),(&quot;jerry&quot;,3),(&quot;kitty&quot;,2))) </span><br><span class="line">val rdd2&#x3D;sc.parallelize(List((&quot;jerry&quot;,2),(&quot;tom&quot;,1),(&quot;shuke&quot;,2))) &#x2F;&#x2F;求并集 </span><br><span class="line">val rdd4&#x3D;rdd1.union(rdd2) &#x2F;&#x2F;按 key 进行分组 </span><br><span class="line">val rdd5&#x3D;rdd4.groupByKey </span><br><span class="line">rdd5.collect</span><br></pre></td></tr></table></figure>
<h2 id="reduceByKey"><a href="#reduceByKey" class="headerlink" title="reduceByKey"></a>reduceByKey</h2><blockquote>
<p>顾名思义，reduceByKey 就是对元素为 KV 对的 RDD 中 Key 相同的元素的 Value 进行 reduce，因此，Key 相同的多个元素的值被 reduce 为一个值，然后与原 RDD 中的 Key 组成一个新的 KV 对。 举例: </p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">valrdd1&#x3D;sc.parallelize(List((&quot;tom&quot;,1),(&quot;jerry&quot;,3),(&quot;kitty&quot;,2))) </span><br><span class="line">valrdd2&#x3D;sc.parallelize(List((&quot;jerry&quot;,2),(&quot;tom&quot;,1),(&quot;shuke&quot;,2))) &#x2F;&#x2F;求并集 </span><br><span class="line">val rdd4&#x3D;rdd1unionrdd2 &#x2F;&#x2F;按 key 进行分组 </span><br><span class="line">val rdd6&#x3D;rdd4.reduceByKey(+) rdd6.collect()</span><br></pre></td></tr></table></figure>
<h2 id="sortByKey"><a href="#sortByKey" class="headerlink" title="sortByKey"></a>sortByKey</h2><blockquote>
<p>将 List((“tom”,1),(“jerry”,3),(“kitty”,2), (“shuke”,1))和 List((“jerry”,2),(“tom”,3), (“shuke”,2),(“kitty”,5))做 wordcount，并按名称排序<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">val rdd1&#x3D;sc.parallelize(List((&quot;tom&quot;,1),(&quot;jerry&quot;,3),(&quot;kitty&quot;,2),(&quot;shuke&quot;,1))) </span><br><span class="line">val rdd2&#x3D;sc.parallelize(List((&quot;jerry&quot;,2),(&quot;tom&quot;,3),(&quot;shuke&quot;,2),(&quot;kitty&quot;,5))) </span><br><span class="line">val rdd3&#x3D;rdd1.union(rdd2) &#x2F;&#x2F;按 key 进行聚合 </span><br><span class="line">val rdd4&#x3D;rdd3.reduceByKey(+) &#x2F;&#x2F;false 降序 </span><br><span class="line">val rdd5&#x3D;rdd4.sortByKey(false) </span><br><span class="line">rdd5.collect</span><br></pre></td></tr></table></figure></p>
</blockquote>
<h2 id="sortBy"><a href="#sortBy" class="headerlink" title="sortBy"></a>sortBy</h2><blockquote>
<p>将 List((“tom”,1),(“jerry”,3),(“kitty”,2), (“shuke”,1))和 List((“jerry”,2),(“tom”,3), (“shuke”,2),(“kitty”,5))做 wordcount，并按数值排序 </p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">val rdd1&#x3D;sc.parallelize(List((&quot;tom&quot;,1),(&quot;jerry&quot;,3),(&quot;kitty&quot;,2),(&quot;shuke&quot;,1))) </span><br><span class="line">valrdd2&#x3D;sc.parallelize(List((&quot;jerry&quot;,2),(&quot;tom&quot;,3),(&quot;shuke&quot;,2),(&quot;kitty&quot;,5))) </span><br><span class="line">val rdd3&#x3D;rdd1.union(rdd2) </span><br><span class="line">&#x2F;&#x2F;按 key 进行聚合 </span><br><span class="line">valrdd4&#x3D;rdd3.reduceByKey(+)</span><br><span class="line">&#x2F;&#x2F;false 降序 </span><br><span class="line">valrdd5&#x3D;rdd4.sortBy(_._2,false) rdd5.collect</span><br><span class="line"></span><br><span class="line">## zip</span><br><span class="line">&gt;def zipU(implicitarg0:ClassTag[U]):RDD[(T,U)]</span><br><span class="line">zip 函数用于将两个 RDD 组合成 Key&#x2F;Value 形式的 RDD,这里默认两个 RDD 的 partition 数量以及元素数量都相同，否则会抛出异常。</span><br></pre></td></tr></table></figure>
<p>scala&gt;varrdd1=sc.makeRDD(1to5,2) rdd1:org.apache.spark.rdd.RDD[Int]=ParallelCollectionRDD[1]atmakeRDDat:21<br>scala&gt;varrdd2=sc.makeRDD(Seq(“A”,”B”,”C”,”D”,”E”),2) rdd2: org.apache.spark.rdd.RDD[String] = ParallelCollectionRDD[2] at makeRDD at:21<br>scala&gt;rdd1.zip(rdd2).collect res0:Array[(Int,String)]=Array((1,A),(2,B),(3,C),(4,D),(5,E))<br>scala&gt;rdd2.zip(rdd1).collect res1:Array[(String,Int)]=Array((A,1),(B,2),(C,3),(D,4),(E,5))<br>scala&gt;varrdd3=sc.makeRDD(Seq(“A”,”B”,”C”,”D”,”E”),3) rdd3: org.apache.spark.rdd.RDD[String] = ParallelCollectionRDD[5] at makeRDD at:21 scala&gt;rdd1.zip(rdd3).collect java.lang.IllegalArgumentException: Can’t zip RDDs with unequal numbers of partitions //如果两个 RDD 分区数不同，则抛出异常<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">## zipPartitions</span><br><span class="line">&gt;zipPartitions 函数将多个 RDD 按照 partition 组合成为新的 RDD，该函数需要组合</span><br><span class="line">的 RDD 具有相同的分区数，但对于每个分区内的元素数量没有要求。 该函数有好几种实现，可分为三类：</span><br><span class="line">参数是一个 RDD</span><br></pre></td></tr></table></figure><br>def zipPartitions<a href="rdd2: RDD[B]">B, V</a>(f: (Iterator[T], Iterator[B]) =&gt; Iterator[V])(implicit arg0: ClassTag[B],arg1:ClassTag[V]):RDD[V]<br>def zipPartitions<a href="rdd2: RDD[B], preservesPartitioning: Boolean">B, V</a>(f: (Iterator[T], Iterator[B]) =&gt; Iterator[V])(implicitarg0:ClassTag[B],arg1:ClassTag[V]):RDD[V]<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">这两个区别就是参数 preservesPartitioning，是否保留父 RDD 的 partitioner 分区信息</span><br><span class="line">映射方法 f 参数为两个 RDD 的迭代器。</span><br></pre></td></tr></table></figure><br>scala&gt;varrdd1=sc.makeRDD(1to5,2) rdd1:org.apache.spark.rdd.RDD[Int]=ParallelCollectionRDD[22]atmakeRDDat:21<br>scala&gt;varrdd2=sc.makeRDD(Seq(“A”,”B”,”C”,”D”,”E”),2) rdd2:org.apache.spark.rdd.RDD[String]=ParallelCollectionRDD[23]atmakeRDDat:21<br>//rdd1 两个分区中元素分布： scala&gt;rdd1.mapPartitionsWithIndex{ | (x,iter)=&gt;{ | varresult=ListString | while(iter.hasNext){ | result::=(“part<em>“+x+”|”+iter.next()) | } | result.iterator | | } | }.collect res17:Array[String]=Array(part_0|2,part_0|1,part_1|5,part_1|4,part_1|3)<br>//rdd2 两个分区中元素分布 scala&gt;rdd2.mapPartitionsWithIndex{ | (x,iter)=&gt;{<br>| varresult=ListString | while(iter.hasNext){ | result::=(“part</em>“+x+”|”+iter.next()) | } | result.iterator | | } | }.collect res18:Array[String]=Array(part<em>0|B,part_0|A,part_1|E,part_1|D,part_1|C)<br>//rdd1 和 rdd2 做 zipPartition scala&gt;rdd1.zipPartitions(rdd2){ | (rdd1Iter,rdd2Iter)=&gt;{ | varresult=ListString | while(rdd1Iter.hasNext&amp;&amp;rdd2Iter.hasNext){ | result::=(rdd1Iter.next()+””+rdd2Iter.next()) | } | result.iterator | } | }.collect res19:Array[String]=Array(2_B,1_A,5_E,4_D,3_C)<br>参数是两个 RDD<br>def zipPartitions<a href="rdd2: RDD[B], rdd3: RDD[C]">B, C, V</a>(f: (Iterator[T], Iterator[B], Iterator[C]) =&gt; Iterator[V])(implicitarg0:ClassTag[B],arg1:ClassTag[C],arg2:ClassTag[V]):RDD[V]<br>def zipPartitions<a href="rdd2: RDD[B], rdd3: RDD[C], preservesPartitioning: Boolean">B, C, V</a>(f: (Iterator[T], Iterator[B], Iterator[C]) =&gt; Iterator[V])(implicit arg0: ClassTag[B], arg1: ClassTag[C], arg2:ClassTag[V]):RDD[V]<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">用法同上面，只不过该函数参数为两个 RDD，映射方法 f 输入参数为两个 RDD 的迭代器。</span><br></pre></td></tr></table></figure><br>scala&gt;varrdd1=sc.makeRDD(1to5,2) rdd1:org.apache.spark.rdd.RDD[Int]=ParallelCollectionRDD[27]atmakeRDDat:21<br>scala&gt;varrdd2=sc.makeRDD(Seq(“A”,”B”,”C”,”D”,”E”),2) rdd2:org.apache.spark.rdd.RDD[String]=ParallelCollectionRDD[28]atmakeRDDat:21<br>scala&gt;varrdd3=sc.makeRDD(Seq(“a”,”b”,”c”,”d”,”e”),2) rdd3:org.apache.spark.rdd.RDD[String]=ParallelCollectionRDD[29]atmakeRDDat:21<br>//rdd3 中个分区元素分布 scala&gt;rdd3.mapPartitionsWithIndex{ | (x,iter)=&gt;{ | varresult=ListString | while(iter.hasNext){ | result::=(“part”+x+”|”+iter.next()) | } | result.iterator | | } | }.collect res21:Array[String]=Array(part_0|b,part_0|a,part_1|e,part_1|d,part_1|c)<br>//三个 RDD 做 zipPartitions scala&gt;varrdd4=rdd1.zipPartitions(rdd2,rdd3){ | (rdd1Iter,rdd2Iter,rdd3Iter)=&gt;{ | varresult=ListString | while(rdd1Iter.hasNext&amp;&amp;rdd2Iter.hasNext&amp;&amp;rdd3Iter.hasNext){ | result::=(rdd1Iter.next()+””+rdd2Iter.next()+””+rdd3Iter.next()) | } | result.iterator | } | } rdd4:org.apache.spark.rdd.RDD[String]=ZippedPartitionsRDD3[33]atzipPartitionsat:27<br>scala&gt;rdd4.collect res23:Array[String]=Array(2_B_b,1_A_a,5_E_e,4_D_d,3_C_c)<br>参数是三个 RDD<br>def zipPartitions<a href="rdd2: RDD[B], rdd3: RDD[C], rdd4: RDD[D]">B, C, D, V</a>(f: (Iterator[T], Iterator[B],<br>Iterator[C], Iterator[D]) =&gt; Iterator[V])(implicit arg0: ClassTag[B], arg1: ClassTag[C], arg2: ClassTag[D],arg3:ClassTag[V]):RDD[V]<br>def zipPartitions<a href="rdd2: RDD[B], rdd3: RDD[C], rdd4: RDD[D], preservesPartitioning: Boolean">B, C, D, V</a>(f: (Iterator[T], Iterator[B], Iterator[C], Iterator[D]) =&gt; Iterator[V])(implicit arg0: ClassTag[B],arg1:ClassTag[C],arg2:ClassTag[D],arg3:ClassTag[V]):RDD[V]<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">用法同上面，只不过这里又多了个一个 RDD 而已。</span><br><span class="line"></span><br><span class="line">## zipWithIndex</span><br><span class="line">&gt;defzipWithIndex():RDD[(T,Long)] 该函数将 RDD 中的元素和这个元素在 RDD 中的 ID（索引号）组合成键&#x2F;值对。</span><br></pre></td></tr></table></figure><br>scala&gt;var rdd2=sc.makeRDD(Seq(“A”,”B”,”R”,”D”,”F”),2)<br>rdd2: org.apache.spark.rdd.RDD[String] = ParallelCollectionRDD[34] at makeRDD at:21<br>scala&gt;rdd2.zipWithIndex().collect res27:Array[(String,Long)]=Array((A,0),(B,1),(R,2),(D,3),(F,4))<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">##  zipWithUniqueId</span><br><span class="line">&gt;def zipWithUniqueId():RDD[(T,Long)] 该函数将 RDD 中元素和一个唯一 ID 组合成键&#x2F;值对，该唯一 ID 生成算法如下： 每个分区中第一个元素的唯一 ID 值为：该分区索引号， 每个分区中第 N 个元素的唯一 ID 值为： (前一个元素的唯一 ID 值)+(该 RDD 总的 分区数) 看下面的例子： scala&gt;varrdd1&#x3D;sc.makeRDD(Seq(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;,&quot;D&quot;,&quot;E&quot;,&quot;F&quot;),2) rdd1: org.apache.spark.rdd.RDD[String] &#x3D; ParallelCollectionRDD[44] at makeRDD at:21 &#x2F;&#x2F;rdd1 有两个分区， scala&gt;rdd1.zipWithUniqueId().collect res32:Array[(String,Long)]&#x3D;Array((A,0),(B,2),(C,4),(D,1),(E,3),(F,5))</span><br><span class="line">&#x2F;&#x2F;总分区数为 2 &#x2F;&#x2F;第一个分区第一个元素 ID 为 0，第二个分区第一个元素 ID 为 1 &#x2F;&#x2F;第一个分区第二个元素 ID 为 0+2&#x3D;2，第一个分区第三个元素 ID 为 2+2&#x3D;4 &#x2F;&#x2F;第二个分区第二个元素 ID 为 1+2&#x3D;3，第二个分区第三个元素 ID 为 3+2&#x3D;5</span><br><span class="line">键值转换</span><br><span class="line"></span><br><span class="line">## partitionBy</span><br><span class="line">&gt;def partitionBy(partitioner:Partitioner):RDD[(K,V)] 该函数根据 partitioner 函数生成新的 ShuffleRDD，将原 RDD 重新分区。 scala&gt;varrdd1&#x3D;sc.makeRDD(Array((1,&quot;A&quot;),(2,&quot;B&quot;),(3,&quot;C&quot;),(4,&quot;D&quot;)),2) rdd1:org.apache.spark.rdd.RDD[(Int,String)]&#x3D;ParallelCollectionRDD[23]atmakeRDDat:21 scala&gt;rdd1.partitions.size res20:Int&#x3D;2</span><br></pre></td></tr></table></figure><br>//查看 rdd1 中每个分区的元素<br>scala&gt;rdd1.mapPartitionsWithIndex{ | (partIdx,iter)=&gt;{ | varpart_map=scala.collection.mutable.MapString,List[(Int,String)] | while(iter.hasNext){ | varpart_name=”part</em>“+partIdx; | varelem=iter.next() | if(part<em>map.contains(part_name)){ | varelems=part_map(part_name) | elems::=elem | part_map(part_name)=elems | }else{ | part_map(part_name)=List[(Int,String)]{elem} | } | } | part_map.iterator | | } | }.collect res22:Array[(String,List[(Int,String)])]=Array((part_0,List((2,B),(1,A))),(part_1,List((4,D),(3,C))))<br>//(2,B),(1,A)在 part_0 中，(4,D),(3,C)在 part_1 中<br>//使用 partitionBy 重分区<br>scala&gt;varrdd2=rdd1.partitionBy(neworg.apache.spark.HashPartitioner(2)) rdd2:org.apache.spark.rdd.RDD[(Int,String)]=ShuffledRDD[25]atpartitionByat:23<br>scala&gt;rdd2.partitions.size res23:Int=2<br>//查看 rdd2 中每个分区的元素<br>scala&gt;rdd2.mapPartitionsWithIndex{ | (partIdx,iter)=&gt;{ | varpart_map=scala.collection.mutable.MapString,List[(Int,String)] | while(iter.hasNext){ | varpart_name=”part</em>“+partIdx; | varelem=iter.next() | if(part<em>map.contains(part_name)){ | varelems=part_map(part_name) | elems::=elem | part_map(part_name)=elems | }else{ | part_map(part_name)=List[(Int,String)]{elem} | } | } | part_map.iterator | } | }.collect res24:Array[(String,List[(Int,String)])]=Array((part_0,List((4,D),(2,B))),(part_1,List((3,C),(1,A)))) //(4,D),(2,B)在 part_0 中，(3,C),(1,A)在 part_1 中<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">##  mapValues</span><br><span class="line">&gt;mapValues 顾名思义就是输入函数应用于 RDD 中 Kev-Value 的 Value，原 RDD 中的 Key 保持 不变，与新的 Value 一起组成新的 RDD 中的元素。因此，该函数只适用于元素为 KV 对的 RDD。 举例：</span><br></pre></td></tr></table></figure><br>scala&gt;vala=sc.parallelize(List(“dog”,”tiger”,”lion”,”cat”,”panther”,”eagle”),2)<br>scala&gt;valb=a.map(x=&gt;(x.length,x))<br>scala&gt;b.mapValues(“x”+</em>+”x”).collect<br>res5: Array[(Int, String)] = Array((3,xdogx), (5,xtigerx), (4,xlionx),(3,xcatx), (7,xpantherx), (5,xeaglex))<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">##  flatMapValues</span><br><span class="line">&gt;flatMapValues 类似于 mapValues，不同的在于 flatMapValues 应用于元素为 KV 对的 RDD 中 Value。每个一元素的 Value 被输入函数映射为一系列的值，然后这些值再与原 RDD 中的 Key 组成一系列新的 KV 对。 举例 vala&#x3D;sc.parallelize(List((1,2),(3,4),(5,6))) valb&#x3D;a.flatMapValues(x&#x3D;&gt;1.to(x)) b.collect.foreach(println)</span><br><span class="line"></span><br><span class="line">## combineByKey</span><br><span class="line">&gt;def combineByKey[C](createCombiner: (V) &#x3D;&gt; C, mergeValue: (C, V) &#x3D;&gt; C, mergeCombiners: (C, C) &#x3D;&gt;C):RDD[(K,C)] def combineByKey[C](createCombiner: (V) &#x3D;&gt; C, mergeValue: (C, V) &#x3D;&gt; C, mergeCombiners: (C, C) &#x3D;&gt;C,numPartitions:Int):RDD[(K,C)] def combineByKey[C](createCombiner: (V) &#x3D;&gt; C, mergeValue: (C, V) &#x3D;&gt; C, mergeCombiners: (C, C) &#x3D;&gt; C, partitioner: Partitioner, mapSideCombine: Boolean &#x3D; true, serializer: Serializer &#x3D; null): RDD[(K,C)] 该函数用于将 RDD[K,V]转换成 RDD[K,C],这里的 V 类型和 C 类型可以相同也可以不同。 其中的参数： createCombiner：组合器函数，用于将 V 类型转换成 C 类型，输入参数为 RDD[K,V]中的 V,输 出为 C,分区内相同的 key 做一次 mergeValue：合并值函数，将一个C类型和一个V类型值合并成一个C类型， 输入参数为(C,V)， 输出为 C，分区内相同的 key 循环做 mergeCombiners：分区合并组合器函数，用于将两个 C 类型值合并成一个 C 类型，输入参数 为(C,C)，输出为 C，分区之间循环做 numPartitions：结果 RDD 分区数，默认保持原有的分区数 partitioner：分区函数,默认为 HashPartitioner mapSideCombine：是否需要在 Map 端进行 combine 操作，类似于 MapReduce 中的 combine， 默认为 true</span><br><span class="line">看下面例子：</span><br></pre></td></tr></table></figure><br>scala&gt;var rdd1=sc.makeRDD(Array((“A”,1),(“A”,2),(“B”,1),(“B”,2),(“C”,1)))<br>rdd1:org.apache.spark.rdd.RDD[(String,Int)]=ParallelCollectionRDD[64]atmakeRDDat:21<br>scala&gt;rdd1.combineByKey( | (v:Int)=&gt;v+””, | (c:String,v:Int)=&gt;c+”@”+v, | (c1:String,c2:String)=&gt;c1+”1),(B,1<em>” +c2//合并 C 类型和 C 类型，中间加$，返回 C(String) 其他参数为默认值。 最终，将 RDD[String,Int]转换为 RDD[String,String]。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">再看例子：</span><br></pre></td></tr></table></figure><br>rdd1.combineByKey( (v:Int)=&gt;List(v), (c:List[Int],v:Int)=&gt;v::c, (c1:List[Int],c2:List[Int])=&gt;c1:::c2 ).collect<br>res65:Array[(String,List[Int])]=Array((A,List(2,1)),(B,List(2,1)),(C,List(1))) 最终将 RDD[String,Int]转换为 RDD[String,List[Int]]。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">## foldByKey</span><br></pre></td></tr></table></figure><br>deffoldByKey(zeroValue:V)(func:(V,V)=&gt;V):RDD[(K,V)]<br>deffoldByKey(zeroValue:V,numPartitions:Int)(func:(V,V)=&gt;V):RDD[(K,V)]<br>deffoldByKey(zeroValue:V,partitioner:Partitioner)(func:(V,V)=&gt;V):RDD[(K,V)]<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">该函数用于 RDD[K,V]根据 K 将 V 做折叠、合并处理，其中的参数 zeroValue 表示先根据映射 函数将 zeroValue 应用于 V,进行初始化 V,再将映射函数应用于初始化后的 V.</span><br><span class="line">例子：</span><br></pre></td></tr></table></figure><br>scala&gt;varrdd1=sc.makeRDD(Array((“A”,0),(“A”,2),(“B”,1),(“B”,2),(“C”,1))) scala&gt;rdd1.foldByKey(0)(+).collect res75:Array[(String,Int)]=Array((A,2),(B,3),(C,1)) //将 rdd1 中每个 key 对应的 V 进行累加，注意 zeroValue=0,需要先初始化 V,映射函数为+操 //作，比如(“A”,0),(“A”,2)，先将 zeroValue 应用于每个 V,得到：(“A”,0+0),(“A”,2+0)，即： //(“A”,0),(“A”,2)，再将映射函数应用于初始化后的 V，最后得到(A,0+2),即(A,2)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">再看：</span><br></pre></td></tr></table></figure><br>scala&gt;rdd1.foldByKey(2)(+).collect res76:Array[(String,Int)]=Array((A,6),(B,7),(C,3)) //先将 zeroValue=2 应用于每个 V,得到：(“A”,0+2), (“A”,2+2)，即：(“A”,2), (“A”,4)，再将映射 函 //数应用于初始化后的 V，最后得到：(A,2+4)，即：(A,6)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">再看乘法操作：</span><br></pre></td></tr></table></figure><br>scala&gt;rdd1.foldByKey(0)(*).collect res77:Array[(String,Int)]=Array((A,0),(B,0),(C,0)) //先将 zeroValue=0 应用于每个 V,注意，这次映射函数为乘法，得到：(“A”,00),(“A”,20)， //即：(“A”,0),(“A”,0)，再将映射函//数应用于初始化后的 V，最后得到：(A,00)，即：(A,0) //其他 K 也一样，最终都得到了 V=0<br>scala&gt;rdd1.foldByKey(1)(_</em>).collect res78:Array[(String,Int)]=Array((A,0),(B,2),(C,1)) //映射函数为乘法时，需要将 zeroValue 设为 1，才能得到我们想要的结果。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">在使用 foldByKey 算子时候，要特别注意映射函数及 zeroValue 的取值。</span><br><span class="line"></span><br><span class="line">## reduceByKeyLocally</span><br><span class="line">&gt;defreduceByKeyLocally(func:(V,V)&#x3D;&gt;V):Map[K,V]</span><br><span class="line">该函数将 RDD[K,V]中每个 K 对应的 V 值根据映射函数来运算，运算结果映射到一个 Map[K,V] 中，而不是 RDD[K,V]。</span><br></pre></td></tr></table></figure><br>scala&gt;var rdd1=sc.makeRDD(Array((“A”,0),(“A”,2),(“B”,1),(“B”,2),(“C”,1)))<br>rdd1:org.apache.spark.rdd.RDD[(String,Int)]=ParallelCollectionRDD[91]atmakeRDDat:21<br>scala&gt;rdd1.reduceByKeyLocally((x,y)=&gt;x+y)<br>res90:scala.collection.Map[String,Int]=Map(B-&gt;3,A-&gt;2,C-&gt;1)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">## sample</span><br><span class="line">&gt;sample(withReplacement, fraction, seed):以指定的随机种子随机抽样出数量为fraction的数据，withReplacement表示是抽出的数据是否放回，true为有放回的抽样，false为无放回的抽样，seed用于指定随机数生成器种子。例子从RDD中随机且有放回的抽出50%的数据，随机种子值为3（即可能以1 2 3的其中一个起始值）</span><br></pre></td></tr></table></figure><br>Val red = sc.makeRDD(1 to 10)<br>Val sample = rdd.sample(true,0.4,.2)<br>``</p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/spark/" rel="tag"># spark</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2021/11/27/hello-world/" rel="next" title="Hello World">
                <i class="fa fa-chevron-left"></i> Hello World
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2022/04/30/RBF%E6%A8%A1%E5%9E%8B%E5%88%86%E6%9E%90%E6%8A%A5%E5%91%8A/" rel="prev" title="RBF模型分析报告">
                RBF模型分析报告 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">LingliGan</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/%7C%7C%20archive">
              
                  <span class="site-state-item-count">15</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">1</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">13</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/LingliGan" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="897992093@qq.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://twitter.com/yourname" target="_blank" title="Twitter">
                      
                        <i class="fa fa-fw fa-twitter"></i>Twitter</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://instagram.com/yourname" target="_blank" title="Instagram">
                      
                        <i class="fa fa-fw fa-instagram"></i>Instagram</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#map"><span class="nav-number">1.</span> <span class="nav-text">map</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#filter"><span class="nav-number">2.</span> <span class="nav-text">filter</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#flatMap"><span class="nav-number">3.</span> <span class="nav-text">flatMap</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#mapPartitions"><span class="nav-number">4.</span> <span class="nav-text">mapPartitions</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#mapPartitionsWithIndex"><span class="nav-number">5.</span> <span class="nav-text">mapPartitionsWithIndex</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#mapWith"><span class="nav-number">6.</span> <span class="nav-text">mapWith</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#flatMapWith"><span class="nav-number">7.</span> <span class="nav-text">flatMapWith</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#coalesce"><span class="nav-number">8.</span> <span class="nav-text">coalesce</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#repartition"><span class="nav-number">9.</span> <span class="nav-text">repartition</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#randomSplit"><span class="nav-number">10.</span> <span class="nav-text">randomSplit</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#glom"><span class="nav-number">11.</span> <span class="nav-text">glom</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#union-并集"><span class="nav-number">12.</span> <span class="nav-text">union 并集</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#distinct"><span class="nav-number">13.</span> <span class="nav-text">distinct</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#intersection-交集"><span class="nav-number">14.</span> <span class="nav-text">intersection 交集</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#subtract"><span class="nav-number">15.</span> <span class="nav-text">subtract</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#subtractByKey"><span class="nav-number">16.</span> <span class="nav-text">subtractByKey</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#groupbyKey"><span class="nav-number">17.</span> <span class="nav-text">groupbyKey</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#reduceByKey"><span class="nav-number">18.</span> <span class="nav-text">reduceByKey</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#sortByKey"><span class="nav-number">19.</span> <span class="nav-text">sortByKey</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#sortBy"><span class="nav-number">20.</span> <span class="nav-text">sortBy</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">LingliGan</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
